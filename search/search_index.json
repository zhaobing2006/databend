{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"api/config/","text":"Get the config of the Databend query server. Examples \u00b6 curl http://127.0.0.1:8080/v1/config Config { log_level: \"INFO\", log_dir: \"./_logs\", num_cpus: 16, mysql_handler_host: \"127.0.0.1\", mysql_handler_port: 3307, max_active_sessions: 256, clickhouse_handler_host: \"127.0.0.1\", clickhouse_handler_port: 9000, flight_api_address: \"127.0.0.1:9090\", http_api_address: \"127.0.0.1:8080\", metric_api_address: \"127.0.0.1:7070\", store_api_address: \"127.0.0.1:9191\", store_api_username: ******, store_api_password: ******, config_file: \"\" }","title":"Config"},{"location":"api/config/#examples","text":"curl http://127.0.0.1:8080/v1/config Config { log_level: \"INFO\", log_dir: \"./_logs\", num_cpus: 16, mysql_handler_host: \"127.0.0.1\", mysql_handler_port: 3307, max_active_sessions: 256, clickhouse_handler_host: \"127.0.0.1\", clickhouse_handler_port: 9000, flight_api_address: \"127.0.0.1:9090\", http_api_address: \"127.0.0.1:8080\", metric_api_address: \"127.0.0.1:7070\", store_api_address: \"127.0.0.1:9191\", store_api_username: ******, store_api_password: ******, config_file: \"\" }","title":"Examples"},{"location":"cli/cli/","text":"bendctl is a command-line tool for creating, listing, logging, deleting databend running instances on local or on cloud. It also supports to port forward webUI, monitoring dashboard on local and run SQL queries from command line. 1. Install \u00b6 curl -fsS https://repo.databend.rs/databend/install-bendctl.sh | bash export PATH=\"${HOME}/.databend/bin:${PATH}\" 2. Setting up a cluster \u00b6 $ bendctl [local] [sql]> \\admin Mode switched to admin mode [local] [admin]> cluster create [ok] databend cluster precheck passed! [ok] \ud83d\udc4f successfully started meta service with rpc endpoint 127.0.0.1:9191 [ok] local data would be stored in /home/ubuntu/.databend/local/data [ok] \ud83d\udc4f successfully started query service. [ok] \u2705 To run queries through RESTful api, run: bendctl query 'SQL statement' [ok] \u2705 For example: bendctl query 'SELECT sum(number), avg(number) FROM numbers(100);' [ok] \u2705 To process mysql queries, run: mysql -h 127.0.0.1 -P 3307 -uroot [ok] \u2705 To process clickhouse queries, run: clickhouse client --host 127.0.0.1 --port 9000 --user root [local] [admin]> 3. Query Example \u00b6 bendctl Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. [local] [admin]> \\sql Mode switched to SQL query mode [local] [sql]> SELECT avg(number) FROM numbers(1000000000); +-------------+ | avg(number) | +-------------+ | 499999999.5 | +-------------+ [ok] read rows: 1,000,000,000, read bytes: 8.00 GB, rows/sec: 1,259,445,843 (rows/sec), bytes/sec: 10.07556675 (GB/sec) [local] [sql]> MySQL Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. $ mysql -h127.0.0.1 -uroot -P3307 mysql> SELECT avg(number) FROM numbers(1000000000); +-------------+ | avg(number) | +-------------+ | 499999999.5 | +-------------+ 1 row in set (0.05 sec) ClickHouse Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. $ clickhouse client --host 0.0.0.0 --port 9001 databend :) SELECT avg(number) FROM numbers(1000000000); SELECT avg(number) FROM numbers(1000000000) Query id: 89e06fba-1d57-464d-bfb0-238df85a2e66 \u250c\u2500avg(number)\u2500\u2510 \u2502 499999999.5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 rows in set. Elapsed: 0.062 sec. Processed 1.00 billion rows, 8.01 GB (16.16 billion rows/s., 129.38 GB/s.)","title":"CLI"},{"location":"cli/cli/#1-install","text":"curl -fsS https://repo.databend.rs/databend/install-bendctl.sh | bash export PATH=\"${HOME}/.databend/bin:${PATH}\"","title":"1. Install"},{"location":"cli/cli/#2-setting-up-a-cluster","text":"$ bendctl [local] [sql]> \\admin Mode switched to admin mode [local] [admin]> cluster create [ok] databend cluster precheck passed! [ok] \ud83d\udc4f successfully started meta service with rpc endpoint 127.0.0.1:9191 [ok] local data would be stored in /home/ubuntu/.databend/local/data [ok] \ud83d\udc4f successfully started query service. [ok] \u2705 To run queries through RESTful api, run: bendctl query 'SQL statement' [ok] \u2705 For example: bendctl query 'SELECT sum(number), avg(number) FROM numbers(100);' [ok] \u2705 To process mysql queries, run: mysql -h 127.0.0.1 -P 3307 -uroot [ok] \u2705 To process clickhouse queries, run: clickhouse client --host 127.0.0.1 --port 9000 --user root [local] [admin]>","title":"2. Setting up a cluster"},{"location":"cli/cli/#3-query-example","text":"bendctl Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. [local] [admin]> \\sql Mode switched to SQL query mode [local] [sql]> SELECT avg(number) FROM numbers(1000000000); +-------------+ | avg(number) | +-------------+ | 499999999.5 | +-------------+ [ok] read rows: 1,000,000,000, read bytes: 8.00 GB, rows/sec: 1,259,445,843 (rows/sec), bytes/sec: 10.07556675 (GB/sec) [local] [sql]> MySQL Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. $ mysql -h127.0.0.1 -uroot -P3307 mysql> SELECT avg(number) FROM numbers(1000000000); +-------------+ | avg(number) | +-------------+ | 499999999.5 | +-------------+ 1 row in set (0.05 sec) ClickHouse Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. $ clickhouse client --host 0.0.0.0 --port 9001 databend :) SELECT avg(number) FROM numbers(1000000000); SELECT avg(number) FROM numbers(1000000000) Query id: 89e06fba-1d57-464d-bfb0-238df85a2e66 \u250c\u2500avg(number)\u2500\u2510 \u2502 499999999.5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 rows in set. Elapsed: 0.062 sec. Processed 1.00 billion rows, 8.01 GB (16.16 billion rows/s., 129.38 GB/s.)","title":"3. Query Example"},{"location":"development/coding-guidelines/","text":"This document describes the coding guidelines for the Databend Rust codebase. Code formatting \u00b6 All code formatting is enforced with rustfmt with a project-specific configuration. Below is an example command: $ make fmt Code analysis \u00b6 Clippy is used to catch common mistakes and is run as a part of continuous integration. Before submitting your code for review, you can run lint: $ make lint Code documentation \u00b6 Any public fields, functions, and methods should be documented with Rustdoc . Please follow the conventions as detailed below for modules, structs, enums, and functions. The single line is used as a preview when navigating Rustdoc. As an example, see the 'Structs' and 'Enums' sections in the collections Rustdoc. /// [Single line] One line summary description /// /// [Longer description] Multiple lines, inline code /// examples, invariants, purpose, usage, etc. [ Attributes ] If attributes exist , add after Rustdoc Example below: /// Represents (x, y) of a 2-dimensional grid /// /// A line is defined by 2 instances. /// A plane is defined by 3 instances. #[repr(C)] struct Point { x : i32 , y : i32 , } Testing \u00b6 Unit tests $ make unit-test Stateless tests $ make stateless-test","title":"Coding Guideline"},{"location":"development/coding-guidelines/#code-formatting","text":"All code formatting is enforced with rustfmt with a project-specific configuration. Below is an example command: $ make fmt","title":"Code formatting"},{"location":"development/coding-guidelines/#code-analysis","text":"Clippy is used to catch common mistakes and is run as a part of continuous integration. Before submitting your code for review, you can run lint: $ make lint","title":"Code analysis"},{"location":"development/coding-guidelines/#code-documentation","text":"Any public fields, functions, and methods should be documented with Rustdoc . Please follow the conventions as detailed below for modules, structs, enums, and functions. The single line is used as a preview when navigating Rustdoc. As an example, see the 'Structs' and 'Enums' sections in the collections Rustdoc. /// [Single line] One line summary description /// /// [Longer description] Multiple lines, inline code /// examples, invariants, purpose, usage, etc. [ Attributes ] If attributes exist , add after Rustdoc Example below: /// Represents (x, y) of a 2-dimensional grid /// /// A line is defined by 2 instances. /// A plane is defined by 3 instances. #[repr(C)] struct Point { x : i32 , y : i32 , }","title":"Code documentation"},{"location":"development/coding-guidelines/#testing","text":"Unit tests $ make unit-test Stateless tests $ make stateless-test","title":"Testing"},{"location":"development/contributing/","text":"Contributing to Databend \u00b6 Databend is an open project, and you can contribute to it in many ways. You can help with ideas, code, or documentation. We appreciate any efforts that help us to make the project better. Our goal is to make contributing to the Databend project easy and transparent. Thank you. Notes Once the code been merged, your name will be stoned in the system.contributors table forever. SELECT * FROM system.contributors Contributing \u00b6 To contribute to Databend, ensure that you have the latest version of the codebase, run the following: $ git clone https://github.com/datafuselabs/databend $ cd databend $ make setup $ make test Coding Guidelines \u00b6 For detailed guidance on how to contribute to the codebase refer to Coding Guidelines . Documentation \u00b6 All developer documentation is published on the Databend developer site, databend.rs . Pull Requests \u00b6 To submit your pull request: Fork the databend repo and create your branch from main . Open an regular issue for binding the pull request. Submit a draft pull requests , tag your work in progress. If you have added code that should be tested, add unit tests. Verify and ensure that the test suites passes, make test . Make sure your code passes both linters, make lint . Change the status to \u201cReady for review\u201d. Watch out the replies from the @datafuse-bots , she will be your guide. Code of Conduct \u00b6 Please refer to the Code of Conduct , which describes the expectations for interactions within the community. Issues \u00b6 Databend uses GitHub issues to track bugs. Please include necessary information and instructions to reproduce your issue.","title":"Contributing"},{"location":"development/contributing/#contributing-to-databend","text":"Databend is an open project, and you can contribute to it in many ways. You can help with ideas, code, or documentation. We appreciate any efforts that help us to make the project better. Our goal is to make contributing to the Databend project easy and transparent. Thank you. Notes Once the code been merged, your name will be stoned in the system.contributors table forever. SELECT * FROM system.contributors","title":"Contributing to Databend"},{"location":"development/contributing/#contributing","text":"To contribute to Databend, ensure that you have the latest version of the codebase, run the following: $ git clone https://github.com/datafuselabs/databend $ cd databend $ make setup $ make test","title":"Contributing"},{"location":"development/contributing/#coding-guidelines","text":"For detailed guidance on how to contribute to the codebase refer to Coding Guidelines .","title":"Coding Guidelines"},{"location":"development/contributing/#documentation","text":"All developer documentation is published on the Databend developer site, databend.rs .","title":"Documentation"},{"location":"development/contributing/#pull-requests","text":"To submit your pull request: Fork the databend repo and create your branch from main . Open an regular issue for binding the pull request. Submit a draft pull requests , tag your work in progress. If you have added code that should be tested, add unit tests. Verify and ensure that the test suites passes, make test . Make sure your code passes both linters, make lint . Change the status to \u201cReady for review\u201d. Watch out the replies from the @datafuse-bots , she will be your guide.","title":"Pull Requests"},{"location":"development/contributing/#code-of-conduct","text":"Please refer to the Code of Conduct , which describes the expectations for interactions within the community.","title":"Code of Conduct"},{"location":"development/contributing/#issues","text":"Databend uses GitHub issues to track bugs. Please include necessary information and instructions to reproduce your issue.","title":"Issues"},{"location":"development/how-to-write-aggregate-functions/","text":"How to write aggregate functions \u00b6 Databend allows us to write custom aggregate functions through rust code. It's not an easy way because you need to be a rustacean first. Databend has a plan to support writing UDAFs in other languages(like js, web assembly) in the future. In this section we will talk about how to write aggregate functions in Databend. AggregateFunction trait introduction \u00b6 All aggregate functions implement AggregateFunction trait, and we register them into a global static factory named FactoryFuncRef , the factory is just an index map and the key is the name of the aggregate function. Note Function name in Databend is case-insensitive. pub trait AggregateFunction : fmt :: Display + Sync + Send { fn name ( & self ) -> & str ; fn return_type ( & self ) -> Result < DataType > ; fn nullable ( & self , _input_schema : & DataSchema ) -> Result < bool > ; fn init_state ( & self , place : StateAddr ); fn state_layout ( & self ) -> Layout ; fn accumulate ( & self , _place : StateAddr , _arrays : & [ Series ], _input_rows : usize ) -> Result < () > ; fn accumulate_keys ( & self , _places : & [ StateAddr ], _offset : usize , _arrays : & [ Series ], _input_rows : usize , ) -> Result < () > ; fn serialize ( & self , _place : StateAddr , _writer : & mut BytesMut ) -> Result < () > ; fn deserialize ( & self , _place : StateAddr , _reader : & mut & [ u8 ]) -> Result < () > ; fn merge ( & self , _place : StateAddr , _rhs : StateAddr ) -> Result < () > ; fn merge_result ( & self , _place : StateAddr ) -> Result < DataValue > ; } Understand the functions \u00b6 The function name indicates the name of this function, such as sum , min . The function return_type indicates the return type of the function, it may vary with different arguments, such as sum(int8) -> int64 , sum(uint8) -> uint64 , sum(float64) -> float64 . The function nullable indicates whether the return_type is nullable or not. Before we start to introduce the function init_state , let's ask a question first: what's aggregate function state? It indicates the temporary results of an aggregate function. Because an aggregate function accumulates data in columns block by block and there will be some intermediate results after the aggregation. Therefore, the state must be mergeable, serializable. For example, in the avg aggregate function, we can represent the state like: struct AggregateAvgState<T: BinarySer + BinaryDe> { pub value: T, pub count: u64, } The function init_state initializes the aggregate function state, we ensure the memory is already allocated, and we just need to initial the state with the initial value. The function state_layout indicates the memory layout of the state. The function accumulate is used in aggregation with a single batch, which means the whole block can be aggregated in a single state, no other keys. The SQL query, which applies aggregation without group-by columns, will hit this function. Noted that the argument _arrays is the function arguments, we can safely get the array by index without index bound check because we must validate the argument numbers and types in function constructor. The _input_rows is the rows of the current block, and it may be useful when the _arrays is empty, e.g., count() function. The function accumulate_keys is similar to accumulate, but we must take into consideration the keys and offsets, for which each key represents a unique memory address named place. The function serialize serializes state into binary. The function deserialize deserializes state from binary. The function merge , can be used to merge other state into current state. The function merge_result , can be used to represent the aggregate function state into one-row field. Example \u00b6 Let's take an example of aggregate function sum . It's declared as AggregateSumFunction<T, SumT> , we can accept varying integer types like u8 , i8 . T and SumT is logic types which implement DFPrimitiveType . e.g., T is u8 and SumT must be u64 . Also, we can dispatch it using macros by matching the types of the arguments. Take a look at the with_match_primitive_type to understand the dispatch macros. The AggregateSumState will be struct AggregateSumState<T> { pub value: Option<T>, } The generic T is from SumT , the Option<T> can return null if nothing is passed into this function. Let's take into the function accumulate_keys , because this is the only function that a little hard to understand in this case. The places is the memory address of the first state in this row, so we can get the address of AggregateSumState<T> using places[row] + offset , then using place.get::<AggregateSumState<SumT>>() to get the value of the corresponding state. Since we already know the array type of this function, we can safely cast it to arrow's PrimitiveArray<T> , here we make two branches to reduce the branch prediction of CPU, null and no_null . In no_null case, we just iterate the array and apply the sum , this is good for compiler to optimize the codes into vectorized codes. Ok, this example is pretty easy. If you already read this, you may have the ability to write a new function. Refer to other examples \u00b6 As you see, adding a new aggregate function in Databend is not as hard as you think. Before you start to add one, please refer to other aggregate function examples, such as min , count , max , avg . Testing \u00b6 To be a good engineer, don't forget to test your codes, please add unit tests and stateless tests after you finish the new aggregate functions. Summary \u00b6 We welcome all community users to contribute more powerful functions to Databend. If you find any problems, feel free to open an issue in GitHub, we will use our best efforts to help you.","title":"How to write aggregate functions"},{"location":"development/how-to-write-aggregate-functions/#how-to-write-aggregate-functions","text":"Databend allows us to write custom aggregate functions through rust code. It's not an easy way because you need to be a rustacean first. Databend has a plan to support writing UDAFs in other languages(like js, web assembly) in the future. In this section we will talk about how to write aggregate functions in Databend.","title":"How to write aggregate functions"},{"location":"development/how-to-write-aggregate-functions/#aggregatefunction-trait-introduction","text":"All aggregate functions implement AggregateFunction trait, and we register them into a global static factory named FactoryFuncRef , the factory is just an index map and the key is the name of the aggregate function. Note Function name in Databend is case-insensitive. pub trait AggregateFunction : fmt :: Display + Sync + Send { fn name ( & self ) -> & str ; fn return_type ( & self ) -> Result < DataType > ; fn nullable ( & self , _input_schema : & DataSchema ) -> Result < bool > ; fn init_state ( & self , place : StateAddr ); fn state_layout ( & self ) -> Layout ; fn accumulate ( & self , _place : StateAddr , _arrays : & [ Series ], _input_rows : usize ) -> Result < () > ; fn accumulate_keys ( & self , _places : & [ StateAddr ], _offset : usize , _arrays : & [ Series ], _input_rows : usize , ) -> Result < () > ; fn serialize ( & self , _place : StateAddr , _writer : & mut BytesMut ) -> Result < () > ; fn deserialize ( & self , _place : StateAddr , _reader : & mut & [ u8 ]) -> Result < () > ; fn merge ( & self , _place : StateAddr , _rhs : StateAddr ) -> Result < () > ; fn merge_result ( & self , _place : StateAddr ) -> Result < DataValue > ; }","title":"AggregateFunction trait introduction"},{"location":"development/how-to-write-aggregate-functions/#understand-the-functions","text":"The function name indicates the name of this function, such as sum , min . The function return_type indicates the return type of the function, it may vary with different arguments, such as sum(int8) -> int64 , sum(uint8) -> uint64 , sum(float64) -> float64 . The function nullable indicates whether the return_type is nullable or not. Before we start to introduce the function init_state , let's ask a question first: what's aggregate function state? It indicates the temporary results of an aggregate function. Because an aggregate function accumulates data in columns block by block and there will be some intermediate results after the aggregation. Therefore, the state must be mergeable, serializable. For example, in the avg aggregate function, we can represent the state like: struct AggregateAvgState<T: BinarySer + BinaryDe> { pub value: T, pub count: u64, } The function init_state initializes the aggregate function state, we ensure the memory is already allocated, and we just need to initial the state with the initial value. The function state_layout indicates the memory layout of the state. The function accumulate is used in aggregation with a single batch, which means the whole block can be aggregated in a single state, no other keys. The SQL query, which applies aggregation without group-by columns, will hit this function. Noted that the argument _arrays is the function arguments, we can safely get the array by index without index bound check because we must validate the argument numbers and types in function constructor. The _input_rows is the rows of the current block, and it may be useful when the _arrays is empty, e.g., count() function. The function accumulate_keys is similar to accumulate, but we must take into consideration the keys and offsets, for which each key represents a unique memory address named place. The function serialize serializes state into binary. The function deserialize deserializes state from binary. The function merge , can be used to merge other state into current state. The function merge_result , can be used to represent the aggregate function state into one-row field.","title":"Understand the functions"},{"location":"development/how-to-write-aggregate-functions/#example","text":"Let's take an example of aggregate function sum . It's declared as AggregateSumFunction<T, SumT> , we can accept varying integer types like u8 , i8 . T and SumT is logic types which implement DFPrimitiveType . e.g., T is u8 and SumT must be u64 . Also, we can dispatch it using macros by matching the types of the arguments. Take a look at the with_match_primitive_type to understand the dispatch macros. The AggregateSumState will be struct AggregateSumState<T> { pub value: Option<T>, } The generic T is from SumT , the Option<T> can return null if nothing is passed into this function. Let's take into the function accumulate_keys , because this is the only function that a little hard to understand in this case. The places is the memory address of the first state in this row, so we can get the address of AggregateSumState<T> using places[row] + offset , then using place.get::<AggregateSumState<SumT>>() to get the value of the corresponding state. Since we already know the array type of this function, we can safely cast it to arrow's PrimitiveArray<T> , here we make two branches to reduce the branch prediction of CPU, null and no_null . In no_null case, we just iterate the array and apply the sum , this is good for compiler to optimize the codes into vectorized codes. Ok, this example is pretty easy. If you already read this, you may have the ability to write a new function.","title":"Example"},{"location":"development/how-to-write-aggregate-functions/#refer-to-other-examples","text":"As you see, adding a new aggregate function in Databend is not as hard as you think. Before you start to add one, please refer to other aggregate function examples, such as min , count , max , avg .","title":"Refer to other examples"},{"location":"development/how-to-write-aggregate-functions/#testing","text":"To be a good engineer, don't forget to test your codes, please add unit tests and stateless tests after you finish the new aggregate functions.","title":"Testing"},{"location":"development/how-to-write-aggregate-functions/#summary","text":"We welcome all community users to contribute more powerful functions to Databend. If you find any problems, feel free to open an issue in GitHub, we will use our best efforts to help you.","title":"Summary"},{"location":"development/profiling/","text":"flame graph \u00b6 Open http://localhost:8080/debug/pprof/profile?seconds=5 in browser, Databend debug api will response the svg of the flame graph to the client. go pprof tool \u00b6 go tool pprof http://localhost:8080/debug/pprof/profile?seconds=20 Fetching profile over HTTP from http://localhost:8080/debug/pprof/profile?seconds=20 Saved profile in /home/bohu/pprof/pprof.cpu.007.pb.gz Type: cpu Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top Showing nodes accounting for 5011, 100% of 5011 total Dropped 248 nodes (cum <= 25) Showing top 10 nodes out of 204 flat flat% sum% cum cum% 5011 100% 100% 5011 100% backtrace::backtrace::libunwind::trace 0 0% 100% 162 3.23% <&alloc::vec::Vec<T,A> as core::iter::traits::collect::IntoIterator>::into_iter 0 0% 100% 45 0.9% <&mut I as core::iter::traits::iterator::Iterator>::next 0 0% 100% 77 1.54% <[A] as core::slice::cmp::SlicePartialEq<B>>::equal 0 0% 100% 35 0.7% <[u8; 8] as ahash::convert::Convert<u64>>::convert 0 0% 100% 199 3.97% <[u8] as ahash::convert::ReadFromSlice>::read_last_u64 0 0% 100% 73 1.46% <[u8] as ahash::convert::ReadFromSlice>::read_last_u64::as_array 0 0% 100% 220 4.39% <[u8] as ahash::convert::ReadFromSlice>::read_u64 0 0% 100% 701 13.99% <ahash::fallback_hash::AHasher as core::hash::Hasher>::write 0 0% 100% 26 0.52% <ahash::random_state::RandomState as core::hash::BuildHasher>::build_hash Or go tool pprof -http=0.0.0.0:8081 $HOME/pprof/pprof.cpu.007.pb.gz","title":"Profling"},{"location":"development/profiling/#flame-graph","text":"Open http://localhost:8080/debug/pprof/profile?seconds=5 in browser, Databend debug api will response the svg of the flame graph to the client.","title":"flame graph"},{"location":"development/profiling/#go-pprof-tool","text":"go tool pprof http://localhost:8080/debug/pprof/profile?seconds=20 Fetching profile over HTTP from http://localhost:8080/debug/pprof/profile?seconds=20 Saved profile in /home/bohu/pprof/pprof.cpu.007.pb.gz Type: cpu Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top Showing nodes accounting for 5011, 100% of 5011 total Dropped 248 nodes (cum <= 25) Showing top 10 nodes out of 204 flat flat% sum% cum cum% 5011 100% 100% 5011 100% backtrace::backtrace::libunwind::trace 0 0% 100% 162 3.23% <&alloc::vec::Vec<T,A> as core::iter::traits::collect::IntoIterator>::into_iter 0 0% 100% 45 0.9% <&mut I as core::iter::traits::iterator::Iterator>::next 0 0% 100% 77 1.54% <[A] as core::slice::cmp::SlicePartialEq<B>>::equal 0 0% 100% 35 0.7% <[u8; 8] as ahash::convert::Convert<u64>>::convert 0 0% 100% 199 3.97% <[u8] as ahash::convert::ReadFromSlice>::read_last_u64 0 0% 100% 73 1.46% <[u8] as ahash::convert::ReadFromSlice>::read_last_u64::as_array 0 0% 100% 220 4.39% <[u8] as ahash::convert::ReadFromSlice>::read_u64 0 0% 100% 701 13.99% <ahash::fallback_hash::AHasher as core::hash::Hasher>::write 0 0% 100% 26 0.52% <ahash::random_state::RandomState as core::hash::BuildHasher>::build_hash Or go tool pprof -http=0.0.0.0:8081 $HOME/pprof/pprof.cpu.007.pb.gz","title":"go pprof tool"},{"location":"development/roadmap/","text":"Databend roadmap 2021. Notes Sync from the #476 Main tasks \u00b6 1. Query task \u00b6 Task Status Release Target Comments Cloud Re-architected track #1408 DONE v0.5 HTTP API #2241 DONE v0.5 fuse table #1780 PROGRESS v0.5 2. Distributed Query task \u00b6 Task Status Release Target Comments Query cluster track #747 PROGRESS v0.6 @zhang2014 Functions track #758 PROGRESS @sundy-li Queries track #765 PROGRESS @zhang2014 3. Observability task \u00b6 Task Status Release Target Comments Observability track #795 PROGRESS v0.6 @BohuTANG 4. Test infra task \u00b6 Task Status Release Target Comments Test Infra track #796 DONE v0.4 @ZhiHanZ 5. RBAC task \u00b6 Task Status Release Target Comments RBAC track #894 PROGRESS v0.6 Access Control and Account Management 6. Optimizer task \u00b6 Task Status Release Target Comments Cost based optimizer(CBO) track #915 PLANNING Table statistics and CBO Refactor SQL Parser #1218 PROGRESS 7. Deployment task \u00b6 Task Status Release Target Comments databend cli #938 PROGRESS v0.5 All-in-one tool for setting up, managing with Databend Experimental and interns tasks \u00b6 Task Status Release Target Comments Hash method in ClickHouse way #754 DONE Join #559 PLANNING @leiysky Online Playgroud PLANNING User can try the demo on the databend.rs website Window functions PLANNING Limited support for transactions PLANNING Tuple functions PLANNING Reference: https://clickhouse.tech/docs/en/sql-reference/functions/tuple-functions/ Array functions PLANNING Reference: https://clickhouse.tech/docs/en/sql-reference/functions/array-functions/ Lambda functions PLANNING Reference: https://clickhouse.tech/docs/en/sql-reference/functions/#higher-order-functions Compile aggregate functions(JIT) PLANNING Reference: https://github.com/ClickHouse/ClickHouse/pull/24789","title":"Roadmap"},{"location":"development/roadmap/#main-tasks","text":"","title":"Main tasks"},{"location":"development/roadmap/#1-query-task","text":"Task Status Release Target Comments Cloud Re-architected track #1408 DONE v0.5 HTTP API #2241 DONE v0.5 fuse table #1780 PROGRESS v0.5","title":"1. Query task"},{"location":"development/roadmap/#2-distributed-query-task","text":"Task Status Release Target Comments Query cluster track #747 PROGRESS v0.6 @zhang2014 Functions track #758 PROGRESS @sundy-li Queries track #765 PROGRESS @zhang2014","title":"2. Distributed Query task"},{"location":"development/roadmap/#3-observability-task","text":"Task Status Release Target Comments Observability track #795 PROGRESS v0.6 @BohuTANG","title":"3. Observability task"},{"location":"development/roadmap/#4-test-infra-task","text":"Task Status Release Target Comments Test Infra track #796 DONE v0.4 @ZhiHanZ","title":"4. Test infra task"},{"location":"development/roadmap/#5-rbac-task","text":"Task Status Release Target Comments RBAC track #894 PROGRESS v0.6 Access Control and Account Management","title":"5. RBAC task"},{"location":"development/roadmap/#6-optimizer-task","text":"Task Status Release Target Comments Cost based optimizer(CBO) track #915 PLANNING Table statistics and CBO Refactor SQL Parser #1218 PROGRESS","title":"6. Optimizer task"},{"location":"development/roadmap/#7-deployment-task","text":"Task Status Release Target Comments databend cli #938 PROGRESS v0.5 All-in-one tool for setting up, managing with Databend","title":"7. Deployment task"},{"location":"development/roadmap/#experimental-and-interns-tasks","text":"Task Status Release Target Comments Hash method in ClickHouse way #754 DONE Join #559 PLANNING @leiysky Online Playgroud PLANNING User can try the demo on the databend.rs website Window functions PLANNING Limited support for transactions PLANNING Tuple functions PLANNING Reference: https://clickhouse.tech/docs/en/sql-reference/functions/tuple-functions/ Array functions PLANNING Reference: https://clickhouse.tech/docs/en/sql-reference/functions/array-functions/ Lambda functions PLANNING Reference: https://clickhouse.tech/docs/en/sql-reference/functions/#higher-order-functions Compile aggregate functions(JIT) PLANNING Reference: https://github.com/ClickHouse/ClickHouse/pull/24789","title":"Experimental and interns tasks"},{"location":"development/tracing/","text":"Tracing In Databend \u00b6 Databend using Rust's tracing ecosystem tokio-tracing to do log and profile. Databend default log level is INFO . Enable Tracing \u00b6 QUERY_LOG_LEVEL=\"DEBUG\" ./databend-query If we want to track the execution of a query: set max_threads=1; select sum(number+1)+1 from numbers(10000) where number>0 group by number%3; Tracing log: Tracing [2021-06-10T08:40:36Z DEBUG clickhouse_srv::cmd] Got packet Query(QueryRequest { query_id: \"bac2b254-6245-4cae-910d-3e5e979c8b68\", client_info: QueryClientInfo { query_kind: 1, initial_user: \"\", initial_query_id: \"\", initial_address: \"0.0.0.0:0\", interface: 1, os_user: \"bohu\", client_hostname: \"thinkpad\", client_name: \"ClickHouse \", client_version_major: 21, client_version_minor: 4, client_version_patch: 6, client_revision: 54447, http_method: 0, http_user_agent: \"\", quota_key: \"\" }, stage: 2, compression: 1, query: \"select sum(number+1)+1 from numbers(10000) where number>0 group by number%3;\" }) Jun 10 16:40:36.131 DEBUG ThreadId(16) databend_query::sql::plan_parser: query=\"select sum(number+1)+1 from numbers(10000) where number>0 group by number%3;\" [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Identifier(Ident { value: \"number\", quote_style: None }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Plus [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 30 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"1\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() RParen [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() RParen [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Function(Function { name: ObjectName([Ident { value: \"sum\", quote_style: None }]), args: [Unnamed(BinaryOp { left: Identifier(Ident { value: \"number\", quote_style: None }), op: Plus, right: Value(Number(\"1\", false)) })], over: None, distinct: false }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Plus [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 30 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"1\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"from\", quote_style: None, keyword: FROM }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"from\", quote_style: None, keyword: FROM }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"10000\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() RParen [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Identifier(Ident { value: \"number\", quote_style: None }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Gt [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 20 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"0\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"group\", quote_style: None, keyword: GROUP }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"group\", quote_style: None, keyword: GROUP }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Identifier(Ident { value: \"number\", quote_style: None }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Mod [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 40 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"3\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() SemiColon [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() SemiColon [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 Jun 10 16:40:36.135 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: new Jun 10 16:40:36.136 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: enter Jun 10 16:40:36.136 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: new Jun 10 16:40:36.136 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: enter Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: exit Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: close time.busy=2.65ms time.idle=457\u00b5s Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: exit Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: close time.busy=3.57ms time.idle=453\u00b5s Jun 10 16:40:36.140 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: new Jun 10 16:40:36.141 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: enter Jun 10 16:40:36.141 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: Before ProjectionPushDown Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.142 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: After ProjectionPushDown Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.142 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: Before Scatters Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.143 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: After Scatters Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: new Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: enter Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: exit Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: close time.busy=145\u00b5s time.idle=264\u00b5s Jun 10 16:40:36.144 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: new Jun 10 16:40:36.144 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: enter Jun 10 16:40:36.144 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: Received plan: Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.145 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: Pipeline: ProjectionTransform \u00d7 1 processor ExpressionTransform \u00d7 1 processor GroupByFinalTransform \u00d7 1 processor GroupByPartialTransform \u00d7 1 processor ExpressionTransform \u00d7 1 processor FilterTransform \u00d7 1 processor SourceTransform \u00d7 1 processor Jun 10 16:40:36.145 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: exit Jun 10 16:40:36.145 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: close time.busy=1.07ms time.idle=215\u00b5s Jun 10 16:40:36.145 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_projection: execute... Jun 10 16:40:36.145 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_final: execute... Jun 10 16:40:36.146 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_partial: execute... Jun 10 16:40:36.146 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_source: execute, table:system.numbers, is_remote:false... Jun 10 16:40:36.148 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_filter: execute... Jun 10 16:40:36.148 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_expression_executor: (filter executor) execute, actions: [Input(ActionInput { name: \"number\", return_type: UInt64 }), Constant(ActionConstant { name: \"0\", value: 0 }), Function(ActionFunction { name: \"(number > 0)\", func_name: \">\", return_type: Boolean, is_aggregated: false, arg_names: [\"number\", \"0\"], arg_types: [UInt64, UInt64], arg_fields: [] })] Jun 10 16:40:36.150 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_filter: Filter cost: 1.678104ms Jun 10 16:40:36.150 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_expression_executor: (expression executor) execute, actions: [Input(ActionInput { name: \"number\", return_type: UInt64 }), Constant(ActionConstant { name: \"3\", value: 3 }), Function(ActionFunction { name: \"(number % 3)\", func_name: \"%\", return_type: UInt64, is_aggregated: false, arg_names: [\"number\", \"3\"], arg_types: [UInt64, UInt64], arg_fields: [] }), Input(ActionInput { name: \"number\", return_type: UInt64 }), Constant(ActionConstant { name: \"1\", value: 1 }), Function(ActionFunction { name: \"(number + 1)\", func_name: \"+\", return_type: UInt64, is_aggregated: false, arg_names: [\"number\", \"1\"], arg_types: [UInt64, UInt64], arg_fields: [] })] Jun 10 16:40:36.165 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_partial: Group by partial cost: 18.822193ms Jun 10 16:40:36.166 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_final: Group by final cost: 20.170851ms Jun 10 16:40:36.167 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: exit Jun 10 16:40:36.167 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: close time.busy=26.1ms time.idle=592\u00b5s Jun 10 16:40:36.167 DEBUG ThreadId(309) databend_query::pipelines::transforms::transform_expression_executor: (expression executor) execute, actions: [Input(ActionInput { name: \"sum((number + 1))\", return_type: UInt64 }), Constant(ActionConstant { name: \"1\", value: 1 }), Function(ActionFunction { name: \"(sum((number + 1)) + 1)\", func_name: \"+\", return_type: UInt64, is_aggregated: false, arg_names: [\"sum((number + 1))\", \"1\"], arg_types: [UInt64, UInt64], arg_fields: [] })] Jun 10 16:40:36.168 DEBUG ThreadId(309) databend_query::pipelines::transforms::transform_expression_executor: (projection executor) execute, actions: [Input(ActionInput { name: \"(sum((number + 1)) + 1)\", return_type: UInt64 })] Jun 10 16:40:36.168 DEBUG ThreadId(309) databend_query::pipelines::transforms::transform_projection: Projection cost: 241.864\u00b5s","title":"Tracing"},{"location":"development/tracing/#tracing-in-databend","text":"Databend using Rust's tracing ecosystem tokio-tracing to do log and profile. Databend default log level is INFO .","title":"Tracing In Databend"},{"location":"development/tracing/#enable-tracing","text":"QUERY_LOG_LEVEL=\"DEBUG\" ./databend-query If we want to track the execution of a query: set max_threads=1; select sum(number+1)+1 from numbers(10000) where number>0 group by number%3; Tracing log: Tracing [2021-06-10T08:40:36Z DEBUG clickhouse_srv::cmd] Got packet Query(QueryRequest { query_id: \"bac2b254-6245-4cae-910d-3e5e979c8b68\", client_info: QueryClientInfo { query_kind: 1, initial_user: \"\", initial_query_id: \"\", initial_address: \"0.0.0.0:0\", interface: 1, os_user: \"bohu\", client_hostname: \"thinkpad\", client_name: \"ClickHouse \", client_version_major: 21, client_version_minor: 4, client_version_patch: 6, client_revision: 54447, http_method: 0, http_user_agent: \"\", quota_key: \"\" }, stage: 2, compression: 1, query: \"select sum(number+1)+1 from numbers(10000) where number>0 group by number%3;\" }) Jun 10 16:40:36.131 DEBUG ThreadId(16) databend_query::sql::plan_parser: query=\"select sum(number+1)+1 from numbers(10000) where number>0 group by number%3;\" [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Identifier(Ident { value: \"number\", quote_style: None }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Plus [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 30 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"1\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() RParen [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() RParen [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Function(Function { name: ObjectName([Ident { value: \"sum\", quote_style: None }]), args: [Unnamed(BinaryOp { left: Identifier(Ident { value: \"number\", quote_style: None }), op: Plus, right: Value(Number(\"1\", false)) })], over: None, distinct: false }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Plus [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 30 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"1\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"from\", quote_style: None, keyword: FROM }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"from\", quote_style: None, keyword: FROM }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"10000\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() RParen [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Identifier(Ident { value: \"number\", quote_style: None }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Gt [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 20 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"0\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"group\", quote_style: None, keyword: GROUP }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Word(Word { value: \"group\", quote_style: None, keyword: GROUP }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Identifier(Ident { value: \"number\", quote_style: None }) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() Mod [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 40 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] parsing expr [2021-06-10T08:40:36Z DEBUG sqlparser::parser] prefix: Value(Number(\"3\", false)) [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() SemiColon [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 [2021-06-10T08:40:36Z DEBUG sqlparser::parser] get_next_precedence() SemiColon [2021-06-10T08:40:36Z DEBUG sqlparser::parser] next precedence: 0 Jun 10 16:40:36.135 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: new Jun 10 16:40:36.136 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: enter Jun 10 16:40:36.136 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: new Jun 10 16:40:36.136 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: enter Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: exit Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan:select_to_plan: databend_query::sql::plan_parser: close time.busy=2.65ms time.idle=457\u00b5s Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: exit Jun 10 16:40:36.139 INFO ThreadId(16) sql_statement_to_plan: databend_query::sql::plan_parser: close time.busy=3.57ms time.idle=453\u00b5s Jun 10 16:40:36.140 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: new Jun 10 16:40:36.141 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: enter Jun 10 16:40:36.141 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: Before ProjectionPushDown Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.142 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: After ProjectionPushDown Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.142 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: Before Scatters Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.143 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::optimizers::optimizer: After Scatters Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: new Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: enter Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: exit Jun 10 16:40:36.143 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:reschedule: databend_query::interpreters::plan_scheduler: close time.busy=145\u00b5s time.idle=264\u00b5s Jun 10 16:40:36.144 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: new Jun 10 16:40:36.144 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: enter Jun 10 16:40:36.144 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: Received plan: Projection: (sum((number + 1)) + 1):UInt64 Expression: (sum((number + 1)) + 1):UInt64 (Before Projection) AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum((number + 1))]] Expression: (number % 3):UInt8, (number + 1):UInt64 (Before GroupBy) Filter: (number > 0) ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10000, read_bytes: 80000] Jun 10 16:40:36.145 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: Pipeline: ProjectionTransform \u00d7 1 processor ExpressionTransform \u00d7 1 processor GroupByFinalTransform \u00d7 1 processor GroupByPartialTransform \u00d7 1 processor ExpressionTransform \u00d7 1 processor FilterTransform \u00d7 1 processor SourceTransform \u00d7 1 processor Jun 10 16:40:36.145 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: exit Jun 10 16:40:36.145 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}:build: databend_query::pipelines::processors::pipeline_builder: close time.busy=1.07ms time.idle=215\u00b5s Jun 10 16:40:36.145 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_projection: execute... Jun 10 16:40:36.145 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_final: execute... Jun 10 16:40:36.146 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_partial: execute... Jun 10 16:40:36.146 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_source: execute, table:system.numbers, is_remote:false... Jun 10 16:40:36.148 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_filter: execute... Jun 10 16:40:36.148 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_expression_executor: (filter executor) execute, actions: [Input(ActionInput { name: \"number\", return_type: UInt64 }), Constant(ActionConstant { name: \"0\", value: 0 }), Function(ActionFunction { name: \"(number > 0)\", func_name: \">\", return_type: Boolean, is_aggregated: false, arg_names: [\"number\", \"0\"], arg_types: [UInt64, UInt64], arg_fields: [] })] Jun 10 16:40:36.150 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_filter: Filter cost: 1.678104ms Jun 10 16:40:36.150 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_expression_executor: (expression executor) execute, actions: [Input(ActionInput { name: \"number\", return_type: UInt64 }), Constant(ActionConstant { name: \"3\", value: 3 }), Function(ActionFunction { name: \"(number % 3)\", func_name: \"%\", return_type: UInt64, is_aggregated: false, arg_names: [\"number\", \"3\"], arg_types: [UInt64, UInt64], arg_fields: [] }), Input(ActionInput { name: \"number\", return_type: UInt64 }), Constant(ActionConstant { name: \"1\", value: 1 }), Function(ActionFunction { name: \"(number + 1)\", func_name: \"+\", return_type: UInt64, is_aggregated: false, arg_names: [\"number\", \"1\"], arg_types: [UInt64, UInt64], arg_fields: [] })] Jun 10 16:40:36.165 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_partial: Group by partial cost: 18.822193ms Jun 10 16:40:36.166 DEBUG ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::pipelines::transforms::transform_groupby_final: Group by final cost: 20.170851ms Jun 10 16:40:36.167 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: exit Jun 10 16:40:36.167 INFO ThreadId(309) execute{ctx.id=\"1c651744-3e73-4b94-9df0-dc031b73c626\"}: databend_query::interpreters::interpreter_select: close time.busy=26.1ms time.idle=592\u00b5s Jun 10 16:40:36.167 DEBUG ThreadId(309) databend_query::pipelines::transforms::transform_expression_executor: (expression executor) execute, actions: [Input(ActionInput { name: \"sum((number + 1))\", return_type: UInt64 }), Constant(ActionConstant { name: \"1\", value: 1 }), Function(ActionFunction { name: \"(sum((number + 1)) + 1)\", func_name: \"+\", return_type: UInt64, is_aggregated: false, arg_names: [\"sum((number + 1))\", \"1\"], arg_types: [UInt64, UInt64], arg_fields: [] })] Jun 10 16:40:36.168 DEBUG ThreadId(309) databend_query::pipelines::transforms::transform_expression_executor: (projection executor) execute, actions: [Input(ActionInput { name: \"(sum((number + 1)) + 1)\", return_type: UInt64 })] Jun 10 16:40:36.168 DEBUG ThreadId(309) databend_query::pipelines::transforms::transform_projection: Projection cost: 241.864\u00b5s","title":"Enable Tracing"},{"location":"overview/architecture/","text":"Design Overview \u00b6 Databend is an open source elastic and scalable cloud warehouse, it offers blazing fast query and combines elasticity, simplicity, low cost of the cloud, built to make the Data Cloud easy. Databend is intended for executing workloads with data stored in cloud storage systems, such as AWS S3 and Azure Blob Storage or others. We design Databend with the following key functionalities in mind: Elastic In Databend storage and compute resources can dynamically scale up and down on demand. Secure All data files and network traffic in Databend is encrypted end-to-end, and provider Role Based Access Control in SQL level. User-friendly Databend is an ANSI SQL compliant cloud warehouse, it is easy for data scientist and engineers to use. Cost-efficient Databend processes queries with high performance, and the user only pays for what is actually used. The picture above shows the high-level architecture of Databend, it consists of three components: meta service layer, and the decoupled compute and storage layers. Meta Service Layer \u00b6 The meta service is a layer to service multiple tenants. This layer implements a persistent key-value store to store each tenant's state. In current implementation, the meta service has many components: Metadata, which manages all metadata of databases, tables, clusters, the transaction, etc. Administration, which stores user info, user management, access control information, usage statistics, etc. Security, which performs authorization and authentication to protect the privacy of users' data. The code of Meta Service Layer mainly resides in the store directory of the repository. Compute Layer \u00b6 The compute layer is the layer to carry out computation for query processing. This layer may consist of many clusters, and each cluster may consist of many nodes. Each node is a compute unit, and is a collection of components: Planner The query planner builds an execution plan from the user's SQL statement and represents the query with different types of relational operators (such as Projection , Filter , Limit , etc.). For example: databend :) EXPLAIN SELECT number + 1 FROM numbers_mt(10) WHERE number > 8 LIMIT 2 \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Limit: 2 \u2502 \u2502 Projection: (number + 1):UInt64 \u2502 \u2502 Expression: (number + 1):UInt64 (Before Projection) \u2502 \u2502 Filter: (number > 8) \u2502 \u2502 ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Optimizer A rule based optimizer, some rules like predicate push down or pruning of unused columns. Processors A vector-based query execution pipeline, which is build by planner instructions. Each pipeline executor is a processor(such as SourceTransform , FilterTransform , etc.), it has zero or more inputs and zero or more outputs, and connected as a pipeline, it also can be distributed on multiple nodes judged by your query workload. For example: databend :) EXPLAIN PIPELINE SELECT number + 1 FROM numbers_mt(10000) WHERE number > 8 LIMIT 2 \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 LimitTransform \u00d7 1 processor \u2502 \u2502 Merge (ProjectionTransform \u00d7 16 processors) to (LimitTransform \u00d7 1) \u2502 \u2502 ProjectionTransform \u00d7 16 processors \u2502 \u2502 ExpressionTransform \u00d7 16 processors \u2502 \u2502 FilterTransform \u00d7 16 processors \u2502 \u2502 SourceTransform \u00d7 16 processors \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Cache The cache utilizes local SSDs for caching Data and Indexes based on the version within a node. The cache can be warmed up with different strategies: LOAD_ON_DEMAND - Load index or table data on demand(By Default). LOAD_INDEXES - Load indexes only. LOAD_ALL - Load full data and indexes. Node is the smallest unit of the compute layer, they can be registered as one cluster via namespace. Many clusters can attach the same database, so they can serve the query in parallel by different users. When you add new nodes to a cluster, the currently running computational tasks can be scaled(known as work-stealing) guarantee. The Compute Layer codes mainly in the query directory. Storage Layer \u00b6 Databend stores data in an efficient, columnar format as Parquet files. Each Parquet file is sorted by the primary key before being written to the underlying shared storage. For efficient pruning, Databend also creates indexes for each Parquet file: min_max.idx The index file stores the minimum and maximum value of this Parquet file. sparse.idx The index file store the mapping for every [N] records granularity. With the indexes, we can speed up the queries by reducing the I/O and CPU cost. Imagine that Parquet file f1 has min_max.idx of [3, 5) and Parquet file f2 has min_max.idx of [4, 6) in column x , if the query predicate is WHERE x < 4 , only f1 needs to be accessed and processed.","title":"Whitepapers"},{"location":"overview/architecture/#design-overview","text":"Databend is an open source elastic and scalable cloud warehouse, it offers blazing fast query and combines elasticity, simplicity, low cost of the cloud, built to make the Data Cloud easy. Databend is intended for executing workloads with data stored in cloud storage systems, such as AWS S3 and Azure Blob Storage or others. We design Databend with the following key functionalities in mind: Elastic In Databend storage and compute resources can dynamically scale up and down on demand. Secure All data files and network traffic in Databend is encrypted end-to-end, and provider Role Based Access Control in SQL level. User-friendly Databend is an ANSI SQL compliant cloud warehouse, it is easy for data scientist and engineers to use. Cost-efficient Databend processes queries with high performance, and the user only pays for what is actually used. The picture above shows the high-level architecture of Databend, it consists of three components: meta service layer, and the decoupled compute and storage layers.","title":"Design Overview"},{"location":"overview/architecture/#meta-service-layer","text":"The meta service is a layer to service multiple tenants. This layer implements a persistent key-value store to store each tenant's state. In current implementation, the meta service has many components: Metadata, which manages all metadata of databases, tables, clusters, the transaction, etc. Administration, which stores user info, user management, access control information, usage statistics, etc. Security, which performs authorization and authentication to protect the privacy of users' data. The code of Meta Service Layer mainly resides in the store directory of the repository.","title":"Meta Service Layer"},{"location":"overview/architecture/#compute-layer","text":"The compute layer is the layer to carry out computation for query processing. This layer may consist of many clusters, and each cluster may consist of many nodes. Each node is a compute unit, and is a collection of components: Planner The query planner builds an execution plan from the user's SQL statement and represents the query with different types of relational operators (such as Projection , Filter , Limit , etc.). For example: databend :) EXPLAIN SELECT number + 1 FROM numbers_mt(10) WHERE number > 8 LIMIT 2 \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Limit: 2 \u2502 \u2502 Projection: (number + 1):UInt64 \u2502 \u2502 Expression: (number + 1):UInt64 (Before Projection) \u2502 \u2502 Filter: (number > 8) \u2502 \u2502 ReadDataSource: scan partitions: [1], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Optimizer A rule based optimizer, some rules like predicate push down or pruning of unused columns. Processors A vector-based query execution pipeline, which is build by planner instructions. Each pipeline executor is a processor(such as SourceTransform , FilterTransform , etc.), it has zero or more inputs and zero or more outputs, and connected as a pipeline, it also can be distributed on multiple nodes judged by your query workload. For example: databend :) EXPLAIN PIPELINE SELECT number + 1 FROM numbers_mt(10000) WHERE number > 8 LIMIT 2 \u250c\u2500explain\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 LimitTransform \u00d7 1 processor \u2502 \u2502 Merge (ProjectionTransform \u00d7 16 processors) to (LimitTransform \u00d7 1) \u2502 \u2502 ProjectionTransform \u00d7 16 processors \u2502 \u2502 ExpressionTransform \u00d7 16 processors \u2502 \u2502 FilterTransform \u00d7 16 processors \u2502 \u2502 SourceTransform \u00d7 16 processors \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Cache The cache utilizes local SSDs for caching Data and Indexes based on the version within a node. The cache can be warmed up with different strategies: LOAD_ON_DEMAND - Load index or table data on demand(By Default). LOAD_INDEXES - Load indexes only. LOAD_ALL - Load full data and indexes. Node is the smallest unit of the compute layer, they can be registered as one cluster via namespace. Many clusters can attach the same database, so they can serve the query in parallel by different users. When you add new nodes to a cluster, the currently running computational tasks can be scaled(known as work-stealing) guarantee. The Compute Layer codes mainly in the query directory.","title":"Compute Layer"},{"location":"overview/architecture/#storage-layer","text":"Databend stores data in an efficient, columnar format as Parquet files. Each Parquet file is sorted by the primary key before being written to the underlying shared storage. For efficient pruning, Databend also creates indexes for each Parquet file: min_max.idx The index file stores the minimum and maximum value of this Parquet file. sparse.idx The index file store the mapping for every [N] records granularity. With the indexes, we can speed up the queries by reducing the I/O and CPU cost. Imagine that Parquet file f1 has min_max.idx of [3, 5) and Parquet file f2 has min_max.idx of [4, 6) in column x , if the query predicate is WHERE x < 4 , only f1 needs to be accessed and processed.","title":"Storage Layer"},{"location":"overview/building-and-running/","text":"This document describes how to build and run DatabendQuery as a distributed query engine. 1. Deploy \u00b6 Release binary curl -fsS https://repo.databend.rs/databend/install-bendctl.sh | bash $ export PATH=\"${HOME}/.databend/bin:${PATH}\" $ bendctl cluster create Run with Docker(Recommended) docker pull datafuselabs/databend docker run --init --rm -p 3307:3307 datafuselabs/databend From source git clone https://github.com/datafuselabs/databend.git cd databend && make setup make run 2. Client \u00b6 MySQL Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql -h127.0.0.1 -uroot -P3307 mysql> SELECT avg(number) FROM numbers(1000000000); +-------------+ | avg(number) | +-------------+ | 499999999.5 | +-------------+ 1 row in set (0.05 sec) ClickHouse Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. clickhouse client --host 0.0.0.0 --port 9001 datafuse :) SELECT avg(number) FROM numbers(1000000000); SELECT avg(number) FROM numbers(1000000000) Query id: 89e06fba-1d57-464d-bfb0-238df85a2e66 \u250c\u2500avg(number)\u2500\u2510 \u2502 499999999.5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 rows in set. Elapsed: 0.062 sec. Processed 1.00 billion rows, 8.01 GB (16.16 billion rows/s., 129.38 GB/s.) HTTP Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. $ curl --location --request POST 'localhost:8001/v1/statement/' \\ --header 'Content-Type: text/plain' \\ --data-raw 'SELECT avg(number) FROM numbers(1000000000)' { \"id\": \"93114794-a532-4706-84c9-61a137398fb8\", \"nextUri\": null, \"data\": [ [ 499999999.5 ] ], \"columns\": { \"fields\": [ { \"name\": \"avg(number)\", \"data_type\": \"Float64\", \"nullable\": false } ], \"metadata\": {} }, \"error\": null, \"stats\": { \"read_rows\": 1000000000, \"read_bytes\": 8000000000, \"total_rows_to_read\": 0 } }","title":"Installation"},{"location":"overview/building-and-running/#1-deploy","text":"Release binary curl -fsS https://repo.databend.rs/databend/install-bendctl.sh | bash $ export PATH=\"${HOME}/.databend/bin:${PATH}\" $ bendctl cluster create Run with Docker(Recommended) docker pull datafuselabs/databend docker run --init --rm -p 3307:3307 datafuselabs/databend From source git clone https://github.com/datafuselabs/databend.git cd databend && make setup make run","title":"1. Deploy"},{"location":"overview/building-and-running/#2-client","text":"MySQL Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql -h127.0.0.1 -uroot -P3307 mysql> SELECT avg(number) FROM numbers(1000000000); +-------------+ | avg(number) | +-------------+ | 499999999.5 | +-------------+ 1 row in set (0.05 sec) ClickHouse Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. clickhouse client --host 0.0.0.0 --port 9001 datafuse :) SELECT avg(number) FROM numbers(1000000000); SELECT avg(number) FROM numbers(1000000000) Query id: 89e06fba-1d57-464d-bfb0-238df85a2e66 \u250c\u2500avg(number)\u2500\u2510 \u2502 499999999.5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 1 rows in set. Elapsed: 0.062 sec. Processed 1.00 billion rows, 8.01 GB (16.16 billion rows/s., 129.38 GB/s.) HTTP Client Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. $ curl --location --request POST 'localhost:8001/v1/statement/' \\ --header 'Content-Type: text/plain' \\ --data-raw 'SELECT avg(number) FROM numbers(1000000000)' { \"id\": \"93114794-a532-4706-84c9-61a137398fb8\", \"nextUri\": null, \"data\": [ [ 499999999.5 ] ], \"columns\": { \"fields\": [ { \"name\": \"avg(number)\", \"data_type\": \"Float64\", \"nullable\": false } ], \"metadata\": {} }, \"error\": null, \"stats\": { \"read_rows\": 1000000000, \"read_bytes\": 8000000000, \"total_rows_to_read\": 0 } }","title":"2. Client"},{"location":"overview/performance/","text":"Note Memory SIMD-Vector processing performance only Dataset: 100,000,000,000 (100 Billion) Hardware: AMD Ryzen 7 PRO 4750U, 8 CPU Cores, 16 Threads Rust: rustc 1.56.0-nightly (e3b1c12be 2021-08-02) Build with Link-time Optimization and Using CPU Specific Instructions Query DatabendQuery (v0.4.76-nightly) SELECT avg(number) FROM numbers_mt(100000000000) 3.712 s. (26.94 billion rows/s., 215.52 GB/s.) SELECT sum(number) FROM numbers_mt(100000000000) 3.669 s. (27.26 billion rows/s., 218.07 GB/s.) SELECT min(number) FROM numbers_mt(100000000000) 4.498 s. (22.23 billion rows/s., 177.85 GB/s.) SELECT max(number) FROM numbers_mt(100000000000) 4.438 s. (22.53 billion rows/s., 180.25 GB/s.) SELECT count(number) FROM numbers_mt(100000000000) 2.125 s. (47.07 billion rows/s., 376.53 GB/s.) SELECT sum(number+number+number) FROM numbers_mt(100000000000) 17.169 s. (5.82 billion rows/s., 46.60 GB/s.) SELECT sum(number) / count(number) FROM numbers_mt(100000000000) 3.696 s. (27.06 billion rows/s., 216.45 GB/s.) SELECT sum(number) / count(number), max(number), min(number) FROM numbers_mt(100000000000) 8.348 s. (11.98 billion rows/s., 95.83 GB/s.) SELECT number FROM numbers_mt(10000000000) ORDER BY number DESC LIMIT 10 3.164 s. (3.16 billion rows/s., 25.28 GB/s.) SELECT max(number), sum(number) FROM numbers_mt(1000000000) GROUP BY number % 3, number % 4, number % 5 LIMIT 10 1.657 s. (603.62 million rows/s., 4.83 GB/s.) Notes DatabendQuery system.numbers_mt is 16-way parallelism processing, gist 100,000,000,000 records on laptop show Experience 100 billion performance on your laptop, talk is cheap just bench it","title":"Performance"},{"location":"policies/cla/","text":"Datafuse Labs, Inc. \u00b6 Contributor License Agreement \u00b6 Thank you for your interest in the open source project(s) managed by Datafuse Labs, Inc. (\"Datafuse Labs\"). In order to clarify the intellectual property license granted with Contributions from any person or entity, Datafuse Labs must have a Contributor License Agreement (\"CLA\") on file that has been entered into by each contributor, indicating agreement to the license terms below. This license is for your protection as a contributor as well as the protection of Datafuse Labs and its other contributors and users; it does not change your rights to use your own Contributions for any other purpose. 1. Definitions. \"You\" (or \"Your\") shall mean the copyright owner or legal entity authorized by the copyright owner that is entering into this CLA with Datafuse Labs. For legal entities, the entity making a Contribution and all other entities that control, are controlled by, or are under common control with that entity are considered to be a single Contributor. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"Contribution\" shall mean any code, documentation or other original works of authorship, including any modifications or additions to an existing work, that are intentionally submitted by You to Datafuse Labs for inclusion in, or documentation of, any of the products owned or managed by Datafuse Labs (the \"Work\"). For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to Datafuse Labs or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, Datafuse Labs for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by You as \"Not a Contribution.\" 2. Grant of Copyright License. Subject to the terms and conditions of this CLA, You hereby grant to Datafuse Labs and to recipients of software distributed by Datafuse Labs a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute Your Contributions and such derivative works. 3. Grant of Patent License. Subject to the terms and conditions of this CLA, You hereby grant to Datafuse Labs and to recipients of software distributed by Datafuse Labs a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by You that are necessarily infringed by Your Contribution(s) alone or by combination of Your Contribution(s) with the Work to which such Contribution(s) were submitted. If any entity institutes patent litigation against You or any other entity (including a cross-claim or counterclaim in a lawsuit) alleging that Your Contribution, or the Work to which You have contributed, constitutes direct or contributory patent infringement, then any patent licenses granted to that entity under this CLA for that Contribution or Work shall terminate as of the date such litigation is filed. 4. Authority. You represent and warrant that You are legally entitled to grant the above license. If You are an individual and Your employer(s) has rights to intellectual property that You create that includes Your Contributions, You represent that You have received permission to make Contributions on behalf of that employer, that Your employer has waived such rights for Your Contributions to Datafuse Labs, or that Your employer has entered into a separate CLA with Datafuse Labs covering Your Contributions. If You are a Company,You represent further that each employee making a Contribution to Datafuse Labs under the Company's name is authorized to submit Contributions on behalf of the Company. 5. Original Works. You represent and warrant that each of Your Contributions is Your original creation (see section 7 for submissions on behalf of others). You represent and warrant that, to Your knowledge, none of Your Contributions infringe, violate, or misappropriate any third party intellectual property or other proprietary rights. 6. Disclaimer. You are not expected to provide support for Your Contributions, except to the extent You desire to provide support. You may provide support for free, for a fee, or not at all. UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING, EXCEPT FOR THE WARRANTIES SET FORTH ABOVE, YOU PROVIDE YOUR CONTRIBUTIONS ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. 7. Submissions on Behalf of Others. Should You wish to submit work that is not Your original creation, You may submit it to Datafuse Labs separately from any Contribution, identifying the complete details of its source and of any license or other restriction (including, but not limited to, related patents, trademarks, and license agreements) of which You are personally aware, and conspicuously marking the work as \"Submitted on behalf of a third-party: [named here]\". 8. Additional Facts/Circumstances. You agree to notify Datafuse Labs of any facts or circumstances of which You become aware that would make the above representations and warranties inaccurate in any respect. 9. Authorization. If You are entering into this CLA as a Company, You represent and warrant that the individual accepting this CLA is duly authorized to enter into this CLA on the Company's behalf.","title":"Contributor License Agreement"},{"location":"policies/cla/#datafuse-labs-inc","text":"","title":"Datafuse Labs, Inc."},{"location":"policies/cla/#contributor-license-agreement","text":"Thank you for your interest in the open source project(s) managed by Datafuse Labs, Inc. (\"Datafuse Labs\"). In order to clarify the intellectual property license granted with Contributions from any person or entity, Datafuse Labs must have a Contributor License Agreement (\"CLA\") on file that has been entered into by each contributor, indicating agreement to the license terms below. This license is for your protection as a contributor as well as the protection of Datafuse Labs and its other contributors and users; it does not change your rights to use your own Contributions for any other purpose. 1. Definitions. \"You\" (or \"Your\") shall mean the copyright owner or legal entity authorized by the copyright owner that is entering into this CLA with Datafuse Labs. For legal entities, the entity making a Contribution and all other entities that control, are controlled by, or are under common control with that entity are considered to be a single Contributor. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"Contribution\" shall mean any code, documentation or other original works of authorship, including any modifications or additions to an existing work, that are intentionally submitted by You to Datafuse Labs for inclusion in, or documentation of, any of the products owned or managed by Datafuse Labs (the \"Work\"). For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to Datafuse Labs or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, Datafuse Labs for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by You as \"Not a Contribution.\" 2. Grant of Copyright License. Subject to the terms and conditions of this CLA, You hereby grant to Datafuse Labs and to recipients of software distributed by Datafuse Labs a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute Your Contributions and such derivative works. 3. Grant of Patent License. Subject to the terms and conditions of this CLA, You hereby grant to Datafuse Labs and to recipients of software distributed by Datafuse Labs a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by You that are necessarily infringed by Your Contribution(s) alone or by combination of Your Contribution(s) with the Work to which such Contribution(s) were submitted. If any entity institutes patent litigation against You or any other entity (including a cross-claim or counterclaim in a lawsuit) alleging that Your Contribution, or the Work to which You have contributed, constitutes direct or contributory patent infringement, then any patent licenses granted to that entity under this CLA for that Contribution or Work shall terminate as of the date such litigation is filed. 4. Authority. You represent and warrant that You are legally entitled to grant the above license. If You are an individual and Your employer(s) has rights to intellectual property that You create that includes Your Contributions, You represent that You have received permission to make Contributions on behalf of that employer, that Your employer has waived such rights for Your Contributions to Datafuse Labs, or that Your employer has entered into a separate CLA with Datafuse Labs covering Your Contributions. If You are a Company,You represent further that each employee making a Contribution to Datafuse Labs under the Company's name is authorized to submit Contributions on behalf of the Company. 5. Original Works. You represent and warrant that each of Your Contributions is Your original creation (see section 7 for submissions on behalf of others). You represent and warrant that, to Your knowledge, none of Your Contributions infringe, violate, or misappropriate any third party intellectual property or other proprietary rights. 6. Disclaimer. You are not expected to provide support for Your Contributions, except to the extent You desire to provide support. You may provide support for free, for a fee, or not at all. UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING, EXCEPT FOR THE WARRANTIES SET FORTH ABOVE, YOU PROVIDE YOUR CONTRIBUTIONS ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE. 7. Submissions on Behalf of Others. Should You wish to submit work that is not Your original creation, You may submit it to Datafuse Labs separately from any Contribution, identifying the complete details of its source and of any license or other restriction (including, but not limited to, related patents, trademarks, and license agreements) of which You are personally aware, and conspicuously marking the work as \"Submitted on behalf of a third-party: [named here]\". 8. Additional Facts/Circumstances. You agree to notify Datafuse Labs of any facts or circumstances of which You become aware that would make the above representations and warranties inaccurate in any respect. 9. Authorization. If You are entering into this CLA as a Company, You represent and warrant that the individual accepting this CLA is duly authorized to enter into this CLA on the Company's behalf.","title":"Contributor License Agreement"},{"location":"policies/code-of-conduct/","text":"Contributor Covenant Code of Conduct \u00b6 Our Pledge \u00b6 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00b6 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00b6 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00b6 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00b6 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at opensource@datafuselabs.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00b6 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Contributor Covenant Code of Conduct"},{"location":"policies/code-of-conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"policies/code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"policies/code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"policies/code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"policies/code-of-conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"policies/code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at opensource@datafuselabs.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"policies/code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"policies/credits/","text":"Credits \u00b6 Databend is developed and built with the following software: (automatically generated via cargo-license ) RustyXML 0.3.0 \u00b6 repository: https://github.com/Florob/RustyXML license: Apache-2.0 OR MIT addr2line 0.16.0 \u00b6 repository: https://github.com/gimli-rs/addr2line license: Apache-2.0 OR MIT adler 1.0.2 \u00b6 repository: https://github.com/jonas-schievink/adler.git license: 0BSD OR Apache-2.0 OR MIT ahash 0.7.6 \u00b6 repository: https://github.com/tkaitchuck/ahash license: Apache-2.0 OR MIT aho-corasick 0.7.18 \u00b6 repository: https://github.com/BurntSushi/aho-corasick license: MIT OR Unlicense ansi_term 0.11.0 \u00b6 repository: None license: MIT ansi_term 0.12.1 \u00b6 repository: https://github.com/ogham/rust-ansi-term license: MIT anyhow 1.0.44 \u00b6 repository: https://github.com/dtolnay/anyhow license: Apache-2.0 OR MIT arbitrary 1.0.2 \u00b6 repository: https://github.com/rust-fuzz/arbitrary/ license: Apache-2.0 OR MIT arrayvec 0.4.12 \u00b6 repository: https://github.com/bluss/arrayvec license: Apache-2.0 OR MIT arrayvec 0.5.2 \u00b6 repository: https://github.com/bluss/arrayvec license: Apache-2.0 OR MIT arrow-format 0.2.1 \u00b6 repository: None license: Apache-2.0 arrow2 0.6.2 \u00b6 repository: https://github.com/jorgecarleitao/arrow2 license: Apache-2.0 ascii-canvas 3.0.0 \u00b6 repository: https://github.com/nikomatsakis/ascii-canvas license: Apache-2.0 OR MIT assert-json-diff 2.0.1 \u00b6 repository: https://github.com/davidpdrsn/assert-json-diff.git license: MIT assert_cmd 2.0.2 \u00b6 repository: https://github.com/assert-rs/assert_cmd.git license: Apache-2.0 OR MIT async-channel 1.6.1 \u00b6 repository: https://github.com/smol-rs/async-channel license: Apache-2.0 OR MIT async-compat 0.2.1 \u00b6 repository: https://github.com/smol-rs/async-compat license: Apache-2.0 OR MIT async-executor 1.4.1 \u00b6 repository: https://github.com/smol-rs/async-executor license: Apache-2.0 OR MIT async-global-executor 2.0.2 \u00b6 repository: https://github.com/Keruspe/async-global-executor license: Apache-2.0 OR MIT async-io 1.6.0 \u00b6 repository: https://github.com/smol-rs/async-io license: Apache-2.0 OR MIT async-lock 2.4.0 \u00b6 repository: https://github.com/smol-rs/async-lock license: Apache-2.0 OR MIT async-mutex 1.4.0 \u00b6 repository: https://github.com/stjepang/async-lock license: Apache-2.0 OR MIT async-object-pool 0.1.4 \u00b6 repository: https://github.com/alexliesenfeld/async-object-pool license: MIT async-process 1.2.0 \u00b6 repository: https://github.com/smol-rs/async-process license: Apache-2.0 OR MIT async-raft 0.6.1 \u00b6 repository: https://github.com/async-raft/async-raft license: Apache-2.0 OR MIT async-std 1.10.0 \u00b6 repository: https://github.com/async-rs/async-std license: Apache-2.0 OR MIT async-stream 0.3.2 \u00b6 repository: https://github.com/tokio-rs/async-stream license: MIT async-stream-impl 0.3.2 \u00b6 repository: https://github.com/tokio-rs/async-stream license: MIT async-task 4.0.3 \u00b6 repository: https://github.com/stjepang/async-task license: Apache-2.0 OR MIT async-trait 0.1.51 \u00b6 repository: https://github.com/dtolnay/async-trait license: Apache-2.0 OR MIT atomic-shim 0.1.0 \u00b6 repository: https://github.com/bltavares/atomic-shim license: Apache-2.0 OR MIT atomic-waker 1.0.0 \u00b6 repository: https://github.com/stjepang/atomic-waker license: Apache-2.0 OR MIT atty 0.2.14 \u00b6 repository: https://github.com/softprops/atty license: MIT autocfg 0.1.7 \u00b6 repository: https://github.com/cuviper/autocfg license: Apache-2.0 OR MIT autocfg 1.0.1 \u00b6 repository: https://github.com/cuviper/autocfg license: Apache-2.0 OR MIT axum 0.2.8 \u00b6 repository: https://github.com/tokio-rs/axum license: MIT axum-server 0.2.5 \u00b6 repository: https://github.com/programatik29/axum-server license: MIT azure_core_mirror 0.1.0 \u00b6 repository: https://github.com/azure/azure-sdk-for-rust license: MIT azure_storage_mirror 0.1.0 \u00b6 repository: https://github.com/azure/azure-sdk-for-rust license: MIT backtrace 0.3.62 \u00b6 repository: https://github.com/rust-lang/backtrace-rs license: Apache-2.0 OR MIT base-x 0.2.8 \u00b6 repository: https://github.com/OrKoN/base-x-rs license: MIT base64 0.12.3 \u00b6 repository: https://github.com/marshallpierce/rust-base64 license: Apache-2.0 OR MIT base64 0.13.0 \u00b6 repository: https://github.com/marshallpierce/rust-base64 license: Apache-2.0 OR MIT base64ct 1.1.1 \u00b6 repository: https://github.com/RustCrypto/formats/tree/master/base64ct license: Apache-2.0 OR MIT basic-cookies 0.1.4 \u00b6 repository: https://github.com/drjokepu/basic-cookies license: MIT bendctl 0.1.0 \u00b6 repository: None license: Apache-2.0 bigdecimal 0.2.2 \u00b6 repository: https://github.com/akubera/bigdecimal-rs license: Apache-2.0 OR MIT bindgen 0.58.1 \u00b6 repository: https://github.com/rust-lang/rust-bindgen license: BSD-3-Clause bit-set 0.5.2 \u00b6 repository: https://github.com/contain-rs/bit-set license: Apache-2.0 OR MIT bit-vec 0.6.3 \u00b6 repository: https://github.com/contain-rs/bit-vec license: Apache-2.0 OR MIT bitflags 1.2.1 \u00b6 repository: https://github.com/bitflags/bitflags license: Apache-2.0 OR MIT bitmaps 2.1.0 \u00b6 repository: https://github.com/bodil/bitmaps license: MPL-2.0+ bitpacking 0.8.4 \u00b6 repository: None license: MIT bitvec 0.22.3 \u00b6 repository: https://github.com/myrrlyn/bitvec license: MIT block-buffer 0.7.3 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT block-buffer 0.9.0 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT block-padding 0.1.5 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT blocking 1.0.2 \u00b6 repository: https://github.com/stjepang/blocking license: Apache-2.0 OR MIT bstr 0.2.17 \u00b6 repository: https://github.com/BurntSushi/bstr license: Apache-2.0 OR MIT bufstream 0.1.4 \u00b6 repository: https://github.com/alexcrichton/bufstream license: Apache-2.0 OR MIT bumpalo 3.8.0 \u00b6 repository: https://github.com/fitzgen/bumpalo license: Apache-2.0 OR MIT byte-tools 0.3.1 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT byte-unit 4.0.13 \u00b6 repository: https://github.com/magiclen/byte-unit license: MIT bytecount 0.6.2 \u00b6 repository: https://github.com/llogiq/bytecount license: Apache-2.0 OR MIT bytemuck 1.7.2 \u00b6 repository: https://github.com/Lokathor/bytemuck license: Apache-2.0 OR MIT OR Zlib byteorder 1.4.3 \u00b6 repository: https://github.com/BurntSushi/byteorder license: MIT OR Unlicense bytes 1.1.0 \u00b6 repository: https://github.com/tokio-rs/bytes license: MIT cache-padded 1.1.1 \u00b6 repository: https://github.com/stjepang/cache-padded license: Apache-2.0 OR MIT camino 1.0.5 \u00b6 repository: https://github.com/withoutboats/camino license: Apache-2.0 OR MIT cargo-license 0.4.2 \u00b6 repository: https://github.com/onur/cargo-license license: MIT cargo-platform 0.1.2 \u00b6 repository: https://github.com/rust-lang/cargo license: Apache-2.0 OR MIT cargo_metadata 0.12.3 \u00b6 repository: https://github.com/oli-obk/cargo_metadata license: MIT cargo_metadata 0.14.1 \u00b6 repository: https://github.com/oli-obk/cargo_metadata license: MIT cast 0.2.7 \u00b6 repository: https://github.com/japaric/cast.rs license: Apache-2.0 OR MIT castaway 0.1.1 \u00b6 repository: https://github.com/sagebind/castaway license: MIT cc 1.0.71 \u00b6 repository: https://github.com/alexcrichton/cc-rs license: Apache-2.0 OR MIT cexpr 0.4.0 \u00b6 repository: https://github.com/jethrogb/rust-cexpr license: Apache-2.0 OR MIT cfg-if 0.1.10 \u00b6 repository: https://github.com/alexcrichton/cfg-if license: Apache-2.0 OR MIT cfg-if 1.0.0 \u00b6 repository: https://github.com/alexcrichton/cfg-if license: Apache-2.0 OR MIT chrono 0.4.19 \u00b6 repository: https://github.com/chronotope/chrono license: Apache-2.0 OR MIT chrono-tz 0.5.3 \u00b6 repository: https://github.com/djzin/chrono-tz license: Apache-2.0 OR MIT chrono-tz 0.6.0 \u00b6 repository: https://github.com/chronotope/chrono-tz license: Apache-2.0 OR MIT chrono-tz-build 0.0.2 \u00b6 repository: None license: Apache-2.0 OR MIT chunked_transfer 1.4.0 \u00b6 repository: https://github.com/frewsxcv/rust-chunked-transfer license: Apache-2.0 clang-sys 1.2.2 \u00b6 repository: https://github.com/KyleMayes/clang-sys license: Apache-2.0 clap 2.33.3 \u00b6 repository: https://github.com/clap-rs/clap license: MIT clap 3.0.0-beta.5 \u00b6 repository: https://github.com/clap-rs/clap license: Apache-2.0 OR MIT clap_derive 3.0.0-beta.5 \u00b6 repository: https://github.com/clap-rs/clap/tree/master/clap_derive license: Apache-2.0 OR MIT clap_generate 3.0.0-beta.5 \u00b6 repository: https://github.com/clap-rs/clap/tree/master/clap_generate license: Apache-2.0 OR MIT clickhouse-rs 1.0.0-alpha.1 \u00b6 repository: https://github.com/suharev7/clickhouse-rs license: MIT clickhouse-rs-cityhash-sys 0.1.2 \u00b6 repository: None license: MIT clipboard-win 4.2.1 \u00b6 repository: https://github.com/DoumanAsh/clipboard-win license: BSL-1.0 cmake 0.1.46 \u00b6 repository: https://github.com/alexcrichton/cmake-rs license: Apache-2.0 OR MIT coarsetime 0.1.19 \u00b6 repository: https://github.com/jedisct1/rust-coarsetime license: ISC colored 2.0.0 \u00b6 repository: https://github.com/mackwic/colored license: MPL-2.0 combine 4.6.1 \u00b6 repository: https://github.com/Marwes/combine license: MIT comfy-table 4.1.1 \u00b6 repository: https://github.com/nukesor/comfy-table license: MIT common-arrow 0.1.0 \u00b6 repository: None license: Apache-2.0 common-base 0.1.0 \u00b6 repository: None license: Apache-2.0 common-building 0.1.0 \u00b6 repository: None license: Apache-2.0 common-cache 0.1.0 \u00b6 repository: None license: Apache-2.0 common-clickhouse-srv 0.3.2 \u00b6 repository: None license: Apache-2.0 common-context 0.1.0 \u00b6 repository: None license: Apache-2.0 common-dal 0.1.0 \u00b6 repository: None license: Apache-2.0 common-datablocks 0.1.0 \u00b6 repository: None license: Apache-2.0 common-datavalues 0.1.0 \u00b6 repository: None license: Apache-2.0 common-exception 0.1.0 \u00b6 repository: None license: Apache-2.0 common-flight-rpc 0.1.0 \u00b6 repository: None license: Apache-2.0 common-functions 0.1.0 \u00b6 repository: None license: Apache-2.0 common-infallible 0.1.0 \u00b6 repository: None license: Apache-2.0 common-io 0.1.0 \u00b6 repository: None license: Apache-2.0 common-macros 0.1.0 \u00b6 repository: None license: None common-management 0.1.0 \u00b6 repository: None license: Apache-2.0 common-mem-allocator 0.1.0 \u00b6 repository: None license: None common-meta-api 0.1.0 \u00b6 repository: None license: Apache-2.0 common-meta-embedded 0.1.0 \u00b6 repository: None license: Apache-2.0 common-meta-flight 0.1.0 \u00b6 repository: None license: Apache-2.0 common-meta-raft-store 0.1.0 \u00b6 repository: None license: Apache-2.0 common-meta-sled-store 0.1.0 \u00b6 repository: None license: Apache-2.0 common-meta-types 0.1.0 \u00b6 repository: None license: Apache-2.0 common-metrics 0.1.0 \u00b6 repository: None license: Apache-2.0 common-planners 0.1.0 \u00b6 repository: None license: Apache-2.0 common-streams 0.1.0 \u00b6 repository: None license: Apache-2.0 common-tracing 0.1.0 \u00b6 repository: None license: Apache-2.0 concurrent-queue 1.2.2 \u00b6 repository: https://github.com/stjepang/concurrent-queue license: Apache-2.0 OR MIT console 0.15.0 \u00b6 repository: https://github.com/mitsuhiko/console license: MIT const-oid 0.6.2 \u00b6 repository: https://github.com/RustCrypto/formats/tree/master/const-oid license: Apache-2.0 OR MIT const_fn 0.4.8 \u00b6 repository: https://github.com/taiki-e/const_fn license: Apache-2.0 OR MIT core-foundation 0.9.2 \u00b6 repository: https://github.com/servo/core-foundation-rs license: Apache-2.0 OR MIT core-foundation-sys 0.8.3 \u00b6 repository: https://github.com/servo/core-foundation-rs license: Apache-2.0 OR MIT cpp_demangle 0.3.3 \u00b6 repository: https://github.com/gimli-rs/cpp_demangle license: Apache-2.0 OR MIT cpufeatures 0.2.1 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT crc32fast 1.2.1 \u00b6 repository: https://github.com/srijs/rust-crc32fast license: Apache-2.0 OR MIT criterion 0.3.5 \u00b6 repository: https://github.com/bheisler/criterion.rs license: Apache-2.0 OR MIT criterion-plot 0.4.4 \u00b6 repository: https://github.com/bheisler/criterion.rs license: Apache-2.0 OR MIT crossbeam 0.7.3 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam 0.8.1 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-channel 0.4.4 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-channel 0.5.1 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-deque 0.7.4 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-deque 0.8.1 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-epoch 0.8.2 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-epoch 0.9.5 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-queue 0.2.3 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 AND BSD-2-Clause OR MIT crossbeam-queue 0.3.2 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-utils 0.7.2 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossbeam-utils 0.8.5 \u00b6 repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT crossterm 0.20.0 \u00b6 repository: https://github.com/crossterm-rs/crossterm license: MIT crossterm_winapi 0.8.0 \u00b6 repository: https://github.com/crossterm-rs/crossterm-winapi license: MIT crunchy 0.2.2 \u00b6 repository: None license: MIT crypto-bigint 0.2.11 \u00b6 repository: https://github.com/RustCrypto/crypto-bigint license: Apache-2.0 OR MIT crypto-mac 0.11.1 \u00b6 repository: https://github.com/RustCrypto/traits license: Apache-2.0 OR MIT csv 1.1.6 \u00b6 repository: https://github.com/BurntSushi/rust-csv license: MIT OR Unlicense csv-core 0.1.10 \u00b6 repository: https://github.com/BurntSushi/rust-csv license: MIT OR Unlicense ct-codecs 1.1.1 \u00b6 repository: https://github.com/jedisct1/rust-ct-codecs license: MIT ct-logs 0.8.0 \u00b6 repository: https://github.com/ctz/ct-logs license: Apache-2.0 OR ISC OR MIT ctor 0.1.21 \u00b6 repository: https://github.com/mmastrac/rust-ctor license: Apache-2.0 OR MIT ctrlc 3.2.0 \u00b6 repository: https://github.com/Detegr/rust-ctrlc.git license: Apache-2.0 OR MIT curl 0.4.39 \u00b6 repository: https://github.com/alexcrichton/curl-rust license: MIT curl-sys 0.4.49+curl-7.79.1 \u00b6 repository: https://github.com/alexcrichton/curl-rust license: MIT dashmap 4.0.2 \u00b6 repository: https://github.com/xacrimon/dashmap license: MIT data-encoding 2.3.2 \u00b6 repository: https://github.com/ia0/data-encoding license: MIT databend-meta 0.1.0 \u00b6 repository: None license: Apache-2.0 databend-query 0.1.0 \u00b6 repository: None license: Apache-2.0 debugid 0.7.2 \u00b6 repository: https://github.com/getsentry/rust-debugid license: Apache-2.0 der 0.4.4 \u00b6 repository: https://github.com/RustCrypto/formats/tree/master/der license: Apache-2.0 OR MIT derive_more 0.99.16 \u00b6 repository: https://github.com/JelteF/derive_more license: MIT derive_utils 0.11.2 \u00b6 repository: https://github.com/taiki-e/derive_utils license: Apache-2.0 OR MIT diff 0.1.12 \u00b6 repository: https://github.com/utkarshkukreti/diff.rs license: Apache-2.0 OR MIT difference 2.0.0 \u00b6 repository: https://github.com/johannhof/difference.rs license: MIT difflib 0.4.0 \u00b6 repository: https://github.com/DimaKudosh/difflib license: MIT digest 0.8.1 \u00b6 repository: https://github.com/RustCrypto/traits license: Apache-2.0 OR MIT digest 0.9.0 \u00b6 repository: https://github.com/RustCrypto/traits license: Apache-2.0 OR MIT dirs 4.0.0 \u00b6 repository: https://github.com/soc/dirs-rs license: Apache-2.0 OR MIT dirs-next 2.0.0 \u00b6 repository: https://github.com/xdg-rs/dirs license: Apache-2.0 OR MIT dirs-sys 0.3.6 \u00b6 repository: https://github.com/dirs-dev/dirs-sys-rs license: Apache-2.0 OR MIT dirs-sys-next 0.1.2 \u00b6 repository: https://github.com/xdg-rs/dirs/tree/master/dirs-sys license: Apache-2.0 OR MIT discard 1.0.4 \u00b6 repository: https://github.com/Pauan/rust-discard license: MIT doc-comment 0.3.3 \u00b6 repository: https://github.com/GuillaumeGomez/doc-comment license: MIT downcast 0.10.0 \u00b6 repository: https://github.com/fkoep/downcast-rs license: MIT dtoa 0.4.8 \u00b6 repository: https://github.com/dtolnay/dtoa license: Apache-2.0 OR MIT dunce 1.0.2 \u00b6 repository: https://gitlab.com/kornelski/dunce license: CC0-1.0 dyn-clone 1.0.4 \u00b6 repository: https://github.com/dtolnay/dyn-clone license: Apache-2.0 OR MIT ecdsa 0.12.4 \u00b6 repository: https://github.com/RustCrypto/signatures license: Apache-2.0 OR MIT ed25519-compact 0.1.11 \u00b6 repository: https://github.com/jedisct1/rust-ed25519-compact license: ISC either 1.6.1 \u00b6 repository: https://github.com/bluss/either license: Apache-2.0 OR MIT elliptic-curve 0.10.6 \u00b6 repository: https://github.com/RustCrypto/traits/tree/master/elliptic-curve license: Apache-2.0 OR MIT ena 0.14.0 \u00b6 repository: https://github.com/rust-lang-nursery/ena license: Apache-2.0 OR MIT encode_unicode 0.3.6 \u00b6 repository: https://github.com/tormol/encode_unicode license: Apache-2.0 OR MIT encoding_rs 0.8.29 \u00b6 repository: https://github.com/hsivonen/encoding_rs license: Apache-2.0 OR MIT endian-type 0.1.2 \u00b6 repository: https://github.com/Lolirofle/endian-type.git license: MIT enum-as-inner 0.3.3 \u00b6 repository: https://github.com/bluejekyll/enum-as-inner license: Apache-2.0 OR MIT enum-iterator 0.7.0 \u00b6 repository: https://github.com/stephaneyfx/enum-iterator.git license: 0BSD enum-iterator-derive 0.7.0 \u00b6 repository: https://github.com/stephaneyfx/enum-iterator.git license: 0BSD env_logger 0.8.4 \u00b6 repository: https://github.com/env-logger-rs/env_logger/ license: Apache-2.0 OR MIT env_logger 0.9.0 \u00b6 repository: https://github.com/env-logger-rs/env_logger/ license: Apache-2.0 OR MIT error-chain 0.12.4 \u00b6 repository: https://github.com/rust-lang-nursery/error-chain license: Apache-2.0 OR MIT error-code 2.3.0 \u00b6 repository: https://github.com/DoumanAsh/error-code license: BSL-1.0 event-listener 2.5.1 \u00b6 repository: https://github.com/stjepang/event-listener license: Apache-2.0 OR MIT failure 0.1.8 \u00b6 repository: https://github.com/rust-lang-nursery/failure license: Apache-2.0 OR MIT failure_derive 0.1.8 \u00b6 repository: https://github.com/rust-lang-nursery/failure license: Apache-2.0 OR MIT fake-simd 0.1.2 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT fallible-streaming-iterator 0.1.9 \u00b6 repository: https://github.com/sfackler/fallible-streaming-iterator license: Apache-2.0 OR MIT fastrand 1.5.0 \u00b6 repository: https://github.com/smol-rs/fastrand license: Apache-2.0 OR MIT fd-lock 3.0.0 \u00b6 repository: https://github.com/yoshuawuyts/fd-lock license: Apache-2.0 OR MIT ff 0.10.1 \u00b6 repository: https://github.com/zkcrypto/ff license: Apache-2.0 OR MIT filetime 0.2.15 \u00b6 repository: https://github.com/alexcrichton/filetime license: Apache-2.0 OR MIT fixedbitset 0.2.0 \u00b6 repository: https://github.com/bluss/fixedbitset license: Apache-2.0 OR MIT flaky_test 0.1.0 \u00b6 repository: https://github.com/denoland/flaky_test license: MIT flatbuffers 2.0.0 \u00b6 repository: https://github.com/google/flatbuffers license: Apache-2.0 flate2 1.0.22 \u00b6 repository: https://github.com/rust-lang/flate2-rs license: Apache-2.0 OR MIT float-cmp 0.8.0 \u00b6 repository: https://github.com/mikedilger/float-cmp license: MIT float-cmp 0.9.0 \u00b6 repository: https://github.com/mikedilger/float-cmp license: MIT fnv 1.0.7 \u00b6 repository: https://github.com/servo/rust-fnv license: Apache-2.0 OR MIT foreign-types 0.3.2 \u00b6 repository: https://github.com/sfackler/foreign-types license: Apache-2.0 OR MIT foreign-types-shared 0.1.1 \u00b6 repository: https://github.com/sfackler/foreign-types license: Apache-2.0 OR MIT form_urlencoded 1.0.1 \u00b6 repository: https://github.com/servo/rust-url license: Apache-2.0 OR MIT fragile 1.0.0 \u00b6 repository: https://github.com/mitsuhiko/rust-fragile license: Apache-2.0 frunk 0.4.0 \u00b6 repository: https://github.com/lloydmeta/frunk license: MIT frunk_core 0.4.0 \u00b6 repository: https://github.com/lloydmeta/frunk license: MIT frunk_derives 0.4.0 \u00b6 repository: https://github.com/lloydmeta/frunk license: MIT frunk_proc_macro_helpers 0.1.0 \u00b6 repository: https://github.com/lloydmeta/frunk license: MIT frunk_proc_macros 0.1.0 \u00b6 repository: https://github.com/lloydmeta/frunk license: MIT frunk_proc_macros_impl 0.1.0 \u00b6 repository: https://github.com/lloydmeta/frunk license: MIT fs2 0.4.3 \u00b6 repository: https://github.com/danburkert/fs2-rs license: Apache-2.0 OR MIT fs_extra 1.2.0 \u00b6 repository: https://github.com/webdesus/fs_extra license: MIT fsio 0.3.0 \u00b6 repository: https://github.com/sagiegurari/fsio.git license: Apache-2.0 funty 1.2.0 \u00b6 repository: https://github.com/myrrlyn/funty license: MIT futures 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-channel 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-core 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-executor 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-io 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-lite 1.12.0 \u00b6 repository: https://github.com/smol-rs/futures-lite license: Apache-2.0 OR MIT futures-macro 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-sink 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-task 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT futures-util 0.3.17 \u00b6 repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT fuzz 0.1.0 \u00b6 repository: None license: None generic-array 0.12.4 \u00b6 repository: https://github.com/fizyk20/generic-array.git license: MIT generic-array 0.14.4 \u00b6 repository: https://github.com/fizyk20/generic-array.git license: MIT gethostname 0.2.1 \u00b6 repository: https://github.com/lunaryorn/gethostname.rs.git license: Apache-2.0 getopts 0.2.21 \u00b6 repository: https://github.com/rust-lang/getopts license: Apache-2.0 OR MIT getrandom 0.1.16 \u00b6 repository: https://github.com/rust-random/getrandom license: Apache-2.0 OR MIT getrandom 0.2.3 \u00b6 repository: https://github.com/rust-random/getrandom license: Apache-2.0 OR MIT getset 0.1.1 \u00b6 repository: https://github.com/Hoverbear/getset license: MIT gimli 0.25.0 \u00b6 repository: https://github.com/gimli-rs/gimli license: Apache-2.0 OR MIT git2 0.13.23 \u00b6 repository: https://github.com/rust-lang/git2-rs license: Apache-2.0 OR MIT glob 0.3.0 \u00b6 repository: https://github.com/rust-lang/glob license: Apache-2.0 OR MIT gloo-timers 0.2.1 \u00b6 repository: https://github.com/rustwasm/gloo/tree/master/crates/timers license: Apache-2.0 OR MIT group 0.10.0 \u00b6 repository: https://github.com/zkcrypto/group license: Apache-2.0 OR MIT h2 0.3.6 \u00b6 repository: https://github.com/hyperium/h2 license: MIT half 1.8.0 \u00b6 repository: https://github.com/starkat99/half-rs license: Apache-2.0 OR MIT handlebars 4.1.3 \u00b6 repository: https://github.com/sunng87/handlebars-rust license: MIT hash_hasher 2.0.3 \u00b6 repository: https://github.com/Fraser999/Hash-Hasher.git license: Apache-2.0 OR MIT hashbrown 0.11.2 \u00b6 repository: https://github.com/rust-lang/hashbrown license: Apache-2.0 OR MIT headers 0.3.5 \u00b6 repository: https://github.com/hyperium/headers license: MIT headers-core 0.2.0 \u00b6 repository: https://github.com/hyperium/headers license: MIT heck 0.3.3 \u00b6 repository: https://github.com/withoutboats/heck license: Apache-2.0 OR MIT hermit-abi 0.1.19 \u00b6 repository: https://github.com/hermitcore/libhermit-rs license: Apache-2.0 OR MIT hex 0.4.3 \u00b6 repository: https://github.com/KokaKiwi/rust-hex license: Apache-2.0 OR MIT hmac 0.11.0 \u00b6 repository: https://github.com/RustCrypto/MACs license: Apache-2.0 OR MIT hmac-sha256 0.1.7 \u00b6 repository: https://github.com/jedisct1/rust-hmac-sha256 license: ISC hmac-sha512 0.1.9 \u00b6 repository: https://github.com/jedisct1/rust-hmac-sha512 license: ISC honggfuzz 0.5.54 \u00b6 repository: https://github.com/rust-fuzz/honggfuzz-rs license: Apache-2.0 OR MIT OR Unlicense OR WTFPL hostname 0.3.1 \u00b6 repository: https://github.com/svartalf/hostname license: MIT http 0.2.5 \u00b6 repository: https://github.com/hyperium/http license: Apache-2.0 OR MIT http-body 0.4.3 \u00b6 repository: https://github.com/hyperium/http-body license: MIT httparse 1.5.1 \u00b6 repository: https://github.com/seanmonstar/httparse license: Apache-2.0 OR MIT httpdate 1.0.1 \u00b6 repository: https://github.com/pyfisch/httpdate license: Apache-2.0 OR MIT httpmock 0.6.2 \u00b6 repository: https://github.com/alexliesenfeld/httpmock license: MIT humantime 2.1.0 \u00b6 repository: https://github.com/tailhook/humantime license: Apache-2.0 OR MIT hyper 0.14.14 \u00b6 repository: https://github.com/hyperium/hyper license: MIT hyper-rustls 0.22.1 \u00b6 repository: https://github.com/ctz/hyper-rustls license: Apache-2.0 OR ISC OR MIT hyper-timeout 0.4.1 \u00b6 repository: https://github.com/hjr3/hyper-timeout license: Apache-2.0 OR MIT hyper-tls 0.5.0 \u00b6 repository: https://github.com/hyperium/hyper-tls license: Apache-2.0 OR MIT idna 0.2.3 \u00b6 repository: https://github.com/servo/rust-url/ license: Apache-2.0 OR MIT im 15.0.0 \u00b6 repository: https://github.com/bodil/im-rs license: MPL-2.0+ indexmap 1.7.0 \u00b6 repository: https://github.com/bluss/indexmap license: Apache-2.0 OR MIT indicatif 0.16.2 \u00b6 repository: https://github.com/mitsuhiko/indicatif license: MIT inferno 0.10.7 \u00b6 repository: https://github.com/jonhoo/inferno.git license: CDDL-1.0 instant 0.1.12 \u00b6 repository: https://github.com/sebcrozet/instant license: BSD-3-Clause integer-encoding 1.1.7 \u00b6 repository: https://github.com/dermesser/integer-encoding-rs license: MIT integer-encoding 3.0.2 \u00b6 repository: https://github.com/dermesser/integer-encoding-rs license: MIT io-enum 1.0.1 \u00b6 repository: https://github.com/taiki-e/io-enum license: Apache-2.0 OR MIT ipconfig 0.2.2 \u00b6 repository: https://github.com/liranringel/ipconfig license: Apache-2.0 OR MIT ipnet 2.3.1 \u00b6 repository: https://github.com/krisprice/ipnet license: Apache-2.0 OR MIT isahc 1.5.1 \u00b6 repository: https://github.com/sagebind/isahc license: MIT itertools 0.10.1 \u00b6 repository: https://github.com/rust-itertools/itertools license: Apache-2.0 OR MIT itoa 0.4.8 \u00b6 repository: https://github.com/dtolnay/itoa license: Apache-2.0 OR MIT jobserver 0.1.24 \u00b6 repository: https://github.com/alexcrichton/jobserver-rs license: Apache-2.0 OR MIT js-sys 0.3.55 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/js-sys license: Apache-2.0 OR MIT jwt-simple 0.10.6 \u00b6 repository: https://github.com/jedisct1/rust-jwt-simple license: ISC k256 0.9.6 \u00b6 repository: https://github.com/RustCrypto/elliptic-curves/tree/master/k256 license: Apache-2.0 OR MIT kv-log-macro 1.0.7 \u00b6 repository: https://github.com/yoshuawuyts/kv-log-macro license: Apache-2.0 OR MIT lalrpop 0.19.6 \u00b6 repository: https://github.com/lalrpop/lalrpop license: Apache-2.0 OR MIT lalrpop-util 0.19.6 \u00b6 repository: https://github.com/lalrpop/lalrpop license: Apache-2.0 OR MIT lazy_static 1.4.0 \u00b6 repository: https://github.com/rust-lang-nursery/lazy-static.rs license: Apache-2.0 OR MIT lazycell 1.3.0 \u00b6 repository: https://github.com/indiv0/lazycell license: Apache-2.0 OR MIT levenshtein 1.0.5 \u00b6 repository: https://github.com/wooorm/levenshtein-rs license: MIT lexical 5.2.2 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT lexical-core 0.7.6 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical/tree/master/lexical-core license: Apache-2.0 OR MIT lexical-core 0.8.2 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT lexical-parse-float 0.8.2 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT lexical-parse-integer 0.8.0 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT lexical-util 0.8.1 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT lexical-write-float 0.8.2 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT lexical-write-integer 0.8.0 \u00b6 repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT libc 0.2.104 \u00b6 repository: https://github.com/rust-lang/libc license: Apache-2.0 OR MIT libgit2-sys 0.12.24+1.3.0 \u00b6 repository: https://github.com/rust-lang/git2-rs license: Apache-2.0 OR MIT libloading 0.7.1 \u00b6 repository: https://github.com/nagisa/rust_libloading/ license: ISC libm 0.1.4 \u00b6 repository: https://github.com/rust-lang-nursery/libm license: Apache-2.0 OR MIT libm 0.2.1 \u00b6 repository: https://github.com/rust-lang/libm license: Apache-2.0 OR MIT libnghttp2-sys 0.1.7+1.45.0 \u00b6 repository: https://github.com/alexcrichton/nghttp2-rs license: Apache-2.0 OR MIT libz-sys 1.1.3 \u00b6 repository: https://github.com/rust-lang/libz-sys license: Apache-2.0 OR MIT linked-hash-map 0.5.4 \u00b6 repository: https://github.com/contain-rs/linked-hash-map license: Apache-2.0 OR MIT lock_api 0.4.5 \u00b6 repository: https://github.com/Amanieu/parking_lot license: Apache-2.0 OR MIT log 0.4.14 \u00b6 repository: https://github.com/rust-lang/log license: Apache-2.0 OR MIT lru 0.6.6 \u00b6 repository: https://github.com/jeromefroe/lru-rs.git license: MIT lru-cache 0.1.2 \u00b6 repository: https://github.com/contain-rs/lru-cache license: Apache-2.0 OR MIT lz4 1.23.2 \u00b6 repository: https://github.com/10xGenomics/lz4-rs license: MIT lz4-sys 1.9.2 \u00b6 repository: https://github.com/bozaro/lz4-rs license: MIT mach 0.3.2 \u00b6 repository: https://github.com/fitzgen/mach license: BSD-2-Clause maplit 1.0.2 \u00b6 repository: https://github.com/bluss/maplit license: Apache-2.0 OR MIT match_cfg 0.1.0 \u00b6 repository: https://github.com/gnzlbg/match_cfg license: Apache-2.0 OR MIT matchers 0.0.1 \u00b6 repository: https://github.com/hawkw/matchers license: MIT matches 0.1.9 \u00b6 repository: https://github.com/SimonSapin/rust-std-candidates license: MIT maybe-uninit 2.0.0 \u00b6 repository: https://github.com/est31/maybe-uninit license: Apache-2.0 OR MIT md-5 0.9.1 \u00b6 repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT md5 0.7.0 \u00b6 repository: https://github.com/stainless-steel/md5 license: Apache-2.0 OR MIT memchr 2.4.1 \u00b6 repository: https://github.com/BurntSushi/memchr license: MIT OR Unlicense memmap 0.7.0 \u00b6 repository: https://github.com/danburkert/memmap-rs license: Apache-2.0 OR MIT memoffset 0.5.6 \u00b6 repository: https://github.com/Gilnaa/memoffset license: MIT memoffset 0.6.4 \u00b6 repository: https://github.com/Gilnaa/memoffset license: MIT metrics 0.17.0 \u00b6 repository: https://github.com/metrics-rs/metrics license: MIT metrics-exporter-prometheus 0.6.1 \u00b6 repository: https://github.com/metrics-rs/metrics license: MIT metrics-macros 0.4.0 \u00b6 repository: https://github.com/metrics-rs/metrics license: MIT metrics-util 0.10.1 \u00b6 repository: https://github.com/metrics-rs/metrics license: MIT mime 0.3.16 \u00b6 repository: https://github.com/hyperium/mime license: Apache-2.0 OR MIT minimal-lexical 0.1.4 \u00b6 repository: https://github.com/Alexhuszagh/minimal-lexical license: Apache-2.0 OR MIT miniz_oxide 0.4.4 \u00b6 repository: https://github.com/Frommi/miniz_oxide/tree/master/miniz_oxide license: Apache-2.0 OR MIT OR Zlib mio 0.7.14 \u00b6 repository: https://github.com/tokio-rs/mio license: MIT miow 0.3.7 \u00b6 repository: https://github.com/yoshuawuyts/miow license: Apache-2.0 OR MIT mockall 0.10.2 \u00b6 repository: https://github.com/asomers/mockall license: Apache-2.0 OR MIT mockall_derive 0.10.2 \u00b6 repository: https://github.com/asomers/mockall license: Apache-2.0 OR MIT msql-srv 0.9.6 \u00b6 repository: https://github.com/jonhoo/msql-srv.git license: Apache-2.0 OR MIT multimap 0.8.3 \u00b6 repository: https://github.com/havarnov/multimap license: Apache-2.0 OR MIT multiversion 0.6.1 \u00b6 repository: https://github.com/calebzulawski/multiversion license: Apache-2.0 OR MIT multiversion-macros 0.6.1 \u00b6 repository: https://github.com/calebzulawski/multiversion license: Apache-2.0 OR MIT mysql 21.0.1 \u00b6 repository: https://github.com/blackbeam/rust-mysql-simple license: Apache-2.0 OR MIT mysql_common 0.27.5 \u00b6 repository: https://github.com/blackbeam/rust_mysql_common license: Apache-2.0 OR MIT named_pipe 0.4.1 \u00b6 repository: https://github.com/blackbeam/named_pipe license: Apache-2.0 OR MIT native-tls 0.2.8 \u00b6 repository: https://github.com/sfackler/rust-native-tls license: Apache-2.0 OR MIT new_debug_unreachable 1.0.4 \u00b6 repository: https://github.com/mbrubeck/rust-debug-unreachable license: MIT nibble_vec 0.1.0 \u00b6 repository: https://github.com/michaelsproul/rust_nibble_vec license: MIT nix 0.20.2 \u00b6 repository: https://github.com/nix-rust/nix license: MIT nix 0.21.2 \u00b6 repository: https://github.com/nix-rust/nix license: MIT nix 0.22.2 \u00b6 repository: https://github.com/nix-rust/nix license: MIT nodrop 0.1.14 \u00b6 repository: https://github.com/bluss/arrayvec license: Apache-2.0 OR MIT nom 5.1.2 \u00b6 repository: https://github.com/Geal/nom license: MIT nom 7.0.0 \u00b6 repository: https://github.com/Geal/nom license: MIT normalize-line-endings 0.3.0 \u00b6 repository: https://github.com/derekdreery/normalize-line-endings license: Apache-2.0 ntapi 0.3.6 \u00b6 repository: https://github.com/MSxDOS/ntapi license: Apache-2.0 OR MIT num 0.4.0 \u00b6 repository: https://github.com/rust-num/num license: Apache-2.0 OR MIT num-bigint 0.3.3 \u00b6 repository: https://github.com/rust-num/num-bigint license: Apache-2.0 OR MIT num-bigint 0.4.2 \u00b6 repository: https://github.com/rust-num/num-bigint license: Apache-2.0 OR MIT num-bigint-dig 0.7.0 \u00b6 repository: https://github.com/dignifiedquire/num-bigint license: Apache-2.0 OR MIT num-complex 0.4.0 \u00b6 repository: https://github.com/rust-num/num-complex license: Apache-2.0 OR MIT num-format 0.4.0 \u00b6 repository: https://github.com/bcmyers/num-format license: Apache-2.0 OR MIT num-integer 0.1.44 \u00b6 repository: https://github.com/rust-num/num-integer license: Apache-2.0 OR MIT num-iter 0.1.42 \u00b6 repository: https://github.com/rust-num/num-iter license: Apache-2.0 OR MIT num-rational 0.4.0 \u00b6 repository: https://github.com/rust-num/num-rational license: Apache-2.0 OR MIT num-traits 0.2.14 \u00b6 repository: https://github.com/rust-num/num-traits license: Apache-2.0 OR MIT num_cpus 1.13.0 \u00b6 repository: https://github.com/seanmonstar/num_cpus license: Apache-2.0 OR MIT number_prefix 0.4.0 \u00b6 repository: https://github.com/ogham/rust-number-prefix license: MIT oauth2 4.0.0-alpha.3 \u00b6 repository: https://github.com/ramosbugs/oauth2-rs license: Apache-2.0 OR MIT object 0.27.0 \u00b6 repository: https://github.com/gimli-rs/object license: Apache-2.0 OR MIT once_cell 1.8.0 \u00b6 repository: https://github.com/matklad/once_cell license: Apache-2.0 OR MIT oorandom 11.1.3 \u00b6 repository: https://sr.ht/~icefox/oorandom/ license: MIT opaque-debug 0.2.3 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT opaque-debug 0.3.0 \u00b6 repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT openssl 0.10.36 \u00b6 repository: https://github.com/sfackler/rust-openssl license: Apache-2.0 openssl-probe 0.1.4 \u00b6 repository: https://github.com/alexcrichton/openssl-probe license: Apache-2.0 OR MIT openssl-sys 0.9.67 \u00b6 repository: https://github.com/sfackler/rust-openssl license: MIT opentelemetry 0.16.0 \u00b6 repository: https://github.com/open-telemetry/opentelemetry-rust license: Apache-2.0 opentelemetry-jaeger 0.15.0 \u00b6 repository: https://github.com/open-telemetry/opentelemetry-rust/tree/main/opentelemetry-jaeger license: Apache-2.0 opentelemetry-semantic-conventions 0.8.0 \u00b6 repository: https://github.com/open-telemetry/opentelemetry-rust/tree/main/opentelemetry-semantic-conventions license: Apache-2.0 ordered-float 1.1.1 \u00b6 repository: https://github.com/reem/rust-ordered-float license: MIT ordered-float 2.8.0 \u00b6 repository: https://github.com/reem/rust-ordered-float license: MIT os_str_bytes 4.2.0 \u00b6 repository: https://github.com/dylni/os_str_bytes license: Apache-2.0 OR MIT output_vt100 0.1.2 \u00b6 repository: https://github.com/Phundrak/output-vt100-rs license: MIT p256 0.9.0 \u00b6 repository: https://github.com/RustCrypto/elliptic-curves/tree/master/p256 license: Apache-2.0 OR MIT packed_simd_2 0.3.6 \u00b6 repository: https://github.com/rust-lang/packed_simd license: Apache-2.0 OR MIT parking 2.0.0 \u00b6 repository: https://github.com/stjepang/parking license: Apache-2.0 OR MIT parking_lot 0.11.2 \u00b6 repository: https://github.com/Amanieu/parking_lot license: Apache-2.0 OR MIT parking_lot_core 0.8.5 \u00b6 repository: https://github.com/Amanieu/parking_lot license: Apache-2.0 OR MIT parquet-format-async-temp 0.2.0 \u00b6 repository: https://github.com/sunchao/parquet-format-rs license: Apache-2.0 parquet2 0.6.0 \u00b6 repository: None license: Apache-2.0 parse-zoneinfo 0.3.0 \u00b6 repository: https://github.com/djzin/parse-zoneinfo license: MIT paste 1.0.5 \u00b6 repository: https://github.com/dtolnay/paste license: Apache-2.0 OR MIT peeking_take_while 0.1.2 \u00b6 repository: https://github.com/fitzgen/peeking_take_while license: Apache-2.0 OR MIT pem 0.8.3 \u00b6 repository: https://github.com/jcreekmore/pem-rs.git license: MIT pem-rfc7468 0.2.3 \u00b6 repository: https://github.com/RustCrypto/formats/tree/master/pem-rfc7468 license: Apache-2.0 OR MIT percent-encoding 2.1.0 \u00b6 repository: https://github.com/servo/rust-url/ license: Apache-2.0 OR MIT pest 2.1.3 \u00b6 repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT pest_derive 2.1.0 \u00b6 repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT pest_generator 2.1.3 \u00b6 repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT pest_meta 2.1.3 \u00b6 repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT petgraph 0.5.1 \u00b6 repository: https://github.com/petgraph/petgraph license: Apache-2.0 OR MIT phf 0.10.0 \u00b6 repository: https://github.com/sfackler/rust-phf license: MIT phf_codegen 0.10.0 \u00b6 repository: https://github.com/sfackler/rust-phf license: MIT phf_generator 0.10.0 \u00b6 repository: https://github.com/sfackler/rust-phf license: MIT phf_shared 0.8.0 \u00b6 repository: https://github.com/sfackler/rust-phf license: MIT phf_shared 0.10.0 \u00b6 repository: https://github.com/sfackler/rust-phf license: MIT pico-args 0.4.2 \u00b6 repository: https://github.com/RazrFalcon/pico-args license: MIT pin-project 1.0.8 \u00b6 repository: https://github.com/taiki-e/pin-project license: Apache-2.0 OR MIT pin-project-internal 1.0.8 \u00b6 repository: https://github.com/taiki-e/pin-project license: Apache-2.0 OR MIT pin-project-lite 0.2.7 \u00b6 repository: https://github.com/taiki-e/pin-project-lite license: Apache-2.0 OR MIT pin-utils 0.1.0 \u00b6 repository: https://github.com/rust-lang-nursery/pin-utils license: Apache-2.0 OR MIT pkcs1 0.2.4 \u00b6 repository: https://github.com/RustCrypto/formats/tree/master/pkcs1 license: Apache-2.0 OR MIT pkcs8 0.7.6 \u00b6 repository: https://github.com/RustCrypto/formats/tree/master/pkcs8 license: Apache-2.0 OR MIT pkg-config 0.3.20 \u00b6 repository: https://github.com/rust-lang/pkg-config-rs license: Apache-2.0 OR MIT plotters 0.3.1 \u00b6 repository: https://github.com/38/plotters license: MIT plotters-backend 0.3.2 \u00b6 repository: https://github.com/plotters-rs/plotters-backend license: MIT plotters-svg 0.3.1 \u00b6 repository: https://github.com/plotters-rs/plotters-svg.git license: MIT polling 2.1.0 \u00b6 repository: https://github.com/smol-rs/polling license: Apache-2.0 OR MIT portpicker 0.1.1 \u00b6 repository: https://github.com/Dentosal/portpicker-rs license: Unlicense pprof 0.5.0 \u00b6 repository: https://github.com/tikv/pprof-rs license: Apache-2.0 ppv-lite86 0.2.14 \u00b6 repository: https://github.com/cryptocorrosion/cryptocorrosion license: Apache-2.0 OR MIT precomputed-hash 0.1.1 \u00b6 repository: https://github.com/emilio/precomputed-hash license: MIT predicates 1.0.8 \u00b6 repository: https://github.com/assert-rs/predicates-rs license: Apache-2.0 OR MIT predicates 2.0.3 \u00b6 repository: https://github.com/assert-rs/predicates-rs license: Apache-2.0 OR MIT predicates-core 1.0.2 \u00b6 repository: https://github.com/assert-rs/predicates-rs/tree/master/predicates-core license: Apache-2.0 OR MIT predicates-tree 1.0.4 \u00b6 repository: https://github.com/assert-rs/predicates-rs/tree/master/predicates-tree license: Apache-2.0 OR MIT pretty_assertions 1.0.0 \u00b6 repository: https://github.com/colin-kiegel/rust-pretty-assertions license: Apache-2.0 OR MIT proc-macro-error 1.0.4 \u00b6 repository: https://gitlab.com/CreepySkeleton/proc-macro-error license: Apache-2.0 OR MIT proc-macro-error-attr 1.0.4 \u00b6 repository: https://gitlab.com/CreepySkeleton/proc-macro-error license: Apache-2.0 OR MIT proc-macro-hack 0.5.19 \u00b6 repository: https://github.com/dtolnay/proc-macro-hack license: Apache-2.0 OR MIT proc-macro-nested 0.1.7 \u00b6 repository: https://github.com/dtolnay/proc-macro-hack license: Apache-2.0 OR MIT proc-macro2 1.0.32 \u00b6 repository: https://github.com/dtolnay/proc-macro2 license: Apache-2.0 OR MIT prometheus-parse 0.2.2 \u00b6 repository: https://github.com/ccakes/prometheus-parse-rs license: Apache-2.0 prost 0.8.0 \u00b6 repository: https://github.com/tokio-rs/prost license: Apache-2.0 prost-build 0.8.0 \u00b6 repository: https://github.com/tokio-rs/prost license: Apache-2.0 prost-derive 0.8.0 \u00b6 repository: https://github.com/tokio-rs/prost license: Apache-2.0 prost-types 0.8.0 \u00b6 repository: https://github.com/tokio-rs/prost license: Apache-2.0 pulldown-cmark 0.8.0 \u00b6 repository: https://github.com/raphlinus/pulldown-cmark license: MIT qstring 0.7.2 \u00b6 repository: https://github.com/algesten/qstring license: MIT quanta 0.9.3 \u00b6 repository: https://github.com/metrics-rs/quanta license: MIT quantiles 0.7.1 \u00b6 repository: https://github.com/postmates/quantiles license: MIT quick-error 1.2.3 \u00b6 repository: http://github.com/tailhook/quick-error license: Apache-2.0 OR MIT quick-error 2.0.1 \u00b6 repository: http://github.com/tailhook/quick-error license: Apache-2.0 OR MIT quick-xml 0.22.0 \u00b6 repository: https://github.com/tafia/quick-xml license: MIT quote 1.0.10 \u00b6 repository: https://github.com/dtolnay/quote license: Apache-2.0 OR MIT radium 0.6.2 \u00b6 repository: https://github.com/bitvecto-rs/radium license: MIT radix_trie 0.2.1 \u00b6 repository: https://github.com/michaelsproul/rust_radix_trie license: MIT rand 0.7.3 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand 0.8.4 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand_chacha 0.2.2 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand_chacha 0.3.1 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand_core 0.5.1 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand_core 0.6.3 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand_hc 0.2.0 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand_hc 0.3.1 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT rand_xoshiro 0.4.0 \u00b6 repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT raw-cpuid 10.2.0 \u00b6 repository: https://github.com/gz/rust-cpuid license: MIT rayon 1.5.1 \u00b6 repository: https://github.com/rayon-rs/rayon license: Apache-2.0 OR MIT rayon-core 1.9.1 \u00b6 repository: https://github.com/rayon-rs/rayon license: Apache-2.0 OR MIT redox_syscall 0.2.10 \u00b6 repository: https://gitlab.redox-os.org/redox-os/syscall license: MIT redox_users 0.4.0 \u00b6 repository: https://gitlab.redox-os.org/redox-os/users license: MIT regex 1.5.4 \u00b6 repository: https://github.com/rust-lang/regex license: Apache-2.0 OR MIT regex-automata 0.1.10 \u00b6 repository: https://github.com/BurntSushi/regex-automata license: MIT OR Unlicense regex-syntax 0.6.25 \u00b6 repository: https://github.com/rust-lang/regex license: Apache-2.0 OR MIT remove_dir_all 0.5.3 \u00b6 repository: https://github.com/XAMPPRocky/remove_dir_all.git license: Apache-2.0 OR MIT reqwest 0.11.6 \u00b6 repository: https://github.com/seanmonstar/reqwest license: Apache-2.0 OR MIT resolv-conf 0.7.0 \u00b6 repository: http://github.com/tailhook/resolv-conf license: Apache-2.0 OR MIT rgb 0.8.27 \u00b6 repository: https://github.com/kornelski/rust-rgb license: MIT ring 0.16.20 \u00b6 repository: https://github.com/briansmith/ring license: None ritelinked 0.3.2 \u00b6 repository: https://github.com/ritelabs/ritelinked license: Apache-2.0 OR MIT rsa 0.5.0 \u00b6 repository: https://github.com/RustCrypto/RSA license: Apache-2.0 OR MIT run_script 0.9.0 \u00b6 repository: https://github.com/sagiegurari/run_script.git license: Apache-2.0 rusoto_core 0.47.0 \u00b6 repository: https://github.com/rusoto/rusoto license: MIT rusoto_credential 0.47.0 \u00b6 repository: https://github.com/rusoto/rusoto license: MIT rusoto_s3 0.47.0 \u00b6 repository: https://github.com/rusoto/rusoto license: MIT rusoto_signature 0.47.0 \u00b6 repository: https://github.com/rusoto/rusoto license: MIT rust_decimal 1.16.0 \u00b6 repository: https://github.com/paupino/rust-decimal license: MIT rustc-demangle 0.1.21 \u00b6 repository: https://github.com/alexcrichton/rustc-demangle license: Apache-2.0 OR MIT rustc-hash 1.1.0 \u00b6 repository: https://github.com/rust-lang-nursery/rustc-hash license: Apache-2.0 OR MIT rustc_version 0.2.3 \u00b6 repository: https://github.com/Kimundi/rustc-version-rs license: Apache-2.0 OR MIT rustc_version 0.4.0 \u00b6 repository: https://github.com/Kimundi/rustc-version-rs license: Apache-2.0 OR MIT rustls 0.19.1 \u00b6 repository: https://github.com/ctz/rustls license: Apache-2.0 OR ISC OR MIT rustls-native-certs 0.5.0 \u00b6 repository: https://github.com/ctz/rustls-native-certs license: Apache-2.0 OR ISC OR MIT rustversion 1.0.5 \u00b6 repository: https://github.com/dtolnay/rustversion license: Apache-2.0 OR MIT rustyline 9.0.0 \u00b6 repository: https://github.com/kkawakam/rustyline license: MIT ryu 1.0.5 \u00b6 repository: https://github.com/dtolnay/ryu license: Apache-2.0 OR BSL-1.0 same-file 1.0.6 \u00b6 repository: https://github.com/BurntSushi/same-file license: MIT OR Unlicense saturating 0.1.0 \u00b6 repository: https://github.com/breeswish/saturating-rs license: MIT schannel 0.1.19 \u00b6 repository: https://github.com/steffengy/schannel-rs license: MIT scopeguard 1.1.0 \u00b6 repository: https://github.com/bluss/scopeguard license: Apache-2.0 OR MIT sct 0.6.1 \u00b6 repository: https://github.com/ctz/sct.rs license: Apache-2.0 OR ISC OR MIT security-framework 2.3.1 \u00b6 repository: https://github.com/kornelski/rust-security-framework license: Apache-2.0 OR MIT security-framework-sys 2.4.2 \u00b6 repository: https://github.com/kornelski/rust-security-framework license: Apache-2.0 OR MIT semver 0.9.0 \u00b6 repository: https://github.com/steveklabnik/semver license: Apache-2.0 OR MIT semver 0.11.0 \u00b6 repository: https://github.com/steveklabnik/semver license: Apache-2.0 OR MIT semver 1.0.4 \u00b6 repository: https://github.com/dtolnay/semver license: Apache-2.0 OR MIT semver-parser 0.7.0 \u00b6 repository: https://github.com/steveklabnik/semver-parser license: Apache-2.0 OR MIT semver-parser 0.10.2 \u00b6 repository: https://github.com/steveklabnik/semver-parser license: Apache-2.0 OR MIT serde 1.0.130 \u00b6 repository: https://github.com/serde-rs/serde license: Apache-2.0 OR MIT serde-xml-rs 0.4.1 \u00b6 repository: https://github.com/RReverser/serde-xml-rs license: MIT serde_cbor 0.11.2 \u00b6 repository: https://github.com/pyfisch/cbor license: Apache-2.0 OR MIT serde_derive 1.0.130 \u00b6 repository: https://github.com/serde-rs/serde license: Apache-2.0 OR MIT serde_json 1.0.68 \u00b6 repository: https://github.com/serde-rs/json license: Apache-2.0 OR MIT serde_regex 1.1.0 \u00b6 repository: None license: Apache-2.0 OR MIT serde_urlencoded 0.7.0 \u00b6 repository: https://github.com/nox/serde_urlencoded license: Apache-2.0 OR MIT serde_yaml 0.8.21 \u00b6 repository: https://github.com/dtolnay/serde-yaml license: Apache-2.0 OR MIT sha-1 0.8.2 \u00b6 repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT sha-1 0.9.8 \u00b6 repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT sha1 0.6.0 \u00b6 repository: https://github.com/mitsuhiko/rust-sha1 license: BSD-3-Clause sha2 0.9.8 \u00b6 repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT sharded-slab 0.1.4 \u00b6 repository: https://github.com/hawkw/sharded-slab license: MIT shellwords 1.1.0 \u00b6 repository: https://github.com/jimmycuadra/rust-shellwords license: MIT shlex 1.1.0 \u00b6 repository: https://github.com/comex/rust-shlex license: Apache-2.0 OR MIT signal-hook 0.3.10 \u00b6 repository: https://github.com/vorner/signal-hook license: Apache-2.0 OR MIT signal-hook-mio 0.2.1 \u00b6 repository: https://github.com/vorner/signal-hook license: Apache-2.0 OR MIT signal-hook-registry 1.4.0 \u00b6 repository: https://github.com/vorner/signal-hook license: Apache-2.0 OR MIT signature 1.3.1 \u00b6 repository: https://github.com/RustCrypto/traits/tree/master/signature license: Apache-2.0 OR MIT simdutf8 0.1.3 \u00b6 repository: https://github.com/rusticstuff/simdutf8 license: Apache-2.0 OR MIT siphasher 0.3.7 \u00b6 repository: https://github.com/jedisct1/rust-siphash license: Apache-2.0 OR MIT sized-chunks 0.6.5 \u00b6 repository: https://github.com/bodil/sized-chunks license: MPL-2.0+ skeptic 0.13.6 \u00b6 repository: https://github.com/budziq/rust-skeptic license: Apache-2.0 OR MIT sketches-ddsketch 0.1.2 \u00b6 repository: https://github.com/mheffner/rust-sketches-ddsketch license: Apache-2.0 slab 0.4.5 \u00b6 repository: https://github.com/tokio-rs/slab license: MIT sled 0.34.6 \u00b6 repository: https://github.com/spacejam/sled license: Apache-2.0 OR MIT sluice 0.5.5 \u00b6 repository: https://github.com/sagebind/sluice license: MIT smallvec 1.7.0 \u00b6 repository: https://github.com/servo/rust-smallvec license: Apache-2.0 OR MIT socket2 0.3.19 \u00b6 repository: https://github.com/alexcrichton/socket2-rs license: Apache-2.0 OR MIT socket2 0.4.2 \u00b6 repository: https://github.com/rust-lang/socket2 license: Apache-2.0 OR MIT spin 0.5.2 \u00b6 repository: https://github.com/mvdnes/spin-rs.git license: MIT spki 0.4.1 \u00b6 repository: https://github.com/RustCrypto/formats/tree/master/spki license: Apache-2.0 OR MIT sqlparser 0.11.1-alpha.0 \u00b6 repository: https://github.com/sqlparser-rs/sqlparser-rs license: Apache-2.0 stable_deref_trait 1.2.0 \u00b6 repository: https://github.com/storyyeller/stable_deref_trait license: Apache-2.0 OR MIT standback 0.2.17 \u00b6 repository: https://github.com/jhpratt/standback license: Apache-2.0 OR MIT static_assertions 1.1.0 \u00b6 repository: https://github.com/nvzqz/static-assertions-rs license: Apache-2.0 OR MIT stdweb 0.4.20 \u00b6 repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT stdweb-derive 0.5.3 \u00b6 repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT stdweb-internal-macros 0.2.9 \u00b6 repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT stdweb-internal-runtime 0.1.5 \u00b6 repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT str-buf 1.0.5 \u00b6 repository: https://github.com/DoumanAsh/str-buf license: BSL-1.0 str_stack 0.1.0 \u00b6 repository: https://github.com/Stebalien/str_stack license: Apache-2.0 OR MIT streaming-decompression 0.1.0 \u00b6 repository: None license: Apache-2.0 streaming-iterator 0.1.5 \u00b6 repository: https://github.com/sfackler/streaming-iterator license: Apache-2.0 OR MIT strength_reduce 0.2.3 \u00b6 repository: http://github.com/ejmahler/strength_reduce license: Apache-2.0 OR MIT string_cache 0.8.2 \u00b6 repository: https://github.com/servo/string-cache license: Apache-2.0 OR MIT strsim 0.8.0 \u00b6 repository: https://github.com/dguo/strsim-rs license: MIT strsim 0.10.0 \u00b6 repository: https://github.com/dguo/strsim-rs license: MIT structopt 0.3.25 \u00b6 repository: https://github.com/TeXitoi/structopt license: Apache-2.0 OR MIT structopt-derive 0.4.18 \u00b6 repository: https://github.com/TeXitoi/structopt license: Apache-2.0 OR MIT structopt-toml 0.5.0 \u00b6 repository: https://github.com/dalance/structopt-toml license: Apache-2.0 OR MIT structopt-toml-derive 0.5.0 \u00b6 repository: https://github.com/dalance/structopt-toml license: Apache-2.0 OR MIT strum 0.21.0 \u00b6 repository: https://github.com/Peternator7/strum license: MIT strum_macros 0.21.1 \u00b6 repository: https://github.com/Peternator7/strum license: MIT subprocess 0.2.8 \u00b6 repository: https://github.com/hniksic/rust-subprocess license: Apache-2.0 OR MIT subtle 2.4.1 \u00b6 repository: https://github.com/dalek-cryptography/subtle license: BSD-3-Clause symbolic-common 8.3.1 \u00b6 repository: https://github.com/getsentry/symbolic license: MIT symbolic-demangle 8.3.1 \u00b6 repository: https://github.com/getsentry/symbolic license: MIT syn 1.0.81 \u00b6 repository: https://github.com/dtolnay/syn license: Apache-2.0 OR MIT sync_wrapper 0.1.1 \u00b6 repository: https://github.com/Actyx/sync_wrapper license: Apache-2.0 synstructure 0.12.6 \u00b6 repository: https://github.com/mystor/synstructure license: MIT sysinfo 0.19.2 \u00b6 repository: https://github.com/GuillaumeGomez/sysinfo license: MIT sysinfo 0.20.5 \u00b6 repository: https://github.com/GuillaumeGomez/sysinfo license: MIT tap 1.0.1 \u00b6 repository: https://github.com/myrrlyn/tap license: MIT tar 0.4.37 \u00b6 repository: https://github.com/alexcrichton/tar-rs license: Apache-2.0 OR MIT tempfile 3.2.0 \u00b6 repository: https://github.com/Stebalien/tempfile license: Apache-2.0 OR MIT term 0.7.0 \u00b6 repository: https://github.com/Stebalien/term license: Apache-2.0 OR MIT termcolor 1.1.2 \u00b6 repository: https://github.com/BurntSushi/termcolor license: MIT OR Unlicense terminal_size 0.1.17 \u00b6 repository: https://github.com/eminence/terminal-size license: Apache-2.0 OR MIT termtree 0.2.1 \u00b6 repository: https://github.com/rust-cli/termtree license: MIT test-env-log 0.2.7 \u00b6 repository: https://github.com/d-e-s-o/test-env-log.git license: Apache-2.0 OR MIT textwrap 0.11.0 \u00b6 repository: https://github.com/mgeisler/textwrap license: MIT textwrap 0.14.2 \u00b6 repository: https://github.com/mgeisler/textwrap license: MIT thiserror 1.0.30 \u00b6 repository: https://github.com/dtolnay/thiserror license: Apache-2.0 OR MIT thiserror-impl 1.0.30 \u00b6 repository: https://github.com/dtolnay/thiserror license: Apache-2.0 OR MIT thread_local 1.1.3 \u00b6 repository: https://github.com/Amanieu/thread_local-rs license: Apache-2.0 OR MIT threadpool 1.8.1 \u00b6 repository: https://github.com/rust-threadpool/rust-threadpool license: Apache-2.0 OR MIT thrift 0.13.0 \u00b6 repository: None license: Apache-2.0 tikv-jemalloc-sys 0.4.2+5.2.1-patched.2 \u00b6 repository: https://github.com/tikv/jemallocator license: Apache-2.0 OR MIT time 0.1.44 \u00b6 repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT time 0.2.27 \u00b6 repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT time-macros 0.1.1 \u00b6 repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT time-macros-impl 0.1.2 \u00b6 repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT tiny-keccak 2.0.2 \u00b6 repository: None license: CC0-1.0 tinytemplate 1.2.1 \u00b6 repository: https://github.com/bheisler/TinyTemplate license: Apache-2.0 OR MIT tinyvec 1.5.0 \u00b6 repository: https://github.com/Lokathor/tinyvec license: Apache-2.0 OR MIT OR Zlib tinyvec_macros 0.1.0 \u00b6 repository: https://github.com/Soveu/tinyvec_macros license: Apache-2.0 OR MIT OR Zlib tokio 1.12.0 \u00b6 repository: https://github.com/tokio-rs/tokio license: MIT tokio-io-timeout 1.1.1 \u00b6 repository: https://github.com/sfackler/tokio-io-timeout license: Apache-2.0 OR MIT tokio-macros 1.5.0 \u00b6 repository: https://github.com/tokio-rs/tokio license: MIT tokio-native-tls 0.3.0 \u00b6 repository: https://github.com/tokio-rs/tls license: MIT tokio-rustls 0.22.0 \u00b6 repository: https://github.com/tokio-rs/tls license: Apache-2.0 OR MIT tokio-stream 0.1.7 \u00b6 repository: https://github.com/tokio-rs/tokio license: MIT tokio-util 0.6.8 \u00b6 repository: https://github.com/tokio-rs/tokio license: MIT toml 0.5.8 \u00b6 repository: https://github.com/alexcrichton/toml-rs license: Apache-2.0 OR MIT tonic 0.5.2 \u00b6 repository: https://github.com/hyperium/tonic license: MIT tonic-build 0.5.2 \u00b6 repository: https://github.com/hyperium/tonic license: MIT tower 0.4.10 \u00b6 repository: https://github.com/tower-rs/tower license: MIT tower-http 0.1.1 \u00b6 repository: https://github.com/tower-rs/tower-http license: MIT tower-layer 0.3.1 \u00b6 repository: https://github.com/tower-rs/tower license: MIT tower-service 0.3.1 \u00b6 repository: https://github.com/tower-rs/tower license: MIT tracing 0.1.29 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-appender 0.1.2 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-attributes 0.1.18 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-bunyan-formatter 0.2.6 \u00b6 repository: https://github.com/LukeMathWalker/tracing-bunyan-formatter license: Apache-2.0 OR MIT tracing-core 0.1.21 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-futures 0.2.5 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-log 0.1.2 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-opentelemetry 0.15.0 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-serde 0.1.2 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT tracing-subscriber 0.2.25 \u00b6 repository: https://github.com/tokio-rs/tracing license: MIT trust-dns-proto 0.20.3 \u00b6 repository: https://github.com/bluejekyll/trust-dns license: Apache-2.0 OR MIT trust-dns-resolver 0.20.3 \u00b6 repository: https://github.com/bluejekyll/trust-dns license: Apache-2.0 OR MIT try-lock 0.2.3 \u00b6 repository: https://github.com/seanmonstar/try-lock license: MIT tryhard 0.4.0 \u00b6 repository: https://github.com/EmbarkStudios/tryhard license: Apache-2.0 OR MIT twox-hash 1.6.1 \u00b6 repository: https://github.com/shepmaster/twox-hash license: MIT typenum 1.14.0 \u00b6 repository: https://github.com/paholg/typenum license: Apache-2.0 OR MIT ucd-trie 0.1.3 \u00b6 repository: https://github.com/BurntSushi/ucd-generate license: Apache-2.0 OR MIT uncased 0.9.6 \u00b6 repository: https://github.com/SergioBenitez/uncased license: Apache-2.0 OR MIT unicase 2.6.0 \u00b6 repository: https://github.com/seanmonstar/unicase license: Apache-2.0 OR MIT unicode-bidi 0.3.7 \u00b6 repository: https://github.com/servo/unicode-bidi license: Apache-2.0 OR MIT unicode-normalization 0.1.19 \u00b6 repository: https://github.com/unicode-rs/unicode-normalization license: Apache-2.0 OR MIT unicode-segmentation 1.8.0 \u00b6 repository: https://github.com/unicode-rs/unicode-segmentation license: Apache-2.0 OR MIT unicode-width 0.1.9 \u00b6 repository: https://github.com/unicode-rs/unicode-width license: Apache-2.0 OR MIT unicode-xid 0.2.2 \u00b6 repository: https://github.com/unicode-rs/unicode-xid license: Apache-2.0 OR MIT untrusted 0.7.1 \u00b6 repository: https://github.com/briansmith/untrusted license: ISC ureq 2.2.0 \u00b6 repository: https://github.com/algesten/ureq license: Apache-2.0 OR MIT url 2.2.2 \u00b6 repository: https://github.com/servo/rust-url license: Apache-2.0 OR MIT users 0.11.0 \u00b6 repository: https://github.com/ogham/rust-users license: MIT utf8-width 0.1.5 \u00b6 repository: https://github.com/magiclen/utf8-width license: MIT utf8parse 0.2.0 \u00b6 repository: https://github.com/jwilm/vte license: Apache-2.0 OR MIT uuid 0.8.2 \u00b6 repository: https://github.com/uuid-rs/uuid license: Apache-2.0 OR MIT value-bag 1.0.0-alpha.7 \u00b6 repository: https://github.com/sval-rs/value-bag license: Apache-2.0 OR MIT vcpkg 0.2.15 \u00b6 repository: https://github.com/mcgoo/vcpkg-rs license: Apache-2.0 OR MIT vec_map 0.8.2 \u00b6 repository: https://github.com/contain-rs/vec-map license: Apache-2.0 OR MIT vergen 5.1.16 \u00b6 repository: https://github.com/rustyhorde/vergen license: Apache-2.0 OR MIT version_check 0.9.3 \u00b6 repository: https://github.com/SergioBenitez/version_check license: Apache-2.0 OR MIT wait-timeout 0.2.0 \u00b6 repository: https://github.com/alexcrichton/wait-timeout license: Apache-2.0 OR MIT waker-fn 1.1.0 \u00b6 repository: https://github.com/stjepang/waker-fn license: Apache-2.0 OR MIT walkdir 2.3.2 \u00b6 repository: https://github.com/BurntSushi/walkdir license: MIT OR Unlicense want 0.3.0 \u00b6 repository: https://github.com/seanmonstar/want license: MIT wasi 0.9.0+wasi-snapshot-preview1 \u00b6 repository: https://github.com/bytecodealliance/wasi license: Apache-2.0 OR Apache-2.0 WITH LLVM-exception OR MIT wasi 0.10.0+wasi-snapshot-preview1 \u00b6 repository: https://github.com/bytecodealliance/wasi license: Apache-2.0 OR Apache-2.0 WITH LLVM-exception OR MIT wasm-bindgen 0.2.78 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen license: Apache-2.0 OR MIT wasm-bindgen-backend 0.2.78 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/backend license: Apache-2.0 OR MIT wasm-bindgen-futures 0.4.28 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/futures license: Apache-2.0 OR MIT wasm-bindgen-macro 0.2.78 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/macro license: Apache-2.0 OR MIT wasm-bindgen-macro-support 0.2.78 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/macro-support license: Apache-2.0 OR MIT wasm-bindgen-shared 0.2.78 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/shared license: Apache-2.0 OR MIT web-sys 0.3.55 \u00b6 repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/web-sys license: Apache-2.0 OR MIT webbrowser 0.5.5 \u00b6 repository: https://github.com/amodm/webbrowser-rs license: Apache-2.0 OR MIT webpki 0.21.4 \u00b6 repository: https://github.com/briansmith/webpki license: None webpki-roots 0.21.1 \u00b6 repository: https://github.com/ctz/webpki-roots license: MPL-2.0 wepoll-ffi 0.1.2 \u00b6 repository: https://github.com/aclysma/wepoll-ffi license: Apache-2.0 OR BSD-2-Clause OR MIT which 3.1.1 \u00b6 repository: https://github.com/harryfei/which-rs.git license: MIT which 4.2.2 \u00b6 repository: https://github.com/harryfei/which-rs.git license: MIT widestring 0.4.3 \u00b6 repository: https://github.com/starkat99/widestring-rs.git license: Apache-2.0 OR MIT winapi 0.3.9 \u00b6 repository: https://github.com/retep998/winapi-rs license: Apache-2.0 OR MIT winapi-i686-pc-windows-gnu 0.4.0 \u00b6 repository: https://github.com/retep998/winapi-rs license: Apache-2.0 OR MIT winapi-util 0.1.5 \u00b6 repository: https://github.com/BurntSushi/winapi-util license: MIT OR Unlicense winapi-x86_64-pc-windows-gnu 0.4.0 \u00b6 repository: https://github.com/retep998/winapi-rs license: Apache-2.0 OR MIT winreg 0.6.2 \u00b6 repository: https://github.com/gentoo90/winreg-rs license: MIT winreg 0.7.0 \u00b6 repository: https://github.com/gentoo90/winreg-rs license: MIT wyz 0.4.0 \u00b6 repository: https://github.com/myrrlyn/wyz license: MIT xattr 0.2.2 \u00b6 repository: https://github.com/Stebalien/xattr license: Apache-2.0 OR MIT xml-rs 0.8.4 \u00b6 repository: https://github.com/netvl/xml-rs license: MIT yaml-rust 0.4.5 \u00b6 repository: https://github.com/chyh1990/yaml-rust license: Apache-2.0 OR MIT zeroize 1.4.2 \u00b6 repository: https://github.com/iqlusioninc/crates/tree/main/zeroize license: Apache-2.0 OR MIT zeroize_derive 1.2.0 \u00b6 repository: https://github.com/iqlusioninc/crates/tree/main/zeroize/derive license: Apache-2.0 OR MIT","title":"Credits"},{"location":"policies/credits/#credits","text":"Databend is developed and built with the following software: (automatically generated via cargo-license )","title":"Credits"},{"location":"policies/credits/#rustyxml-030","text":"repository: https://github.com/Florob/RustyXML license: Apache-2.0 OR MIT","title":"RustyXML 0.3.0"},{"location":"policies/credits/#addr2line-0160","text":"repository: https://github.com/gimli-rs/addr2line license: Apache-2.0 OR MIT","title":"addr2line 0.16.0"},{"location":"policies/credits/#adler-102","text":"repository: https://github.com/jonas-schievink/adler.git license: 0BSD OR Apache-2.0 OR MIT","title":"adler 1.0.2"},{"location":"policies/credits/#ahash-076","text":"repository: https://github.com/tkaitchuck/ahash license: Apache-2.0 OR MIT","title":"ahash 0.7.6"},{"location":"policies/credits/#aho-corasick-0718","text":"repository: https://github.com/BurntSushi/aho-corasick license: MIT OR Unlicense","title":"aho-corasick 0.7.18"},{"location":"policies/credits/#ansi_term-0110","text":"repository: None license: MIT","title":"ansi_term 0.11.0"},{"location":"policies/credits/#ansi_term-0121","text":"repository: https://github.com/ogham/rust-ansi-term license: MIT","title":"ansi_term 0.12.1"},{"location":"policies/credits/#anyhow-1044","text":"repository: https://github.com/dtolnay/anyhow license: Apache-2.0 OR MIT","title":"anyhow 1.0.44"},{"location":"policies/credits/#arbitrary-102","text":"repository: https://github.com/rust-fuzz/arbitrary/ license: Apache-2.0 OR MIT","title":"arbitrary 1.0.2"},{"location":"policies/credits/#arrayvec-0412","text":"repository: https://github.com/bluss/arrayvec license: Apache-2.0 OR MIT","title":"arrayvec 0.4.12"},{"location":"policies/credits/#arrayvec-052","text":"repository: https://github.com/bluss/arrayvec license: Apache-2.0 OR MIT","title":"arrayvec 0.5.2"},{"location":"policies/credits/#arrow-format-021","text":"repository: None license: Apache-2.0","title":"arrow-format 0.2.1"},{"location":"policies/credits/#arrow2-062","text":"repository: https://github.com/jorgecarleitao/arrow2 license: Apache-2.0","title":"arrow2 0.6.2"},{"location":"policies/credits/#ascii-canvas-300","text":"repository: https://github.com/nikomatsakis/ascii-canvas license: Apache-2.0 OR MIT","title":"ascii-canvas 3.0.0"},{"location":"policies/credits/#assert-json-diff-201","text":"repository: https://github.com/davidpdrsn/assert-json-diff.git license: MIT","title":"assert-json-diff 2.0.1"},{"location":"policies/credits/#assert_cmd-202","text":"repository: https://github.com/assert-rs/assert_cmd.git license: Apache-2.0 OR MIT","title":"assert_cmd 2.0.2"},{"location":"policies/credits/#async-channel-161","text":"repository: https://github.com/smol-rs/async-channel license: Apache-2.0 OR MIT","title":"async-channel 1.6.1"},{"location":"policies/credits/#async-compat-021","text":"repository: https://github.com/smol-rs/async-compat license: Apache-2.0 OR MIT","title":"async-compat 0.2.1"},{"location":"policies/credits/#async-executor-141","text":"repository: https://github.com/smol-rs/async-executor license: Apache-2.0 OR MIT","title":"async-executor 1.4.1"},{"location":"policies/credits/#async-global-executor-202","text":"repository: https://github.com/Keruspe/async-global-executor license: Apache-2.0 OR MIT","title":"async-global-executor 2.0.2"},{"location":"policies/credits/#async-io-160","text":"repository: https://github.com/smol-rs/async-io license: Apache-2.0 OR MIT","title":"async-io 1.6.0"},{"location":"policies/credits/#async-lock-240","text":"repository: https://github.com/smol-rs/async-lock license: Apache-2.0 OR MIT","title":"async-lock 2.4.0"},{"location":"policies/credits/#async-mutex-140","text":"repository: https://github.com/stjepang/async-lock license: Apache-2.0 OR MIT","title":"async-mutex 1.4.0"},{"location":"policies/credits/#async-object-pool-014","text":"repository: https://github.com/alexliesenfeld/async-object-pool license: MIT","title":"async-object-pool 0.1.4"},{"location":"policies/credits/#async-process-120","text":"repository: https://github.com/smol-rs/async-process license: Apache-2.0 OR MIT","title":"async-process 1.2.0"},{"location":"policies/credits/#async-raft-061","text":"repository: https://github.com/async-raft/async-raft license: Apache-2.0 OR MIT","title":"async-raft 0.6.1"},{"location":"policies/credits/#async-std-1100","text":"repository: https://github.com/async-rs/async-std license: Apache-2.0 OR MIT","title":"async-std 1.10.0"},{"location":"policies/credits/#async-stream-032","text":"repository: https://github.com/tokio-rs/async-stream license: MIT","title":"async-stream 0.3.2"},{"location":"policies/credits/#async-stream-impl-032","text":"repository: https://github.com/tokio-rs/async-stream license: MIT","title":"async-stream-impl 0.3.2"},{"location":"policies/credits/#async-task-403","text":"repository: https://github.com/stjepang/async-task license: Apache-2.0 OR MIT","title":"async-task 4.0.3"},{"location":"policies/credits/#async-trait-0151","text":"repository: https://github.com/dtolnay/async-trait license: Apache-2.0 OR MIT","title":"async-trait 0.1.51"},{"location":"policies/credits/#atomic-shim-010","text":"repository: https://github.com/bltavares/atomic-shim license: Apache-2.0 OR MIT","title":"atomic-shim 0.1.0"},{"location":"policies/credits/#atomic-waker-100","text":"repository: https://github.com/stjepang/atomic-waker license: Apache-2.0 OR MIT","title":"atomic-waker 1.0.0"},{"location":"policies/credits/#atty-0214","text":"repository: https://github.com/softprops/atty license: MIT","title":"atty 0.2.14"},{"location":"policies/credits/#autocfg-017","text":"repository: https://github.com/cuviper/autocfg license: Apache-2.0 OR MIT","title":"autocfg 0.1.7"},{"location":"policies/credits/#autocfg-101","text":"repository: https://github.com/cuviper/autocfg license: Apache-2.0 OR MIT","title":"autocfg 1.0.1"},{"location":"policies/credits/#axum-028","text":"repository: https://github.com/tokio-rs/axum license: MIT","title":"axum 0.2.8"},{"location":"policies/credits/#axum-server-025","text":"repository: https://github.com/programatik29/axum-server license: MIT","title":"axum-server 0.2.5"},{"location":"policies/credits/#azure_core_mirror-010","text":"repository: https://github.com/azure/azure-sdk-for-rust license: MIT","title":"azure_core_mirror 0.1.0"},{"location":"policies/credits/#azure_storage_mirror-010","text":"repository: https://github.com/azure/azure-sdk-for-rust license: MIT","title":"azure_storage_mirror 0.1.0"},{"location":"policies/credits/#backtrace-0362","text":"repository: https://github.com/rust-lang/backtrace-rs license: Apache-2.0 OR MIT","title":"backtrace 0.3.62"},{"location":"policies/credits/#base-x-028","text":"repository: https://github.com/OrKoN/base-x-rs license: MIT","title":"base-x 0.2.8"},{"location":"policies/credits/#base64-0123","text":"repository: https://github.com/marshallpierce/rust-base64 license: Apache-2.0 OR MIT","title":"base64 0.12.3"},{"location":"policies/credits/#base64-0130","text":"repository: https://github.com/marshallpierce/rust-base64 license: Apache-2.0 OR MIT","title":"base64 0.13.0"},{"location":"policies/credits/#base64ct-111","text":"repository: https://github.com/RustCrypto/formats/tree/master/base64ct license: Apache-2.0 OR MIT","title":"base64ct 1.1.1"},{"location":"policies/credits/#basic-cookies-014","text":"repository: https://github.com/drjokepu/basic-cookies license: MIT","title":"basic-cookies 0.1.4"},{"location":"policies/credits/#bendctl-010","text":"repository: None license: Apache-2.0","title":"bendctl 0.1.0"},{"location":"policies/credits/#bigdecimal-022","text":"repository: https://github.com/akubera/bigdecimal-rs license: Apache-2.0 OR MIT","title":"bigdecimal 0.2.2"},{"location":"policies/credits/#bindgen-0581","text":"repository: https://github.com/rust-lang/rust-bindgen license: BSD-3-Clause","title":"bindgen 0.58.1"},{"location":"policies/credits/#bit-set-052","text":"repository: https://github.com/contain-rs/bit-set license: Apache-2.0 OR MIT","title":"bit-set 0.5.2"},{"location":"policies/credits/#bit-vec-063","text":"repository: https://github.com/contain-rs/bit-vec license: Apache-2.0 OR MIT","title":"bit-vec 0.6.3"},{"location":"policies/credits/#bitflags-121","text":"repository: https://github.com/bitflags/bitflags license: Apache-2.0 OR MIT","title":"bitflags 1.2.1"},{"location":"policies/credits/#bitmaps-210","text":"repository: https://github.com/bodil/bitmaps license: MPL-2.0+","title":"bitmaps 2.1.0"},{"location":"policies/credits/#bitpacking-084","text":"repository: None license: MIT","title":"bitpacking 0.8.4"},{"location":"policies/credits/#bitvec-0223","text":"repository: https://github.com/myrrlyn/bitvec license: MIT","title":"bitvec 0.22.3"},{"location":"policies/credits/#block-buffer-073","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"block-buffer 0.7.3"},{"location":"policies/credits/#block-buffer-090","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"block-buffer 0.9.0"},{"location":"policies/credits/#block-padding-015","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"block-padding 0.1.5"},{"location":"policies/credits/#blocking-102","text":"repository: https://github.com/stjepang/blocking license: Apache-2.0 OR MIT","title":"blocking 1.0.2"},{"location":"policies/credits/#bstr-0217","text":"repository: https://github.com/BurntSushi/bstr license: Apache-2.0 OR MIT","title":"bstr 0.2.17"},{"location":"policies/credits/#bufstream-014","text":"repository: https://github.com/alexcrichton/bufstream license: Apache-2.0 OR MIT","title":"bufstream 0.1.4"},{"location":"policies/credits/#bumpalo-380","text":"repository: https://github.com/fitzgen/bumpalo license: Apache-2.0 OR MIT","title":"bumpalo 3.8.0"},{"location":"policies/credits/#byte-tools-031","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"byte-tools 0.3.1"},{"location":"policies/credits/#byte-unit-4013","text":"repository: https://github.com/magiclen/byte-unit license: MIT","title":"byte-unit 4.0.13"},{"location":"policies/credits/#bytecount-062","text":"repository: https://github.com/llogiq/bytecount license: Apache-2.0 OR MIT","title":"bytecount 0.6.2"},{"location":"policies/credits/#bytemuck-172","text":"repository: https://github.com/Lokathor/bytemuck license: Apache-2.0 OR MIT OR Zlib","title":"bytemuck 1.7.2"},{"location":"policies/credits/#byteorder-143","text":"repository: https://github.com/BurntSushi/byteorder license: MIT OR Unlicense","title":"byteorder 1.4.3"},{"location":"policies/credits/#bytes-110","text":"repository: https://github.com/tokio-rs/bytes license: MIT","title":"bytes 1.1.0"},{"location":"policies/credits/#cache-padded-111","text":"repository: https://github.com/stjepang/cache-padded license: Apache-2.0 OR MIT","title":"cache-padded 1.1.1"},{"location":"policies/credits/#camino-105","text":"repository: https://github.com/withoutboats/camino license: Apache-2.0 OR MIT","title":"camino 1.0.5"},{"location":"policies/credits/#cargo-license-042","text":"repository: https://github.com/onur/cargo-license license: MIT","title":"cargo-license 0.4.2"},{"location":"policies/credits/#cargo-platform-012","text":"repository: https://github.com/rust-lang/cargo license: Apache-2.0 OR MIT","title":"cargo-platform 0.1.2"},{"location":"policies/credits/#cargo_metadata-0123","text":"repository: https://github.com/oli-obk/cargo_metadata license: MIT","title":"cargo_metadata 0.12.3"},{"location":"policies/credits/#cargo_metadata-0141","text":"repository: https://github.com/oli-obk/cargo_metadata license: MIT","title":"cargo_metadata 0.14.1"},{"location":"policies/credits/#cast-027","text":"repository: https://github.com/japaric/cast.rs license: Apache-2.0 OR MIT","title":"cast 0.2.7"},{"location":"policies/credits/#castaway-011","text":"repository: https://github.com/sagebind/castaway license: MIT","title":"castaway 0.1.1"},{"location":"policies/credits/#cc-1071","text":"repository: https://github.com/alexcrichton/cc-rs license: Apache-2.0 OR MIT","title":"cc 1.0.71"},{"location":"policies/credits/#cexpr-040","text":"repository: https://github.com/jethrogb/rust-cexpr license: Apache-2.0 OR MIT","title":"cexpr 0.4.0"},{"location":"policies/credits/#cfg-if-0110","text":"repository: https://github.com/alexcrichton/cfg-if license: Apache-2.0 OR MIT","title":"cfg-if 0.1.10"},{"location":"policies/credits/#cfg-if-100","text":"repository: https://github.com/alexcrichton/cfg-if license: Apache-2.0 OR MIT","title":"cfg-if 1.0.0"},{"location":"policies/credits/#chrono-0419","text":"repository: https://github.com/chronotope/chrono license: Apache-2.0 OR MIT","title":"chrono 0.4.19"},{"location":"policies/credits/#chrono-tz-053","text":"repository: https://github.com/djzin/chrono-tz license: Apache-2.0 OR MIT","title":"chrono-tz 0.5.3"},{"location":"policies/credits/#chrono-tz-060","text":"repository: https://github.com/chronotope/chrono-tz license: Apache-2.0 OR MIT","title":"chrono-tz 0.6.0"},{"location":"policies/credits/#chrono-tz-build-002","text":"repository: None license: Apache-2.0 OR MIT","title":"chrono-tz-build 0.0.2"},{"location":"policies/credits/#chunked_transfer-140","text":"repository: https://github.com/frewsxcv/rust-chunked-transfer license: Apache-2.0","title":"chunked_transfer 1.4.0"},{"location":"policies/credits/#clang-sys-122","text":"repository: https://github.com/KyleMayes/clang-sys license: Apache-2.0","title":"clang-sys 1.2.2"},{"location":"policies/credits/#clap-2333","text":"repository: https://github.com/clap-rs/clap license: MIT","title":"clap 2.33.3"},{"location":"policies/credits/#clap-300-beta5","text":"repository: https://github.com/clap-rs/clap license: Apache-2.0 OR MIT","title":"clap 3.0.0-beta.5"},{"location":"policies/credits/#clap_derive-300-beta5","text":"repository: https://github.com/clap-rs/clap/tree/master/clap_derive license: Apache-2.0 OR MIT","title":"clap_derive 3.0.0-beta.5"},{"location":"policies/credits/#clap_generate-300-beta5","text":"repository: https://github.com/clap-rs/clap/tree/master/clap_generate license: Apache-2.0 OR MIT","title":"clap_generate 3.0.0-beta.5"},{"location":"policies/credits/#clickhouse-rs-100-alpha1","text":"repository: https://github.com/suharev7/clickhouse-rs license: MIT","title":"clickhouse-rs 1.0.0-alpha.1"},{"location":"policies/credits/#clickhouse-rs-cityhash-sys-012","text":"repository: None license: MIT","title":"clickhouse-rs-cityhash-sys 0.1.2"},{"location":"policies/credits/#clipboard-win-421","text":"repository: https://github.com/DoumanAsh/clipboard-win license: BSL-1.0","title":"clipboard-win 4.2.1"},{"location":"policies/credits/#cmake-0146","text":"repository: https://github.com/alexcrichton/cmake-rs license: Apache-2.0 OR MIT","title":"cmake 0.1.46"},{"location":"policies/credits/#coarsetime-0119","text":"repository: https://github.com/jedisct1/rust-coarsetime license: ISC","title":"coarsetime 0.1.19"},{"location":"policies/credits/#colored-200","text":"repository: https://github.com/mackwic/colored license: MPL-2.0","title":"colored 2.0.0"},{"location":"policies/credits/#combine-461","text":"repository: https://github.com/Marwes/combine license: MIT","title":"combine 4.6.1"},{"location":"policies/credits/#comfy-table-411","text":"repository: https://github.com/nukesor/comfy-table license: MIT","title":"comfy-table 4.1.1"},{"location":"policies/credits/#common-arrow-010","text":"repository: None license: Apache-2.0","title":"common-arrow 0.1.0"},{"location":"policies/credits/#common-base-010","text":"repository: None license: Apache-2.0","title":"common-base 0.1.0"},{"location":"policies/credits/#common-building-010","text":"repository: None license: Apache-2.0","title":"common-building 0.1.0"},{"location":"policies/credits/#common-cache-010","text":"repository: None license: Apache-2.0","title":"common-cache 0.1.0"},{"location":"policies/credits/#common-clickhouse-srv-032","text":"repository: None license: Apache-2.0","title":"common-clickhouse-srv 0.3.2"},{"location":"policies/credits/#common-context-010","text":"repository: None license: Apache-2.0","title":"common-context 0.1.0"},{"location":"policies/credits/#common-dal-010","text":"repository: None license: Apache-2.0","title":"common-dal 0.1.0"},{"location":"policies/credits/#common-datablocks-010","text":"repository: None license: Apache-2.0","title":"common-datablocks 0.1.0"},{"location":"policies/credits/#common-datavalues-010","text":"repository: None license: Apache-2.0","title":"common-datavalues 0.1.0"},{"location":"policies/credits/#common-exception-010","text":"repository: None license: Apache-2.0","title":"common-exception 0.1.0"},{"location":"policies/credits/#common-flight-rpc-010","text":"repository: None license: Apache-2.0","title":"common-flight-rpc 0.1.0"},{"location":"policies/credits/#common-functions-010","text":"repository: None license: Apache-2.0","title":"common-functions 0.1.0"},{"location":"policies/credits/#common-infallible-010","text":"repository: None license: Apache-2.0","title":"common-infallible 0.1.0"},{"location":"policies/credits/#common-io-010","text":"repository: None license: Apache-2.0","title":"common-io 0.1.0"},{"location":"policies/credits/#common-macros-010","text":"repository: None license: None","title":"common-macros 0.1.0"},{"location":"policies/credits/#common-management-010","text":"repository: None license: Apache-2.0","title":"common-management 0.1.0"},{"location":"policies/credits/#common-mem-allocator-010","text":"repository: None license: None","title":"common-mem-allocator 0.1.0"},{"location":"policies/credits/#common-meta-api-010","text":"repository: None license: Apache-2.0","title":"common-meta-api 0.1.0"},{"location":"policies/credits/#common-meta-embedded-010","text":"repository: None license: Apache-2.0","title":"common-meta-embedded 0.1.0"},{"location":"policies/credits/#common-meta-flight-010","text":"repository: None license: Apache-2.0","title":"common-meta-flight 0.1.0"},{"location":"policies/credits/#common-meta-raft-store-010","text":"repository: None license: Apache-2.0","title":"common-meta-raft-store 0.1.0"},{"location":"policies/credits/#common-meta-sled-store-010","text":"repository: None license: Apache-2.0","title":"common-meta-sled-store 0.1.0"},{"location":"policies/credits/#common-meta-types-010","text":"repository: None license: Apache-2.0","title":"common-meta-types 0.1.0"},{"location":"policies/credits/#common-metrics-010","text":"repository: None license: Apache-2.0","title":"common-metrics 0.1.0"},{"location":"policies/credits/#common-planners-010","text":"repository: None license: Apache-2.0","title":"common-planners 0.1.0"},{"location":"policies/credits/#common-streams-010","text":"repository: None license: Apache-2.0","title":"common-streams 0.1.0"},{"location":"policies/credits/#common-tracing-010","text":"repository: None license: Apache-2.0","title":"common-tracing 0.1.0"},{"location":"policies/credits/#concurrent-queue-122","text":"repository: https://github.com/stjepang/concurrent-queue license: Apache-2.0 OR MIT","title":"concurrent-queue 1.2.2"},{"location":"policies/credits/#console-0150","text":"repository: https://github.com/mitsuhiko/console license: MIT","title":"console 0.15.0"},{"location":"policies/credits/#const-oid-062","text":"repository: https://github.com/RustCrypto/formats/tree/master/const-oid license: Apache-2.0 OR MIT","title":"const-oid 0.6.2"},{"location":"policies/credits/#const_fn-048","text":"repository: https://github.com/taiki-e/const_fn license: Apache-2.0 OR MIT","title":"const_fn 0.4.8"},{"location":"policies/credits/#core-foundation-092","text":"repository: https://github.com/servo/core-foundation-rs license: Apache-2.0 OR MIT","title":"core-foundation 0.9.2"},{"location":"policies/credits/#core-foundation-sys-083","text":"repository: https://github.com/servo/core-foundation-rs license: Apache-2.0 OR MIT","title":"core-foundation-sys 0.8.3"},{"location":"policies/credits/#cpp_demangle-033","text":"repository: https://github.com/gimli-rs/cpp_demangle license: Apache-2.0 OR MIT","title":"cpp_demangle 0.3.3"},{"location":"policies/credits/#cpufeatures-021","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"cpufeatures 0.2.1"},{"location":"policies/credits/#crc32fast-121","text":"repository: https://github.com/srijs/rust-crc32fast license: Apache-2.0 OR MIT","title":"crc32fast 1.2.1"},{"location":"policies/credits/#criterion-035","text":"repository: https://github.com/bheisler/criterion.rs license: Apache-2.0 OR MIT","title":"criterion 0.3.5"},{"location":"policies/credits/#criterion-plot-044","text":"repository: https://github.com/bheisler/criterion.rs license: Apache-2.0 OR MIT","title":"criterion-plot 0.4.4"},{"location":"policies/credits/#crossbeam-073","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam 0.7.3"},{"location":"policies/credits/#crossbeam-081","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam 0.8.1"},{"location":"policies/credits/#crossbeam-channel-044","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-channel 0.4.4"},{"location":"policies/credits/#crossbeam-channel-051","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-channel 0.5.1"},{"location":"policies/credits/#crossbeam-deque-074","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-deque 0.7.4"},{"location":"policies/credits/#crossbeam-deque-081","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-deque 0.8.1"},{"location":"policies/credits/#crossbeam-epoch-082","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-epoch 0.8.2"},{"location":"policies/credits/#crossbeam-epoch-095","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-epoch 0.9.5"},{"location":"policies/credits/#crossbeam-queue-023","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 AND BSD-2-Clause OR MIT","title":"crossbeam-queue 0.2.3"},{"location":"policies/credits/#crossbeam-queue-032","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-queue 0.3.2"},{"location":"policies/credits/#crossbeam-utils-072","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-utils 0.7.2"},{"location":"policies/credits/#crossbeam-utils-085","text":"repository: https://github.com/crossbeam-rs/crossbeam license: Apache-2.0 OR MIT","title":"crossbeam-utils 0.8.5"},{"location":"policies/credits/#crossterm-0200","text":"repository: https://github.com/crossterm-rs/crossterm license: MIT","title":"crossterm 0.20.0"},{"location":"policies/credits/#crossterm_winapi-080","text":"repository: https://github.com/crossterm-rs/crossterm-winapi license: MIT","title":"crossterm_winapi 0.8.0"},{"location":"policies/credits/#crunchy-022","text":"repository: None license: MIT","title":"crunchy 0.2.2"},{"location":"policies/credits/#crypto-bigint-0211","text":"repository: https://github.com/RustCrypto/crypto-bigint license: Apache-2.0 OR MIT","title":"crypto-bigint 0.2.11"},{"location":"policies/credits/#crypto-mac-0111","text":"repository: https://github.com/RustCrypto/traits license: Apache-2.0 OR MIT","title":"crypto-mac 0.11.1"},{"location":"policies/credits/#csv-116","text":"repository: https://github.com/BurntSushi/rust-csv license: MIT OR Unlicense","title":"csv 1.1.6"},{"location":"policies/credits/#csv-core-0110","text":"repository: https://github.com/BurntSushi/rust-csv license: MIT OR Unlicense","title":"csv-core 0.1.10"},{"location":"policies/credits/#ct-codecs-111","text":"repository: https://github.com/jedisct1/rust-ct-codecs license: MIT","title":"ct-codecs 1.1.1"},{"location":"policies/credits/#ct-logs-080","text":"repository: https://github.com/ctz/ct-logs license: Apache-2.0 OR ISC OR MIT","title":"ct-logs 0.8.0"},{"location":"policies/credits/#ctor-0121","text":"repository: https://github.com/mmastrac/rust-ctor license: Apache-2.0 OR MIT","title":"ctor 0.1.21"},{"location":"policies/credits/#ctrlc-320","text":"repository: https://github.com/Detegr/rust-ctrlc.git license: Apache-2.0 OR MIT","title":"ctrlc 3.2.0"},{"location":"policies/credits/#curl-0439","text":"repository: https://github.com/alexcrichton/curl-rust license: MIT","title":"curl 0.4.39"},{"location":"policies/credits/#curl-sys-0449curl-7791","text":"repository: https://github.com/alexcrichton/curl-rust license: MIT","title":"curl-sys 0.4.49+curl-7.79.1"},{"location":"policies/credits/#dashmap-402","text":"repository: https://github.com/xacrimon/dashmap license: MIT","title":"dashmap 4.0.2"},{"location":"policies/credits/#data-encoding-232","text":"repository: https://github.com/ia0/data-encoding license: MIT","title":"data-encoding 2.3.2"},{"location":"policies/credits/#databend-meta-010","text":"repository: None license: Apache-2.0","title":"databend-meta 0.1.0"},{"location":"policies/credits/#databend-query-010","text":"repository: None license: Apache-2.0","title":"databend-query 0.1.0"},{"location":"policies/credits/#debugid-072","text":"repository: https://github.com/getsentry/rust-debugid license: Apache-2.0","title":"debugid 0.7.2"},{"location":"policies/credits/#der-044","text":"repository: https://github.com/RustCrypto/formats/tree/master/der license: Apache-2.0 OR MIT","title":"der 0.4.4"},{"location":"policies/credits/#derive_more-09916","text":"repository: https://github.com/JelteF/derive_more license: MIT","title":"derive_more 0.99.16"},{"location":"policies/credits/#derive_utils-0112","text":"repository: https://github.com/taiki-e/derive_utils license: Apache-2.0 OR MIT","title":"derive_utils 0.11.2"},{"location":"policies/credits/#diff-0112","text":"repository: https://github.com/utkarshkukreti/diff.rs license: Apache-2.0 OR MIT","title":"diff 0.1.12"},{"location":"policies/credits/#difference-200","text":"repository: https://github.com/johannhof/difference.rs license: MIT","title":"difference 2.0.0"},{"location":"policies/credits/#difflib-040","text":"repository: https://github.com/DimaKudosh/difflib license: MIT","title":"difflib 0.4.0"},{"location":"policies/credits/#digest-081","text":"repository: https://github.com/RustCrypto/traits license: Apache-2.0 OR MIT","title":"digest 0.8.1"},{"location":"policies/credits/#digest-090","text":"repository: https://github.com/RustCrypto/traits license: Apache-2.0 OR MIT","title":"digest 0.9.0"},{"location":"policies/credits/#dirs-400","text":"repository: https://github.com/soc/dirs-rs license: Apache-2.0 OR MIT","title":"dirs 4.0.0"},{"location":"policies/credits/#dirs-next-200","text":"repository: https://github.com/xdg-rs/dirs license: Apache-2.0 OR MIT","title":"dirs-next 2.0.0"},{"location":"policies/credits/#dirs-sys-036","text":"repository: https://github.com/dirs-dev/dirs-sys-rs license: Apache-2.0 OR MIT","title":"dirs-sys 0.3.6"},{"location":"policies/credits/#dirs-sys-next-012","text":"repository: https://github.com/xdg-rs/dirs/tree/master/dirs-sys license: Apache-2.0 OR MIT","title":"dirs-sys-next 0.1.2"},{"location":"policies/credits/#discard-104","text":"repository: https://github.com/Pauan/rust-discard license: MIT","title":"discard 1.0.4"},{"location":"policies/credits/#doc-comment-033","text":"repository: https://github.com/GuillaumeGomez/doc-comment license: MIT","title":"doc-comment 0.3.3"},{"location":"policies/credits/#downcast-0100","text":"repository: https://github.com/fkoep/downcast-rs license: MIT","title":"downcast 0.10.0"},{"location":"policies/credits/#dtoa-048","text":"repository: https://github.com/dtolnay/dtoa license: Apache-2.0 OR MIT","title":"dtoa 0.4.8"},{"location":"policies/credits/#dunce-102","text":"repository: https://gitlab.com/kornelski/dunce license: CC0-1.0","title":"dunce 1.0.2"},{"location":"policies/credits/#dyn-clone-104","text":"repository: https://github.com/dtolnay/dyn-clone license: Apache-2.0 OR MIT","title":"dyn-clone 1.0.4"},{"location":"policies/credits/#ecdsa-0124","text":"repository: https://github.com/RustCrypto/signatures license: Apache-2.0 OR MIT","title":"ecdsa 0.12.4"},{"location":"policies/credits/#ed25519-compact-0111","text":"repository: https://github.com/jedisct1/rust-ed25519-compact license: ISC","title":"ed25519-compact 0.1.11"},{"location":"policies/credits/#either-161","text":"repository: https://github.com/bluss/either license: Apache-2.0 OR MIT","title":"either 1.6.1"},{"location":"policies/credits/#elliptic-curve-0106","text":"repository: https://github.com/RustCrypto/traits/tree/master/elliptic-curve license: Apache-2.0 OR MIT","title":"elliptic-curve 0.10.6"},{"location":"policies/credits/#ena-0140","text":"repository: https://github.com/rust-lang-nursery/ena license: Apache-2.0 OR MIT","title":"ena 0.14.0"},{"location":"policies/credits/#encode_unicode-036","text":"repository: https://github.com/tormol/encode_unicode license: Apache-2.0 OR MIT","title":"encode_unicode 0.3.6"},{"location":"policies/credits/#encoding_rs-0829","text":"repository: https://github.com/hsivonen/encoding_rs license: Apache-2.0 OR MIT","title":"encoding_rs 0.8.29"},{"location":"policies/credits/#endian-type-012","text":"repository: https://github.com/Lolirofle/endian-type.git license: MIT","title":"endian-type 0.1.2"},{"location":"policies/credits/#enum-as-inner-033","text":"repository: https://github.com/bluejekyll/enum-as-inner license: Apache-2.0 OR MIT","title":"enum-as-inner 0.3.3"},{"location":"policies/credits/#enum-iterator-070","text":"repository: https://github.com/stephaneyfx/enum-iterator.git license: 0BSD","title":"enum-iterator 0.7.0"},{"location":"policies/credits/#enum-iterator-derive-070","text":"repository: https://github.com/stephaneyfx/enum-iterator.git license: 0BSD","title":"enum-iterator-derive 0.7.0"},{"location":"policies/credits/#env_logger-084","text":"repository: https://github.com/env-logger-rs/env_logger/ license: Apache-2.0 OR MIT","title":"env_logger 0.8.4"},{"location":"policies/credits/#env_logger-090","text":"repository: https://github.com/env-logger-rs/env_logger/ license: Apache-2.0 OR MIT","title":"env_logger 0.9.0"},{"location":"policies/credits/#error-chain-0124","text":"repository: https://github.com/rust-lang-nursery/error-chain license: Apache-2.0 OR MIT","title":"error-chain 0.12.4"},{"location":"policies/credits/#error-code-230","text":"repository: https://github.com/DoumanAsh/error-code license: BSL-1.0","title":"error-code 2.3.0"},{"location":"policies/credits/#event-listener-251","text":"repository: https://github.com/stjepang/event-listener license: Apache-2.0 OR MIT","title":"event-listener 2.5.1"},{"location":"policies/credits/#failure-018","text":"repository: https://github.com/rust-lang-nursery/failure license: Apache-2.0 OR MIT","title":"failure 0.1.8"},{"location":"policies/credits/#failure_derive-018","text":"repository: https://github.com/rust-lang-nursery/failure license: Apache-2.0 OR MIT","title":"failure_derive 0.1.8"},{"location":"policies/credits/#fake-simd-012","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"fake-simd 0.1.2"},{"location":"policies/credits/#fallible-streaming-iterator-019","text":"repository: https://github.com/sfackler/fallible-streaming-iterator license: Apache-2.0 OR MIT","title":"fallible-streaming-iterator 0.1.9"},{"location":"policies/credits/#fastrand-150","text":"repository: https://github.com/smol-rs/fastrand license: Apache-2.0 OR MIT","title":"fastrand 1.5.0"},{"location":"policies/credits/#fd-lock-300","text":"repository: https://github.com/yoshuawuyts/fd-lock license: Apache-2.0 OR MIT","title":"fd-lock 3.0.0"},{"location":"policies/credits/#ff-0101","text":"repository: https://github.com/zkcrypto/ff license: Apache-2.0 OR MIT","title":"ff 0.10.1"},{"location":"policies/credits/#filetime-0215","text":"repository: https://github.com/alexcrichton/filetime license: Apache-2.0 OR MIT","title":"filetime 0.2.15"},{"location":"policies/credits/#fixedbitset-020","text":"repository: https://github.com/bluss/fixedbitset license: Apache-2.0 OR MIT","title":"fixedbitset 0.2.0"},{"location":"policies/credits/#flaky_test-010","text":"repository: https://github.com/denoland/flaky_test license: MIT","title":"flaky_test 0.1.0"},{"location":"policies/credits/#flatbuffers-200","text":"repository: https://github.com/google/flatbuffers license: Apache-2.0","title":"flatbuffers 2.0.0"},{"location":"policies/credits/#flate2-1022","text":"repository: https://github.com/rust-lang/flate2-rs license: Apache-2.0 OR MIT","title":"flate2 1.0.22"},{"location":"policies/credits/#float-cmp-080","text":"repository: https://github.com/mikedilger/float-cmp license: MIT","title":"float-cmp 0.8.0"},{"location":"policies/credits/#float-cmp-090","text":"repository: https://github.com/mikedilger/float-cmp license: MIT","title":"float-cmp 0.9.0"},{"location":"policies/credits/#fnv-107","text":"repository: https://github.com/servo/rust-fnv license: Apache-2.0 OR MIT","title":"fnv 1.0.7"},{"location":"policies/credits/#foreign-types-032","text":"repository: https://github.com/sfackler/foreign-types license: Apache-2.0 OR MIT","title":"foreign-types 0.3.2"},{"location":"policies/credits/#foreign-types-shared-011","text":"repository: https://github.com/sfackler/foreign-types license: Apache-2.0 OR MIT","title":"foreign-types-shared 0.1.1"},{"location":"policies/credits/#form_urlencoded-101","text":"repository: https://github.com/servo/rust-url license: Apache-2.0 OR MIT","title":"form_urlencoded 1.0.1"},{"location":"policies/credits/#fragile-100","text":"repository: https://github.com/mitsuhiko/rust-fragile license: Apache-2.0","title":"fragile 1.0.0"},{"location":"policies/credits/#frunk-040","text":"repository: https://github.com/lloydmeta/frunk license: MIT","title":"frunk 0.4.0"},{"location":"policies/credits/#frunk_core-040","text":"repository: https://github.com/lloydmeta/frunk license: MIT","title":"frunk_core 0.4.0"},{"location":"policies/credits/#frunk_derives-040","text":"repository: https://github.com/lloydmeta/frunk license: MIT","title":"frunk_derives 0.4.0"},{"location":"policies/credits/#frunk_proc_macro_helpers-010","text":"repository: https://github.com/lloydmeta/frunk license: MIT","title":"frunk_proc_macro_helpers 0.1.0"},{"location":"policies/credits/#frunk_proc_macros-010","text":"repository: https://github.com/lloydmeta/frunk license: MIT","title":"frunk_proc_macros 0.1.0"},{"location":"policies/credits/#frunk_proc_macros_impl-010","text":"repository: https://github.com/lloydmeta/frunk license: MIT","title":"frunk_proc_macros_impl 0.1.0"},{"location":"policies/credits/#fs2-043","text":"repository: https://github.com/danburkert/fs2-rs license: Apache-2.0 OR MIT","title":"fs2 0.4.3"},{"location":"policies/credits/#fs_extra-120","text":"repository: https://github.com/webdesus/fs_extra license: MIT","title":"fs_extra 1.2.0"},{"location":"policies/credits/#fsio-030","text":"repository: https://github.com/sagiegurari/fsio.git license: Apache-2.0","title":"fsio 0.3.0"},{"location":"policies/credits/#funty-120","text":"repository: https://github.com/myrrlyn/funty license: MIT","title":"funty 1.2.0"},{"location":"policies/credits/#futures-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures 0.3.17"},{"location":"policies/credits/#futures-channel-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-channel 0.3.17"},{"location":"policies/credits/#futures-core-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-core 0.3.17"},{"location":"policies/credits/#futures-executor-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-executor 0.3.17"},{"location":"policies/credits/#futures-io-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-io 0.3.17"},{"location":"policies/credits/#futures-lite-1120","text":"repository: https://github.com/smol-rs/futures-lite license: Apache-2.0 OR MIT","title":"futures-lite 1.12.0"},{"location":"policies/credits/#futures-macro-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-macro 0.3.17"},{"location":"policies/credits/#futures-sink-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-sink 0.3.17"},{"location":"policies/credits/#futures-task-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-task 0.3.17"},{"location":"policies/credits/#futures-util-0317","text":"repository: https://github.com/rust-lang/futures-rs license: Apache-2.0 OR MIT","title":"futures-util 0.3.17"},{"location":"policies/credits/#fuzz-010","text":"repository: None license: None","title":"fuzz 0.1.0"},{"location":"policies/credits/#generic-array-0124","text":"repository: https://github.com/fizyk20/generic-array.git license: MIT","title":"generic-array 0.12.4"},{"location":"policies/credits/#generic-array-0144","text":"repository: https://github.com/fizyk20/generic-array.git license: MIT","title":"generic-array 0.14.4"},{"location":"policies/credits/#gethostname-021","text":"repository: https://github.com/lunaryorn/gethostname.rs.git license: Apache-2.0","title":"gethostname 0.2.1"},{"location":"policies/credits/#getopts-0221","text":"repository: https://github.com/rust-lang/getopts license: Apache-2.0 OR MIT","title":"getopts 0.2.21"},{"location":"policies/credits/#getrandom-0116","text":"repository: https://github.com/rust-random/getrandom license: Apache-2.0 OR MIT","title":"getrandom 0.1.16"},{"location":"policies/credits/#getrandom-023","text":"repository: https://github.com/rust-random/getrandom license: Apache-2.0 OR MIT","title":"getrandom 0.2.3"},{"location":"policies/credits/#getset-011","text":"repository: https://github.com/Hoverbear/getset license: MIT","title":"getset 0.1.1"},{"location":"policies/credits/#gimli-0250","text":"repository: https://github.com/gimli-rs/gimli license: Apache-2.0 OR MIT","title":"gimli 0.25.0"},{"location":"policies/credits/#git2-01323","text":"repository: https://github.com/rust-lang/git2-rs license: Apache-2.0 OR MIT","title":"git2 0.13.23"},{"location":"policies/credits/#glob-030","text":"repository: https://github.com/rust-lang/glob license: Apache-2.0 OR MIT","title":"glob 0.3.0"},{"location":"policies/credits/#gloo-timers-021","text":"repository: https://github.com/rustwasm/gloo/tree/master/crates/timers license: Apache-2.0 OR MIT","title":"gloo-timers 0.2.1"},{"location":"policies/credits/#group-0100","text":"repository: https://github.com/zkcrypto/group license: Apache-2.0 OR MIT","title":"group 0.10.0"},{"location":"policies/credits/#h2-036","text":"repository: https://github.com/hyperium/h2 license: MIT","title":"h2 0.3.6"},{"location":"policies/credits/#half-180","text":"repository: https://github.com/starkat99/half-rs license: Apache-2.0 OR MIT","title":"half 1.8.0"},{"location":"policies/credits/#handlebars-413","text":"repository: https://github.com/sunng87/handlebars-rust license: MIT","title":"handlebars 4.1.3"},{"location":"policies/credits/#hash_hasher-203","text":"repository: https://github.com/Fraser999/Hash-Hasher.git license: Apache-2.0 OR MIT","title":"hash_hasher 2.0.3"},{"location":"policies/credits/#hashbrown-0112","text":"repository: https://github.com/rust-lang/hashbrown license: Apache-2.0 OR MIT","title":"hashbrown 0.11.2"},{"location":"policies/credits/#headers-035","text":"repository: https://github.com/hyperium/headers license: MIT","title":"headers 0.3.5"},{"location":"policies/credits/#headers-core-020","text":"repository: https://github.com/hyperium/headers license: MIT","title":"headers-core 0.2.0"},{"location":"policies/credits/#heck-033","text":"repository: https://github.com/withoutboats/heck license: Apache-2.0 OR MIT","title":"heck 0.3.3"},{"location":"policies/credits/#hermit-abi-0119","text":"repository: https://github.com/hermitcore/libhermit-rs license: Apache-2.0 OR MIT","title":"hermit-abi 0.1.19"},{"location":"policies/credits/#hex-043","text":"repository: https://github.com/KokaKiwi/rust-hex license: Apache-2.0 OR MIT","title":"hex 0.4.3"},{"location":"policies/credits/#hmac-0110","text":"repository: https://github.com/RustCrypto/MACs license: Apache-2.0 OR MIT","title":"hmac 0.11.0"},{"location":"policies/credits/#hmac-sha256-017","text":"repository: https://github.com/jedisct1/rust-hmac-sha256 license: ISC","title":"hmac-sha256 0.1.7"},{"location":"policies/credits/#hmac-sha512-019","text":"repository: https://github.com/jedisct1/rust-hmac-sha512 license: ISC","title":"hmac-sha512 0.1.9"},{"location":"policies/credits/#honggfuzz-0554","text":"repository: https://github.com/rust-fuzz/honggfuzz-rs license: Apache-2.0 OR MIT OR Unlicense OR WTFPL","title":"honggfuzz 0.5.54"},{"location":"policies/credits/#hostname-031","text":"repository: https://github.com/svartalf/hostname license: MIT","title":"hostname 0.3.1"},{"location":"policies/credits/#http-025","text":"repository: https://github.com/hyperium/http license: Apache-2.0 OR MIT","title":"http 0.2.5"},{"location":"policies/credits/#http-body-043","text":"repository: https://github.com/hyperium/http-body license: MIT","title":"http-body 0.4.3"},{"location":"policies/credits/#httparse-151","text":"repository: https://github.com/seanmonstar/httparse license: Apache-2.0 OR MIT","title":"httparse 1.5.1"},{"location":"policies/credits/#httpdate-101","text":"repository: https://github.com/pyfisch/httpdate license: Apache-2.0 OR MIT","title":"httpdate 1.0.1"},{"location":"policies/credits/#httpmock-062","text":"repository: https://github.com/alexliesenfeld/httpmock license: MIT","title":"httpmock 0.6.2"},{"location":"policies/credits/#humantime-210","text":"repository: https://github.com/tailhook/humantime license: Apache-2.0 OR MIT","title":"humantime 2.1.0"},{"location":"policies/credits/#hyper-01414","text":"repository: https://github.com/hyperium/hyper license: MIT","title":"hyper 0.14.14"},{"location":"policies/credits/#hyper-rustls-0221","text":"repository: https://github.com/ctz/hyper-rustls license: Apache-2.0 OR ISC OR MIT","title":"hyper-rustls 0.22.1"},{"location":"policies/credits/#hyper-timeout-041","text":"repository: https://github.com/hjr3/hyper-timeout license: Apache-2.0 OR MIT","title":"hyper-timeout 0.4.1"},{"location":"policies/credits/#hyper-tls-050","text":"repository: https://github.com/hyperium/hyper-tls license: Apache-2.0 OR MIT","title":"hyper-tls 0.5.0"},{"location":"policies/credits/#idna-023","text":"repository: https://github.com/servo/rust-url/ license: Apache-2.0 OR MIT","title":"idna 0.2.3"},{"location":"policies/credits/#im-1500","text":"repository: https://github.com/bodil/im-rs license: MPL-2.0+","title":"im 15.0.0"},{"location":"policies/credits/#indexmap-170","text":"repository: https://github.com/bluss/indexmap license: Apache-2.0 OR MIT","title":"indexmap 1.7.0"},{"location":"policies/credits/#indicatif-0162","text":"repository: https://github.com/mitsuhiko/indicatif license: MIT","title":"indicatif 0.16.2"},{"location":"policies/credits/#inferno-0107","text":"repository: https://github.com/jonhoo/inferno.git license: CDDL-1.0","title":"inferno 0.10.7"},{"location":"policies/credits/#instant-0112","text":"repository: https://github.com/sebcrozet/instant license: BSD-3-Clause","title":"instant 0.1.12"},{"location":"policies/credits/#integer-encoding-117","text":"repository: https://github.com/dermesser/integer-encoding-rs license: MIT","title":"integer-encoding 1.1.7"},{"location":"policies/credits/#integer-encoding-302","text":"repository: https://github.com/dermesser/integer-encoding-rs license: MIT","title":"integer-encoding 3.0.2"},{"location":"policies/credits/#io-enum-101","text":"repository: https://github.com/taiki-e/io-enum license: Apache-2.0 OR MIT","title":"io-enum 1.0.1"},{"location":"policies/credits/#ipconfig-022","text":"repository: https://github.com/liranringel/ipconfig license: Apache-2.0 OR MIT","title":"ipconfig 0.2.2"},{"location":"policies/credits/#ipnet-231","text":"repository: https://github.com/krisprice/ipnet license: Apache-2.0 OR MIT","title":"ipnet 2.3.1"},{"location":"policies/credits/#isahc-151","text":"repository: https://github.com/sagebind/isahc license: MIT","title":"isahc 1.5.1"},{"location":"policies/credits/#itertools-0101","text":"repository: https://github.com/rust-itertools/itertools license: Apache-2.0 OR MIT","title":"itertools 0.10.1"},{"location":"policies/credits/#itoa-048","text":"repository: https://github.com/dtolnay/itoa license: Apache-2.0 OR MIT","title":"itoa 0.4.8"},{"location":"policies/credits/#jobserver-0124","text":"repository: https://github.com/alexcrichton/jobserver-rs license: Apache-2.0 OR MIT","title":"jobserver 0.1.24"},{"location":"policies/credits/#js-sys-0355","text":"repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/js-sys license: Apache-2.0 OR MIT","title":"js-sys 0.3.55"},{"location":"policies/credits/#jwt-simple-0106","text":"repository: https://github.com/jedisct1/rust-jwt-simple license: ISC","title":"jwt-simple 0.10.6"},{"location":"policies/credits/#k256-096","text":"repository: https://github.com/RustCrypto/elliptic-curves/tree/master/k256 license: Apache-2.0 OR MIT","title":"k256 0.9.6"},{"location":"policies/credits/#kv-log-macro-107","text":"repository: https://github.com/yoshuawuyts/kv-log-macro license: Apache-2.0 OR MIT","title":"kv-log-macro 1.0.7"},{"location":"policies/credits/#lalrpop-0196","text":"repository: https://github.com/lalrpop/lalrpop license: Apache-2.0 OR MIT","title":"lalrpop 0.19.6"},{"location":"policies/credits/#lalrpop-util-0196","text":"repository: https://github.com/lalrpop/lalrpop license: Apache-2.0 OR MIT","title":"lalrpop-util 0.19.6"},{"location":"policies/credits/#lazy_static-140","text":"repository: https://github.com/rust-lang-nursery/lazy-static.rs license: Apache-2.0 OR MIT","title":"lazy_static 1.4.0"},{"location":"policies/credits/#lazycell-130","text":"repository: https://github.com/indiv0/lazycell license: Apache-2.0 OR MIT","title":"lazycell 1.3.0"},{"location":"policies/credits/#levenshtein-105","text":"repository: https://github.com/wooorm/levenshtein-rs license: MIT","title":"levenshtein 1.0.5"},{"location":"policies/credits/#lexical-522","text":"repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT","title":"lexical 5.2.2"},{"location":"policies/credits/#lexical-core-076","text":"repository: https://github.com/Alexhuszagh/rust-lexical/tree/master/lexical-core license: Apache-2.0 OR MIT","title":"lexical-core 0.7.6"},{"location":"policies/credits/#lexical-core-082","text":"repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT","title":"lexical-core 0.8.2"},{"location":"policies/credits/#lexical-parse-float-082","text":"repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT","title":"lexical-parse-float 0.8.2"},{"location":"policies/credits/#lexical-parse-integer-080","text":"repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT","title":"lexical-parse-integer 0.8.0"},{"location":"policies/credits/#lexical-util-081","text":"repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT","title":"lexical-util 0.8.1"},{"location":"policies/credits/#lexical-write-float-082","text":"repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT","title":"lexical-write-float 0.8.2"},{"location":"policies/credits/#lexical-write-integer-080","text":"repository: https://github.com/Alexhuszagh/rust-lexical license: Apache-2.0 OR MIT","title":"lexical-write-integer 0.8.0"},{"location":"policies/credits/#libc-02104","text":"repository: https://github.com/rust-lang/libc license: Apache-2.0 OR MIT","title":"libc 0.2.104"},{"location":"policies/credits/#libgit2-sys-01224130","text":"repository: https://github.com/rust-lang/git2-rs license: Apache-2.0 OR MIT","title":"libgit2-sys 0.12.24+1.3.0"},{"location":"policies/credits/#libloading-071","text":"repository: https://github.com/nagisa/rust_libloading/ license: ISC","title":"libloading 0.7.1"},{"location":"policies/credits/#libm-014","text":"repository: https://github.com/rust-lang-nursery/libm license: Apache-2.0 OR MIT","title":"libm 0.1.4"},{"location":"policies/credits/#libm-021","text":"repository: https://github.com/rust-lang/libm license: Apache-2.0 OR MIT","title":"libm 0.2.1"},{"location":"policies/credits/#libnghttp2-sys-0171450","text":"repository: https://github.com/alexcrichton/nghttp2-rs license: Apache-2.0 OR MIT","title":"libnghttp2-sys 0.1.7+1.45.0"},{"location":"policies/credits/#libz-sys-113","text":"repository: https://github.com/rust-lang/libz-sys license: Apache-2.0 OR MIT","title":"libz-sys 1.1.3"},{"location":"policies/credits/#linked-hash-map-054","text":"repository: https://github.com/contain-rs/linked-hash-map license: Apache-2.0 OR MIT","title":"linked-hash-map 0.5.4"},{"location":"policies/credits/#lock_api-045","text":"repository: https://github.com/Amanieu/parking_lot license: Apache-2.0 OR MIT","title":"lock_api 0.4.5"},{"location":"policies/credits/#log-0414","text":"repository: https://github.com/rust-lang/log license: Apache-2.0 OR MIT","title":"log 0.4.14"},{"location":"policies/credits/#lru-066","text":"repository: https://github.com/jeromefroe/lru-rs.git license: MIT","title":"lru 0.6.6"},{"location":"policies/credits/#lru-cache-012","text":"repository: https://github.com/contain-rs/lru-cache license: Apache-2.0 OR MIT","title":"lru-cache 0.1.2"},{"location":"policies/credits/#lz4-1232","text":"repository: https://github.com/10xGenomics/lz4-rs license: MIT","title":"lz4 1.23.2"},{"location":"policies/credits/#lz4-sys-192","text":"repository: https://github.com/bozaro/lz4-rs license: MIT","title":"lz4-sys 1.9.2"},{"location":"policies/credits/#mach-032","text":"repository: https://github.com/fitzgen/mach license: BSD-2-Clause","title":"mach 0.3.2"},{"location":"policies/credits/#maplit-102","text":"repository: https://github.com/bluss/maplit license: Apache-2.0 OR MIT","title":"maplit 1.0.2"},{"location":"policies/credits/#match_cfg-010","text":"repository: https://github.com/gnzlbg/match_cfg license: Apache-2.0 OR MIT","title":"match_cfg 0.1.0"},{"location":"policies/credits/#matchers-001","text":"repository: https://github.com/hawkw/matchers license: MIT","title":"matchers 0.0.1"},{"location":"policies/credits/#matches-019","text":"repository: https://github.com/SimonSapin/rust-std-candidates license: MIT","title":"matches 0.1.9"},{"location":"policies/credits/#maybe-uninit-200","text":"repository: https://github.com/est31/maybe-uninit license: Apache-2.0 OR MIT","title":"maybe-uninit 2.0.0"},{"location":"policies/credits/#md-5-091","text":"repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT","title":"md-5 0.9.1"},{"location":"policies/credits/#md5-070","text":"repository: https://github.com/stainless-steel/md5 license: Apache-2.0 OR MIT","title":"md5 0.7.0"},{"location":"policies/credits/#memchr-241","text":"repository: https://github.com/BurntSushi/memchr license: MIT OR Unlicense","title":"memchr 2.4.1"},{"location":"policies/credits/#memmap-070","text":"repository: https://github.com/danburkert/memmap-rs license: Apache-2.0 OR MIT","title":"memmap 0.7.0"},{"location":"policies/credits/#memoffset-056","text":"repository: https://github.com/Gilnaa/memoffset license: MIT","title":"memoffset 0.5.6"},{"location":"policies/credits/#memoffset-064","text":"repository: https://github.com/Gilnaa/memoffset license: MIT","title":"memoffset 0.6.4"},{"location":"policies/credits/#metrics-0170","text":"repository: https://github.com/metrics-rs/metrics license: MIT","title":"metrics 0.17.0"},{"location":"policies/credits/#metrics-exporter-prometheus-061","text":"repository: https://github.com/metrics-rs/metrics license: MIT","title":"metrics-exporter-prometheus 0.6.1"},{"location":"policies/credits/#metrics-macros-040","text":"repository: https://github.com/metrics-rs/metrics license: MIT","title":"metrics-macros 0.4.0"},{"location":"policies/credits/#metrics-util-0101","text":"repository: https://github.com/metrics-rs/metrics license: MIT","title":"metrics-util 0.10.1"},{"location":"policies/credits/#mime-0316","text":"repository: https://github.com/hyperium/mime license: Apache-2.0 OR MIT","title":"mime 0.3.16"},{"location":"policies/credits/#minimal-lexical-014","text":"repository: https://github.com/Alexhuszagh/minimal-lexical license: Apache-2.0 OR MIT","title":"minimal-lexical 0.1.4"},{"location":"policies/credits/#miniz_oxide-044","text":"repository: https://github.com/Frommi/miniz_oxide/tree/master/miniz_oxide license: Apache-2.0 OR MIT OR Zlib","title":"miniz_oxide 0.4.4"},{"location":"policies/credits/#mio-0714","text":"repository: https://github.com/tokio-rs/mio license: MIT","title":"mio 0.7.14"},{"location":"policies/credits/#miow-037","text":"repository: https://github.com/yoshuawuyts/miow license: Apache-2.0 OR MIT","title":"miow 0.3.7"},{"location":"policies/credits/#mockall-0102","text":"repository: https://github.com/asomers/mockall license: Apache-2.0 OR MIT","title":"mockall 0.10.2"},{"location":"policies/credits/#mockall_derive-0102","text":"repository: https://github.com/asomers/mockall license: Apache-2.0 OR MIT","title":"mockall_derive 0.10.2"},{"location":"policies/credits/#msql-srv-096","text":"repository: https://github.com/jonhoo/msql-srv.git license: Apache-2.0 OR MIT","title":"msql-srv 0.9.6"},{"location":"policies/credits/#multimap-083","text":"repository: https://github.com/havarnov/multimap license: Apache-2.0 OR MIT","title":"multimap 0.8.3"},{"location":"policies/credits/#multiversion-061","text":"repository: https://github.com/calebzulawski/multiversion license: Apache-2.0 OR MIT","title":"multiversion 0.6.1"},{"location":"policies/credits/#multiversion-macros-061","text":"repository: https://github.com/calebzulawski/multiversion license: Apache-2.0 OR MIT","title":"multiversion-macros 0.6.1"},{"location":"policies/credits/#mysql-2101","text":"repository: https://github.com/blackbeam/rust-mysql-simple license: Apache-2.0 OR MIT","title":"mysql 21.0.1"},{"location":"policies/credits/#mysql_common-0275","text":"repository: https://github.com/blackbeam/rust_mysql_common license: Apache-2.0 OR MIT","title":"mysql_common 0.27.5"},{"location":"policies/credits/#named_pipe-041","text":"repository: https://github.com/blackbeam/named_pipe license: Apache-2.0 OR MIT","title":"named_pipe 0.4.1"},{"location":"policies/credits/#native-tls-028","text":"repository: https://github.com/sfackler/rust-native-tls license: Apache-2.0 OR MIT","title":"native-tls 0.2.8"},{"location":"policies/credits/#new_debug_unreachable-104","text":"repository: https://github.com/mbrubeck/rust-debug-unreachable license: MIT","title":"new_debug_unreachable 1.0.4"},{"location":"policies/credits/#nibble_vec-010","text":"repository: https://github.com/michaelsproul/rust_nibble_vec license: MIT","title":"nibble_vec 0.1.0"},{"location":"policies/credits/#nix-0202","text":"repository: https://github.com/nix-rust/nix license: MIT","title":"nix 0.20.2"},{"location":"policies/credits/#nix-0212","text":"repository: https://github.com/nix-rust/nix license: MIT","title":"nix 0.21.2"},{"location":"policies/credits/#nix-0222","text":"repository: https://github.com/nix-rust/nix license: MIT","title":"nix 0.22.2"},{"location":"policies/credits/#nodrop-0114","text":"repository: https://github.com/bluss/arrayvec license: Apache-2.0 OR MIT","title":"nodrop 0.1.14"},{"location":"policies/credits/#nom-512","text":"repository: https://github.com/Geal/nom license: MIT","title":"nom 5.1.2"},{"location":"policies/credits/#nom-700","text":"repository: https://github.com/Geal/nom license: MIT","title":"nom 7.0.0"},{"location":"policies/credits/#normalize-line-endings-030","text":"repository: https://github.com/derekdreery/normalize-line-endings license: Apache-2.0","title":"normalize-line-endings 0.3.0"},{"location":"policies/credits/#ntapi-036","text":"repository: https://github.com/MSxDOS/ntapi license: Apache-2.0 OR MIT","title":"ntapi 0.3.6"},{"location":"policies/credits/#num-040","text":"repository: https://github.com/rust-num/num license: Apache-2.0 OR MIT","title":"num 0.4.0"},{"location":"policies/credits/#num-bigint-033","text":"repository: https://github.com/rust-num/num-bigint license: Apache-2.0 OR MIT","title":"num-bigint 0.3.3"},{"location":"policies/credits/#num-bigint-042","text":"repository: https://github.com/rust-num/num-bigint license: Apache-2.0 OR MIT","title":"num-bigint 0.4.2"},{"location":"policies/credits/#num-bigint-dig-070","text":"repository: https://github.com/dignifiedquire/num-bigint license: Apache-2.0 OR MIT","title":"num-bigint-dig 0.7.0"},{"location":"policies/credits/#num-complex-040","text":"repository: https://github.com/rust-num/num-complex license: Apache-2.0 OR MIT","title":"num-complex 0.4.0"},{"location":"policies/credits/#num-format-040","text":"repository: https://github.com/bcmyers/num-format license: Apache-2.0 OR MIT","title":"num-format 0.4.0"},{"location":"policies/credits/#num-integer-0144","text":"repository: https://github.com/rust-num/num-integer license: Apache-2.0 OR MIT","title":"num-integer 0.1.44"},{"location":"policies/credits/#num-iter-0142","text":"repository: https://github.com/rust-num/num-iter license: Apache-2.0 OR MIT","title":"num-iter 0.1.42"},{"location":"policies/credits/#num-rational-040","text":"repository: https://github.com/rust-num/num-rational license: Apache-2.0 OR MIT","title":"num-rational 0.4.0"},{"location":"policies/credits/#num-traits-0214","text":"repository: https://github.com/rust-num/num-traits license: Apache-2.0 OR MIT","title":"num-traits 0.2.14"},{"location":"policies/credits/#num_cpus-1130","text":"repository: https://github.com/seanmonstar/num_cpus license: Apache-2.0 OR MIT","title":"num_cpus 1.13.0"},{"location":"policies/credits/#number_prefix-040","text":"repository: https://github.com/ogham/rust-number-prefix license: MIT","title":"number_prefix 0.4.0"},{"location":"policies/credits/#oauth2-400-alpha3","text":"repository: https://github.com/ramosbugs/oauth2-rs license: Apache-2.0 OR MIT","title":"oauth2 4.0.0-alpha.3"},{"location":"policies/credits/#object-0270","text":"repository: https://github.com/gimli-rs/object license: Apache-2.0 OR MIT","title":"object 0.27.0"},{"location":"policies/credits/#once_cell-180","text":"repository: https://github.com/matklad/once_cell license: Apache-2.0 OR MIT","title":"once_cell 1.8.0"},{"location":"policies/credits/#oorandom-1113","text":"repository: https://sr.ht/~icefox/oorandom/ license: MIT","title":"oorandom 11.1.3"},{"location":"policies/credits/#opaque-debug-023","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"opaque-debug 0.2.3"},{"location":"policies/credits/#opaque-debug-030","text":"repository: https://github.com/RustCrypto/utils license: Apache-2.0 OR MIT","title":"opaque-debug 0.3.0"},{"location":"policies/credits/#openssl-01036","text":"repository: https://github.com/sfackler/rust-openssl license: Apache-2.0","title":"openssl 0.10.36"},{"location":"policies/credits/#openssl-probe-014","text":"repository: https://github.com/alexcrichton/openssl-probe license: Apache-2.0 OR MIT","title":"openssl-probe 0.1.4"},{"location":"policies/credits/#openssl-sys-0967","text":"repository: https://github.com/sfackler/rust-openssl license: MIT","title":"openssl-sys 0.9.67"},{"location":"policies/credits/#opentelemetry-0160","text":"repository: https://github.com/open-telemetry/opentelemetry-rust license: Apache-2.0","title":"opentelemetry 0.16.0"},{"location":"policies/credits/#opentelemetry-jaeger-0150","text":"repository: https://github.com/open-telemetry/opentelemetry-rust/tree/main/opentelemetry-jaeger license: Apache-2.0","title":"opentelemetry-jaeger 0.15.0"},{"location":"policies/credits/#opentelemetry-semantic-conventions-080","text":"repository: https://github.com/open-telemetry/opentelemetry-rust/tree/main/opentelemetry-semantic-conventions license: Apache-2.0","title":"opentelemetry-semantic-conventions 0.8.0"},{"location":"policies/credits/#ordered-float-111","text":"repository: https://github.com/reem/rust-ordered-float license: MIT","title":"ordered-float 1.1.1"},{"location":"policies/credits/#ordered-float-280","text":"repository: https://github.com/reem/rust-ordered-float license: MIT","title":"ordered-float 2.8.0"},{"location":"policies/credits/#os_str_bytes-420","text":"repository: https://github.com/dylni/os_str_bytes license: Apache-2.0 OR MIT","title":"os_str_bytes 4.2.0"},{"location":"policies/credits/#output_vt100-012","text":"repository: https://github.com/Phundrak/output-vt100-rs license: MIT","title":"output_vt100 0.1.2"},{"location":"policies/credits/#p256-090","text":"repository: https://github.com/RustCrypto/elliptic-curves/tree/master/p256 license: Apache-2.0 OR MIT","title":"p256 0.9.0"},{"location":"policies/credits/#packed_simd_2-036","text":"repository: https://github.com/rust-lang/packed_simd license: Apache-2.0 OR MIT","title":"packed_simd_2 0.3.6"},{"location":"policies/credits/#parking-200","text":"repository: https://github.com/stjepang/parking license: Apache-2.0 OR MIT","title":"parking 2.0.0"},{"location":"policies/credits/#parking_lot-0112","text":"repository: https://github.com/Amanieu/parking_lot license: Apache-2.0 OR MIT","title":"parking_lot 0.11.2"},{"location":"policies/credits/#parking_lot_core-085","text":"repository: https://github.com/Amanieu/parking_lot license: Apache-2.0 OR MIT","title":"parking_lot_core 0.8.5"},{"location":"policies/credits/#parquet-format-async-temp-020","text":"repository: https://github.com/sunchao/parquet-format-rs license: Apache-2.0","title":"parquet-format-async-temp 0.2.0"},{"location":"policies/credits/#parquet2-060","text":"repository: None license: Apache-2.0","title":"parquet2 0.6.0"},{"location":"policies/credits/#parse-zoneinfo-030","text":"repository: https://github.com/djzin/parse-zoneinfo license: MIT","title":"parse-zoneinfo 0.3.0"},{"location":"policies/credits/#paste-105","text":"repository: https://github.com/dtolnay/paste license: Apache-2.0 OR MIT","title":"paste 1.0.5"},{"location":"policies/credits/#peeking_take_while-012","text":"repository: https://github.com/fitzgen/peeking_take_while license: Apache-2.0 OR MIT","title":"peeking_take_while 0.1.2"},{"location":"policies/credits/#pem-083","text":"repository: https://github.com/jcreekmore/pem-rs.git license: MIT","title":"pem 0.8.3"},{"location":"policies/credits/#pem-rfc7468-023","text":"repository: https://github.com/RustCrypto/formats/tree/master/pem-rfc7468 license: Apache-2.0 OR MIT","title":"pem-rfc7468 0.2.3"},{"location":"policies/credits/#percent-encoding-210","text":"repository: https://github.com/servo/rust-url/ license: Apache-2.0 OR MIT","title":"percent-encoding 2.1.0"},{"location":"policies/credits/#pest-213","text":"repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT","title":"pest 2.1.3"},{"location":"policies/credits/#pest_derive-210","text":"repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT","title":"pest_derive 2.1.0"},{"location":"policies/credits/#pest_generator-213","text":"repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT","title":"pest_generator 2.1.3"},{"location":"policies/credits/#pest_meta-213","text":"repository: https://github.com/pest-parser/pest license: Apache-2.0 OR MIT","title":"pest_meta 2.1.3"},{"location":"policies/credits/#petgraph-051","text":"repository: https://github.com/petgraph/petgraph license: Apache-2.0 OR MIT","title":"petgraph 0.5.1"},{"location":"policies/credits/#phf-0100","text":"repository: https://github.com/sfackler/rust-phf license: MIT","title":"phf 0.10.0"},{"location":"policies/credits/#phf_codegen-0100","text":"repository: https://github.com/sfackler/rust-phf license: MIT","title":"phf_codegen 0.10.0"},{"location":"policies/credits/#phf_generator-0100","text":"repository: https://github.com/sfackler/rust-phf license: MIT","title":"phf_generator 0.10.0"},{"location":"policies/credits/#phf_shared-080","text":"repository: https://github.com/sfackler/rust-phf license: MIT","title":"phf_shared 0.8.0"},{"location":"policies/credits/#phf_shared-0100","text":"repository: https://github.com/sfackler/rust-phf license: MIT","title":"phf_shared 0.10.0"},{"location":"policies/credits/#pico-args-042","text":"repository: https://github.com/RazrFalcon/pico-args license: MIT","title":"pico-args 0.4.2"},{"location":"policies/credits/#pin-project-108","text":"repository: https://github.com/taiki-e/pin-project license: Apache-2.0 OR MIT","title":"pin-project 1.0.8"},{"location":"policies/credits/#pin-project-internal-108","text":"repository: https://github.com/taiki-e/pin-project license: Apache-2.0 OR MIT","title":"pin-project-internal 1.0.8"},{"location":"policies/credits/#pin-project-lite-027","text":"repository: https://github.com/taiki-e/pin-project-lite license: Apache-2.0 OR MIT","title":"pin-project-lite 0.2.7"},{"location":"policies/credits/#pin-utils-010","text":"repository: https://github.com/rust-lang-nursery/pin-utils license: Apache-2.0 OR MIT","title":"pin-utils 0.1.0"},{"location":"policies/credits/#pkcs1-024","text":"repository: https://github.com/RustCrypto/formats/tree/master/pkcs1 license: Apache-2.0 OR MIT","title":"pkcs1 0.2.4"},{"location":"policies/credits/#pkcs8-076","text":"repository: https://github.com/RustCrypto/formats/tree/master/pkcs8 license: Apache-2.0 OR MIT","title":"pkcs8 0.7.6"},{"location":"policies/credits/#pkg-config-0320","text":"repository: https://github.com/rust-lang/pkg-config-rs license: Apache-2.0 OR MIT","title":"pkg-config 0.3.20"},{"location":"policies/credits/#plotters-031","text":"repository: https://github.com/38/plotters license: MIT","title":"plotters 0.3.1"},{"location":"policies/credits/#plotters-backend-032","text":"repository: https://github.com/plotters-rs/plotters-backend license: MIT","title":"plotters-backend 0.3.2"},{"location":"policies/credits/#plotters-svg-031","text":"repository: https://github.com/plotters-rs/plotters-svg.git license: MIT","title":"plotters-svg 0.3.1"},{"location":"policies/credits/#polling-210","text":"repository: https://github.com/smol-rs/polling license: Apache-2.0 OR MIT","title":"polling 2.1.0"},{"location":"policies/credits/#portpicker-011","text":"repository: https://github.com/Dentosal/portpicker-rs license: Unlicense","title":"portpicker 0.1.1"},{"location":"policies/credits/#pprof-050","text":"repository: https://github.com/tikv/pprof-rs license: Apache-2.0","title":"pprof 0.5.0"},{"location":"policies/credits/#ppv-lite86-0214","text":"repository: https://github.com/cryptocorrosion/cryptocorrosion license: Apache-2.0 OR MIT","title":"ppv-lite86 0.2.14"},{"location":"policies/credits/#precomputed-hash-011","text":"repository: https://github.com/emilio/precomputed-hash license: MIT","title":"precomputed-hash 0.1.1"},{"location":"policies/credits/#predicates-108","text":"repository: https://github.com/assert-rs/predicates-rs license: Apache-2.0 OR MIT","title":"predicates 1.0.8"},{"location":"policies/credits/#predicates-203","text":"repository: https://github.com/assert-rs/predicates-rs license: Apache-2.0 OR MIT","title":"predicates 2.0.3"},{"location":"policies/credits/#predicates-core-102","text":"repository: https://github.com/assert-rs/predicates-rs/tree/master/predicates-core license: Apache-2.0 OR MIT","title":"predicates-core 1.0.2"},{"location":"policies/credits/#predicates-tree-104","text":"repository: https://github.com/assert-rs/predicates-rs/tree/master/predicates-tree license: Apache-2.0 OR MIT","title":"predicates-tree 1.0.4"},{"location":"policies/credits/#pretty_assertions-100","text":"repository: https://github.com/colin-kiegel/rust-pretty-assertions license: Apache-2.0 OR MIT","title":"pretty_assertions 1.0.0"},{"location":"policies/credits/#proc-macro-error-104","text":"repository: https://gitlab.com/CreepySkeleton/proc-macro-error license: Apache-2.0 OR MIT","title":"proc-macro-error 1.0.4"},{"location":"policies/credits/#proc-macro-error-attr-104","text":"repository: https://gitlab.com/CreepySkeleton/proc-macro-error license: Apache-2.0 OR MIT","title":"proc-macro-error-attr 1.0.4"},{"location":"policies/credits/#proc-macro-hack-0519","text":"repository: https://github.com/dtolnay/proc-macro-hack license: Apache-2.0 OR MIT","title":"proc-macro-hack 0.5.19"},{"location":"policies/credits/#proc-macro-nested-017","text":"repository: https://github.com/dtolnay/proc-macro-hack license: Apache-2.0 OR MIT","title":"proc-macro-nested 0.1.7"},{"location":"policies/credits/#proc-macro2-1032","text":"repository: https://github.com/dtolnay/proc-macro2 license: Apache-2.0 OR MIT","title":"proc-macro2 1.0.32"},{"location":"policies/credits/#prometheus-parse-022","text":"repository: https://github.com/ccakes/prometheus-parse-rs license: Apache-2.0","title":"prometheus-parse 0.2.2"},{"location":"policies/credits/#prost-080","text":"repository: https://github.com/tokio-rs/prost license: Apache-2.0","title":"prost 0.8.0"},{"location":"policies/credits/#prost-build-080","text":"repository: https://github.com/tokio-rs/prost license: Apache-2.0","title":"prost-build 0.8.0"},{"location":"policies/credits/#prost-derive-080","text":"repository: https://github.com/tokio-rs/prost license: Apache-2.0","title":"prost-derive 0.8.0"},{"location":"policies/credits/#prost-types-080","text":"repository: https://github.com/tokio-rs/prost license: Apache-2.0","title":"prost-types 0.8.0"},{"location":"policies/credits/#pulldown-cmark-080","text":"repository: https://github.com/raphlinus/pulldown-cmark license: MIT","title":"pulldown-cmark 0.8.0"},{"location":"policies/credits/#qstring-072","text":"repository: https://github.com/algesten/qstring license: MIT","title":"qstring 0.7.2"},{"location":"policies/credits/#quanta-093","text":"repository: https://github.com/metrics-rs/quanta license: MIT","title":"quanta 0.9.3"},{"location":"policies/credits/#quantiles-071","text":"repository: https://github.com/postmates/quantiles license: MIT","title":"quantiles 0.7.1"},{"location":"policies/credits/#quick-error-123","text":"repository: http://github.com/tailhook/quick-error license: Apache-2.0 OR MIT","title":"quick-error 1.2.3"},{"location":"policies/credits/#quick-error-201","text":"repository: http://github.com/tailhook/quick-error license: Apache-2.0 OR MIT","title":"quick-error 2.0.1"},{"location":"policies/credits/#quick-xml-0220","text":"repository: https://github.com/tafia/quick-xml license: MIT","title":"quick-xml 0.22.0"},{"location":"policies/credits/#quote-1010","text":"repository: https://github.com/dtolnay/quote license: Apache-2.0 OR MIT","title":"quote 1.0.10"},{"location":"policies/credits/#radium-062","text":"repository: https://github.com/bitvecto-rs/radium license: MIT","title":"radium 0.6.2"},{"location":"policies/credits/#radix_trie-021","text":"repository: https://github.com/michaelsproul/rust_radix_trie license: MIT","title":"radix_trie 0.2.1"},{"location":"policies/credits/#rand-073","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand 0.7.3"},{"location":"policies/credits/#rand-084","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand 0.8.4"},{"location":"policies/credits/#rand_chacha-022","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand_chacha 0.2.2"},{"location":"policies/credits/#rand_chacha-031","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand_chacha 0.3.1"},{"location":"policies/credits/#rand_core-051","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand_core 0.5.1"},{"location":"policies/credits/#rand_core-063","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand_core 0.6.3"},{"location":"policies/credits/#rand_hc-020","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand_hc 0.2.0"},{"location":"policies/credits/#rand_hc-031","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand_hc 0.3.1"},{"location":"policies/credits/#rand_xoshiro-040","text":"repository: https://github.com/rust-random/rand license: Apache-2.0 OR MIT","title":"rand_xoshiro 0.4.0"},{"location":"policies/credits/#raw-cpuid-1020","text":"repository: https://github.com/gz/rust-cpuid license: MIT","title":"raw-cpuid 10.2.0"},{"location":"policies/credits/#rayon-151","text":"repository: https://github.com/rayon-rs/rayon license: Apache-2.0 OR MIT","title":"rayon 1.5.1"},{"location":"policies/credits/#rayon-core-191","text":"repository: https://github.com/rayon-rs/rayon license: Apache-2.0 OR MIT","title":"rayon-core 1.9.1"},{"location":"policies/credits/#redox_syscall-0210","text":"repository: https://gitlab.redox-os.org/redox-os/syscall license: MIT","title":"redox_syscall 0.2.10"},{"location":"policies/credits/#redox_users-040","text":"repository: https://gitlab.redox-os.org/redox-os/users license: MIT","title":"redox_users 0.4.0"},{"location":"policies/credits/#regex-154","text":"repository: https://github.com/rust-lang/regex license: Apache-2.0 OR MIT","title":"regex 1.5.4"},{"location":"policies/credits/#regex-automata-0110","text":"repository: https://github.com/BurntSushi/regex-automata license: MIT OR Unlicense","title":"regex-automata 0.1.10"},{"location":"policies/credits/#regex-syntax-0625","text":"repository: https://github.com/rust-lang/regex license: Apache-2.0 OR MIT","title":"regex-syntax 0.6.25"},{"location":"policies/credits/#remove_dir_all-053","text":"repository: https://github.com/XAMPPRocky/remove_dir_all.git license: Apache-2.0 OR MIT","title":"remove_dir_all 0.5.3"},{"location":"policies/credits/#reqwest-0116","text":"repository: https://github.com/seanmonstar/reqwest license: Apache-2.0 OR MIT","title":"reqwest 0.11.6"},{"location":"policies/credits/#resolv-conf-070","text":"repository: http://github.com/tailhook/resolv-conf license: Apache-2.0 OR MIT","title":"resolv-conf 0.7.0"},{"location":"policies/credits/#rgb-0827","text":"repository: https://github.com/kornelski/rust-rgb license: MIT","title":"rgb 0.8.27"},{"location":"policies/credits/#ring-01620","text":"repository: https://github.com/briansmith/ring license: None","title":"ring 0.16.20"},{"location":"policies/credits/#ritelinked-032","text":"repository: https://github.com/ritelabs/ritelinked license: Apache-2.0 OR MIT","title":"ritelinked 0.3.2"},{"location":"policies/credits/#rsa-050","text":"repository: https://github.com/RustCrypto/RSA license: Apache-2.0 OR MIT","title":"rsa 0.5.0"},{"location":"policies/credits/#run_script-090","text":"repository: https://github.com/sagiegurari/run_script.git license: Apache-2.0","title":"run_script 0.9.0"},{"location":"policies/credits/#rusoto_core-0470","text":"repository: https://github.com/rusoto/rusoto license: MIT","title":"rusoto_core 0.47.0"},{"location":"policies/credits/#rusoto_credential-0470","text":"repository: https://github.com/rusoto/rusoto license: MIT","title":"rusoto_credential 0.47.0"},{"location":"policies/credits/#rusoto_s3-0470","text":"repository: https://github.com/rusoto/rusoto license: MIT","title":"rusoto_s3 0.47.0"},{"location":"policies/credits/#rusoto_signature-0470","text":"repository: https://github.com/rusoto/rusoto license: MIT","title":"rusoto_signature 0.47.0"},{"location":"policies/credits/#rust_decimal-1160","text":"repository: https://github.com/paupino/rust-decimal license: MIT","title":"rust_decimal 1.16.0"},{"location":"policies/credits/#rustc-demangle-0121","text":"repository: https://github.com/alexcrichton/rustc-demangle license: Apache-2.0 OR MIT","title":"rustc-demangle 0.1.21"},{"location":"policies/credits/#rustc-hash-110","text":"repository: https://github.com/rust-lang-nursery/rustc-hash license: Apache-2.0 OR MIT","title":"rustc-hash 1.1.0"},{"location":"policies/credits/#rustc_version-023","text":"repository: https://github.com/Kimundi/rustc-version-rs license: Apache-2.0 OR MIT","title":"rustc_version 0.2.3"},{"location":"policies/credits/#rustc_version-040","text":"repository: https://github.com/Kimundi/rustc-version-rs license: Apache-2.0 OR MIT","title":"rustc_version 0.4.0"},{"location":"policies/credits/#rustls-0191","text":"repository: https://github.com/ctz/rustls license: Apache-2.0 OR ISC OR MIT","title":"rustls 0.19.1"},{"location":"policies/credits/#rustls-native-certs-050","text":"repository: https://github.com/ctz/rustls-native-certs license: Apache-2.0 OR ISC OR MIT","title":"rustls-native-certs 0.5.0"},{"location":"policies/credits/#rustversion-105","text":"repository: https://github.com/dtolnay/rustversion license: Apache-2.0 OR MIT","title":"rustversion 1.0.5"},{"location":"policies/credits/#rustyline-900","text":"repository: https://github.com/kkawakam/rustyline license: MIT","title":"rustyline 9.0.0"},{"location":"policies/credits/#ryu-105","text":"repository: https://github.com/dtolnay/ryu license: Apache-2.0 OR BSL-1.0","title":"ryu 1.0.5"},{"location":"policies/credits/#same-file-106","text":"repository: https://github.com/BurntSushi/same-file license: MIT OR Unlicense","title":"same-file 1.0.6"},{"location":"policies/credits/#saturating-010","text":"repository: https://github.com/breeswish/saturating-rs license: MIT","title":"saturating 0.1.0"},{"location":"policies/credits/#schannel-0119","text":"repository: https://github.com/steffengy/schannel-rs license: MIT","title":"schannel 0.1.19"},{"location":"policies/credits/#scopeguard-110","text":"repository: https://github.com/bluss/scopeguard license: Apache-2.0 OR MIT","title":"scopeguard 1.1.0"},{"location":"policies/credits/#sct-061","text":"repository: https://github.com/ctz/sct.rs license: Apache-2.0 OR ISC OR MIT","title":"sct 0.6.1"},{"location":"policies/credits/#security-framework-231","text":"repository: https://github.com/kornelski/rust-security-framework license: Apache-2.0 OR MIT","title":"security-framework 2.3.1"},{"location":"policies/credits/#security-framework-sys-242","text":"repository: https://github.com/kornelski/rust-security-framework license: Apache-2.0 OR MIT","title":"security-framework-sys 2.4.2"},{"location":"policies/credits/#semver-090","text":"repository: https://github.com/steveklabnik/semver license: Apache-2.0 OR MIT","title":"semver 0.9.0"},{"location":"policies/credits/#semver-0110","text":"repository: https://github.com/steveklabnik/semver license: Apache-2.0 OR MIT","title":"semver 0.11.0"},{"location":"policies/credits/#semver-104","text":"repository: https://github.com/dtolnay/semver license: Apache-2.0 OR MIT","title":"semver 1.0.4"},{"location":"policies/credits/#semver-parser-070","text":"repository: https://github.com/steveklabnik/semver-parser license: Apache-2.0 OR MIT","title":"semver-parser 0.7.0"},{"location":"policies/credits/#semver-parser-0102","text":"repository: https://github.com/steveklabnik/semver-parser license: Apache-2.0 OR MIT","title":"semver-parser 0.10.2"},{"location":"policies/credits/#serde-10130","text":"repository: https://github.com/serde-rs/serde license: Apache-2.0 OR MIT","title":"serde 1.0.130"},{"location":"policies/credits/#serde-xml-rs-041","text":"repository: https://github.com/RReverser/serde-xml-rs license: MIT","title":"serde-xml-rs 0.4.1"},{"location":"policies/credits/#serde_cbor-0112","text":"repository: https://github.com/pyfisch/cbor license: Apache-2.0 OR MIT","title":"serde_cbor 0.11.2"},{"location":"policies/credits/#serde_derive-10130","text":"repository: https://github.com/serde-rs/serde license: Apache-2.0 OR MIT","title":"serde_derive 1.0.130"},{"location":"policies/credits/#serde_json-1068","text":"repository: https://github.com/serde-rs/json license: Apache-2.0 OR MIT","title":"serde_json 1.0.68"},{"location":"policies/credits/#serde_regex-110","text":"repository: None license: Apache-2.0 OR MIT","title":"serde_regex 1.1.0"},{"location":"policies/credits/#serde_urlencoded-070","text":"repository: https://github.com/nox/serde_urlencoded license: Apache-2.0 OR MIT","title":"serde_urlencoded 0.7.0"},{"location":"policies/credits/#serde_yaml-0821","text":"repository: https://github.com/dtolnay/serde-yaml license: Apache-2.0 OR MIT","title":"serde_yaml 0.8.21"},{"location":"policies/credits/#sha-1-082","text":"repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT","title":"sha-1 0.8.2"},{"location":"policies/credits/#sha-1-098","text":"repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT","title":"sha-1 0.9.8"},{"location":"policies/credits/#sha1-060","text":"repository: https://github.com/mitsuhiko/rust-sha1 license: BSD-3-Clause","title":"sha1 0.6.0"},{"location":"policies/credits/#sha2-098","text":"repository: https://github.com/RustCrypto/hashes license: Apache-2.0 OR MIT","title":"sha2 0.9.8"},{"location":"policies/credits/#sharded-slab-014","text":"repository: https://github.com/hawkw/sharded-slab license: MIT","title":"sharded-slab 0.1.4"},{"location":"policies/credits/#shellwords-110","text":"repository: https://github.com/jimmycuadra/rust-shellwords license: MIT","title":"shellwords 1.1.0"},{"location":"policies/credits/#shlex-110","text":"repository: https://github.com/comex/rust-shlex license: Apache-2.0 OR MIT","title":"shlex 1.1.0"},{"location":"policies/credits/#signal-hook-0310","text":"repository: https://github.com/vorner/signal-hook license: Apache-2.0 OR MIT","title":"signal-hook 0.3.10"},{"location":"policies/credits/#signal-hook-mio-021","text":"repository: https://github.com/vorner/signal-hook license: Apache-2.0 OR MIT","title":"signal-hook-mio 0.2.1"},{"location":"policies/credits/#signal-hook-registry-140","text":"repository: https://github.com/vorner/signal-hook license: Apache-2.0 OR MIT","title":"signal-hook-registry 1.4.0"},{"location":"policies/credits/#signature-131","text":"repository: https://github.com/RustCrypto/traits/tree/master/signature license: Apache-2.0 OR MIT","title":"signature 1.3.1"},{"location":"policies/credits/#simdutf8-013","text":"repository: https://github.com/rusticstuff/simdutf8 license: Apache-2.0 OR MIT","title":"simdutf8 0.1.3"},{"location":"policies/credits/#siphasher-037","text":"repository: https://github.com/jedisct1/rust-siphash license: Apache-2.0 OR MIT","title":"siphasher 0.3.7"},{"location":"policies/credits/#sized-chunks-065","text":"repository: https://github.com/bodil/sized-chunks license: MPL-2.0+","title":"sized-chunks 0.6.5"},{"location":"policies/credits/#skeptic-0136","text":"repository: https://github.com/budziq/rust-skeptic license: Apache-2.0 OR MIT","title":"skeptic 0.13.6"},{"location":"policies/credits/#sketches-ddsketch-012","text":"repository: https://github.com/mheffner/rust-sketches-ddsketch license: Apache-2.0","title":"sketches-ddsketch 0.1.2"},{"location":"policies/credits/#slab-045","text":"repository: https://github.com/tokio-rs/slab license: MIT","title":"slab 0.4.5"},{"location":"policies/credits/#sled-0346","text":"repository: https://github.com/spacejam/sled license: Apache-2.0 OR MIT","title":"sled 0.34.6"},{"location":"policies/credits/#sluice-055","text":"repository: https://github.com/sagebind/sluice license: MIT","title":"sluice 0.5.5"},{"location":"policies/credits/#smallvec-170","text":"repository: https://github.com/servo/rust-smallvec license: Apache-2.0 OR MIT","title":"smallvec 1.7.0"},{"location":"policies/credits/#socket2-0319","text":"repository: https://github.com/alexcrichton/socket2-rs license: Apache-2.0 OR MIT","title":"socket2 0.3.19"},{"location":"policies/credits/#socket2-042","text":"repository: https://github.com/rust-lang/socket2 license: Apache-2.0 OR MIT","title":"socket2 0.4.2"},{"location":"policies/credits/#spin-052","text":"repository: https://github.com/mvdnes/spin-rs.git license: MIT","title":"spin 0.5.2"},{"location":"policies/credits/#spki-041","text":"repository: https://github.com/RustCrypto/formats/tree/master/spki license: Apache-2.0 OR MIT","title":"spki 0.4.1"},{"location":"policies/credits/#sqlparser-0111-alpha0","text":"repository: https://github.com/sqlparser-rs/sqlparser-rs license: Apache-2.0","title":"sqlparser 0.11.1-alpha.0"},{"location":"policies/credits/#stable_deref_trait-120","text":"repository: https://github.com/storyyeller/stable_deref_trait license: Apache-2.0 OR MIT","title":"stable_deref_trait 1.2.0"},{"location":"policies/credits/#standback-0217","text":"repository: https://github.com/jhpratt/standback license: Apache-2.0 OR MIT","title":"standback 0.2.17"},{"location":"policies/credits/#static_assertions-110","text":"repository: https://github.com/nvzqz/static-assertions-rs license: Apache-2.0 OR MIT","title":"static_assertions 1.1.0"},{"location":"policies/credits/#stdweb-0420","text":"repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT","title":"stdweb 0.4.20"},{"location":"policies/credits/#stdweb-derive-053","text":"repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT","title":"stdweb-derive 0.5.3"},{"location":"policies/credits/#stdweb-internal-macros-029","text":"repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT","title":"stdweb-internal-macros 0.2.9"},{"location":"policies/credits/#stdweb-internal-runtime-015","text":"repository: https://github.com/koute/stdweb license: Apache-2.0 OR MIT","title":"stdweb-internal-runtime 0.1.5"},{"location":"policies/credits/#str-buf-105","text":"repository: https://github.com/DoumanAsh/str-buf license: BSL-1.0","title":"str-buf 1.0.5"},{"location":"policies/credits/#str_stack-010","text":"repository: https://github.com/Stebalien/str_stack license: Apache-2.0 OR MIT","title":"str_stack 0.1.0"},{"location":"policies/credits/#streaming-decompression-010","text":"repository: None license: Apache-2.0","title":"streaming-decompression 0.1.0"},{"location":"policies/credits/#streaming-iterator-015","text":"repository: https://github.com/sfackler/streaming-iterator license: Apache-2.0 OR MIT","title":"streaming-iterator 0.1.5"},{"location":"policies/credits/#strength_reduce-023","text":"repository: http://github.com/ejmahler/strength_reduce license: Apache-2.0 OR MIT","title":"strength_reduce 0.2.3"},{"location":"policies/credits/#string_cache-082","text":"repository: https://github.com/servo/string-cache license: Apache-2.0 OR MIT","title":"string_cache 0.8.2"},{"location":"policies/credits/#strsim-080","text":"repository: https://github.com/dguo/strsim-rs license: MIT","title":"strsim 0.8.0"},{"location":"policies/credits/#strsim-0100","text":"repository: https://github.com/dguo/strsim-rs license: MIT","title":"strsim 0.10.0"},{"location":"policies/credits/#structopt-0325","text":"repository: https://github.com/TeXitoi/structopt license: Apache-2.0 OR MIT","title":"structopt 0.3.25"},{"location":"policies/credits/#structopt-derive-0418","text":"repository: https://github.com/TeXitoi/structopt license: Apache-2.0 OR MIT","title":"structopt-derive 0.4.18"},{"location":"policies/credits/#structopt-toml-050","text":"repository: https://github.com/dalance/structopt-toml license: Apache-2.0 OR MIT","title":"structopt-toml 0.5.0"},{"location":"policies/credits/#structopt-toml-derive-050","text":"repository: https://github.com/dalance/structopt-toml license: Apache-2.0 OR MIT","title":"structopt-toml-derive 0.5.0"},{"location":"policies/credits/#strum-0210","text":"repository: https://github.com/Peternator7/strum license: MIT","title":"strum 0.21.0"},{"location":"policies/credits/#strum_macros-0211","text":"repository: https://github.com/Peternator7/strum license: MIT","title":"strum_macros 0.21.1"},{"location":"policies/credits/#subprocess-028","text":"repository: https://github.com/hniksic/rust-subprocess license: Apache-2.0 OR MIT","title":"subprocess 0.2.8"},{"location":"policies/credits/#subtle-241","text":"repository: https://github.com/dalek-cryptography/subtle license: BSD-3-Clause","title":"subtle 2.4.1"},{"location":"policies/credits/#symbolic-common-831","text":"repository: https://github.com/getsentry/symbolic license: MIT","title":"symbolic-common 8.3.1"},{"location":"policies/credits/#symbolic-demangle-831","text":"repository: https://github.com/getsentry/symbolic license: MIT","title":"symbolic-demangle 8.3.1"},{"location":"policies/credits/#syn-1081","text":"repository: https://github.com/dtolnay/syn license: Apache-2.0 OR MIT","title":"syn 1.0.81"},{"location":"policies/credits/#sync_wrapper-011","text":"repository: https://github.com/Actyx/sync_wrapper license: Apache-2.0","title":"sync_wrapper 0.1.1"},{"location":"policies/credits/#synstructure-0126","text":"repository: https://github.com/mystor/synstructure license: MIT","title":"synstructure 0.12.6"},{"location":"policies/credits/#sysinfo-0192","text":"repository: https://github.com/GuillaumeGomez/sysinfo license: MIT","title":"sysinfo 0.19.2"},{"location":"policies/credits/#sysinfo-0205","text":"repository: https://github.com/GuillaumeGomez/sysinfo license: MIT","title":"sysinfo 0.20.5"},{"location":"policies/credits/#tap-101","text":"repository: https://github.com/myrrlyn/tap license: MIT","title":"tap 1.0.1"},{"location":"policies/credits/#tar-0437","text":"repository: https://github.com/alexcrichton/tar-rs license: Apache-2.0 OR MIT","title":"tar 0.4.37"},{"location":"policies/credits/#tempfile-320","text":"repository: https://github.com/Stebalien/tempfile license: Apache-2.0 OR MIT","title":"tempfile 3.2.0"},{"location":"policies/credits/#term-070","text":"repository: https://github.com/Stebalien/term license: Apache-2.0 OR MIT","title":"term 0.7.0"},{"location":"policies/credits/#termcolor-112","text":"repository: https://github.com/BurntSushi/termcolor license: MIT OR Unlicense","title":"termcolor 1.1.2"},{"location":"policies/credits/#terminal_size-0117","text":"repository: https://github.com/eminence/terminal-size license: Apache-2.0 OR MIT","title":"terminal_size 0.1.17"},{"location":"policies/credits/#termtree-021","text":"repository: https://github.com/rust-cli/termtree license: MIT","title":"termtree 0.2.1"},{"location":"policies/credits/#test-env-log-027","text":"repository: https://github.com/d-e-s-o/test-env-log.git license: Apache-2.0 OR MIT","title":"test-env-log 0.2.7"},{"location":"policies/credits/#textwrap-0110","text":"repository: https://github.com/mgeisler/textwrap license: MIT","title":"textwrap 0.11.0"},{"location":"policies/credits/#textwrap-0142","text":"repository: https://github.com/mgeisler/textwrap license: MIT","title":"textwrap 0.14.2"},{"location":"policies/credits/#thiserror-1030","text":"repository: https://github.com/dtolnay/thiserror license: Apache-2.0 OR MIT","title":"thiserror 1.0.30"},{"location":"policies/credits/#thiserror-impl-1030","text":"repository: https://github.com/dtolnay/thiserror license: Apache-2.0 OR MIT","title":"thiserror-impl 1.0.30"},{"location":"policies/credits/#thread_local-113","text":"repository: https://github.com/Amanieu/thread_local-rs license: Apache-2.0 OR MIT","title":"thread_local 1.1.3"},{"location":"policies/credits/#threadpool-181","text":"repository: https://github.com/rust-threadpool/rust-threadpool license: Apache-2.0 OR MIT","title":"threadpool 1.8.1"},{"location":"policies/credits/#thrift-0130","text":"repository: None license: Apache-2.0","title":"thrift 0.13.0"},{"location":"policies/credits/#tikv-jemalloc-sys-042521-patched2","text":"repository: https://github.com/tikv/jemallocator license: Apache-2.0 OR MIT","title":"tikv-jemalloc-sys 0.4.2+5.2.1-patched.2"},{"location":"policies/credits/#time-0144","text":"repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT","title":"time 0.1.44"},{"location":"policies/credits/#time-0227","text":"repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT","title":"time 0.2.27"},{"location":"policies/credits/#time-macros-011","text":"repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT","title":"time-macros 0.1.1"},{"location":"policies/credits/#time-macros-impl-012","text":"repository: https://github.com/time-rs/time license: Apache-2.0 OR MIT","title":"time-macros-impl 0.1.2"},{"location":"policies/credits/#tiny-keccak-202","text":"repository: None license: CC0-1.0","title":"tiny-keccak 2.0.2"},{"location":"policies/credits/#tinytemplate-121","text":"repository: https://github.com/bheisler/TinyTemplate license: Apache-2.0 OR MIT","title":"tinytemplate 1.2.1"},{"location":"policies/credits/#tinyvec-150","text":"repository: https://github.com/Lokathor/tinyvec license: Apache-2.0 OR MIT OR Zlib","title":"tinyvec 1.5.0"},{"location":"policies/credits/#tinyvec_macros-010","text":"repository: https://github.com/Soveu/tinyvec_macros license: Apache-2.0 OR MIT OR Zlib","title":"tinyvec_macros 0.1.0"},{"location":"policies/credits/#tokio-1120","text":"repository: https://github.com/tokio-rs/tokio license: MIT","title":"tokio 1.12.0"},{"location":"policies/credits/#tokio-io-timeout-111","text":"repository: https://github.com/sfackler/tokio-io-timeout license: Apache-2.0 OR MIT","title":"tokio-io-timeout 1.1.1"},{"location":"policies/credits/#tokio-macros-150","text":"repository: https://github.com/tokio-rs/tokio license: MIT","title":"tokio-macros 1.5.0"},{"location":"policies/credits/#tokio-native-tls-030","text":"repository: https://github.com/tokio-rs/tls license: MIT","title":"tokio-native-tls 0.3.0"},{"location":"policies/credits/#tokio-rustls-0220","text":"repository: https://github.com/tokio-rs/tls license: Apache-2.0 OR MIT","title":"tokio-rustls 0.22.0"},{"location":"policies/credits/#tokio-stream-017","text":"repository: https://github.com/tokio-rs/tokio license: MIT","title":"tokio-stream 0.1.7"},{"location":"policies/credits/#tokio-util-068","text":"repository: https://github.com/tokio-rs/tokio license: MIT","title":"tokio-util 0.6.8"},{"location":"policies/credits/#toml-058","text":"repository: https://github.com/alexcrichton/toml-rs license: Apache-2.0 OR MIT","title":"toml 0.5.8"},{"location":"policies/credits/#tonic-052","text":"repository: https://github.com/hyperium/tonic license: MIT","title":"tonic 0.5.2"},{"location":"policies/credits/#tonic-build-052","text":"repository: https://github.com/hyperium/tonic license: MIT","title":"tonic-build 0.5.2"},{"location":"policies/credits/#tower-0410","text":"repository: https://github.com/tower-rs/tower license: MIT","title":"tower 0.4.10"},{"location":"policies/credits/#tower-http-011","text":"repository: https://github.com/tower-rs/tower-http license: MIT","title":"tower-http 0.1.1"},{"location":"policies/credits/#tower-layer-031","text":"repository: https://github.com/tower-rs/tower license: MIT","title":"tower-layer 0.3.1"},{"location":"policies/credits/#tower-service-031","text":"repository: https://github.com/tower-rs/tower license: MIT","title":"tower-service 0.3.1"},{"location":"policies/credits/#tracing-0129","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing 0.1.29"},{"location":"policies/credits/#tracing-appender-012","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-appender 0.1.2"},{"location":"policies/credits/#tracing-attributes-0118","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-attributes 0.1.18"},{"location":"policies/credits/#tracing-bunyan-formatter-026","text":"repository: https://github.com/LukeMathWalker/tracing-bunyan-formatter license: Apache-2.0 OR MIT","title":"tracing-bunyan-formatter 0.2.6"},{"location":"policies/credits/#tracing-core-0121","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-core 0.1.21"},{"location":"policies/credits/#tracing-futures-025","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-futures 0.2.5"},{"location":"policies/credits/#tracing-log-012","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-log 0.1.2"},{"location":"policies/credits/#tracing-opentelemetry-0150","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-opentelemetry 0.15.0"},{"location":"policies/credits/#tracing-serde-012","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-serde 0.1.2"},{"location":"policies/credits/#tracing-subscriber-0225","text":"repository: https://github.com/tokio-rs/tracing license: MIT","title":"tracing-subscriber 0.2.25"},{"location":"policies/credits/#trust-dns-proto-0203","text":"repository: https://github.com/bluejekyll/trust-dns license: Apache-2.0 OR MIT","title":"trust-dns-proto 0.20.3"},{"location":"policies/credits/#trust-dns-resolver-0203","text":"repository: https://github.com/bluejekyll/trust-dns license: Apache-2.0 OR MIT","title":"trust-dns-resolver 0.20.3"},{"location":"policies/credits/#try-lock-023","text":"repository: https://github.com/seanmonstar/try-lock license: MIT","title":"try-lock 0.2.3"},{"location":"policies/credits/#tryhard-040","text":"repository: https://github.com/EmbarkStudios/tryhard license: Apache-2.0 OR MIT","title":"tryhard 0.4.0"},{"location":"policies/credits/#twox-hash-161","text":"repository: https://github.com/shepmaster/twox-hash license: MIT","title":"twox-hash 1.6.1"},{"location":"policies/credits/#typenum-1140","text":"repository: https://github.com/paholg/typenum license: Apache-2.0 OR MIT","title":"typenum 1.14.0"},{"location":"policies/credits/#ucd-trie-013","text":"repository: https://github.com/BurntSushi/ucd-generate license: Apache-2.0 OR MIT","title":"ucd-trie 0.1.3"},{"location":"policies/credits/#uncased-096","text":"repository: https://github.com/SergioBenitez/uncased license: Apache-2.0 OR MIT","title":"uncased 0.9.6"},{"location":"policies/credits/#unicase-260","text":"repository: https://github.com/seanmonstar/unicase license: Apache-2.0 OR MIT","title":"unicase 2.6.0"},{"location":"policies/credits/#unicode-bidi-037","text":"repository: https://github.com/servo/unicode-bidi license: Apache-2.0 OR MIT","title":"unicode-bidi 0.3.7"},{"location":"policies/credits/#unicode-normalization-0119","text":"repository: https://github.com/unicode-rs/unicode-normalization license: Apache-2.0 OR MIT","title":"unicode-normalization 0.1.19"},{"location":"policies/credits/#unicode-segmentation-180","text":"repository: https://github.com/unicode-rs/unicode-segmentation license: Apache-2.0 OR MIT","title":"unicode-segmentation 1.8.0"},{"location":"policies/credits/#unicode-width-019","text":"repository: https://github.com/unicode-rs/unicode-width license: Apache-2.0 OR MIT","title":"unicode-width 0.1.9"},{"location":"policies/credits/#unicode-xid-022","text":"repository: https://github.com/unicode-rs/unicode-xid license: Apache-2.0 OR MIT","title":"unicode-xid 0.2.2"},{"location":"policies/credits/#untrusted-071","text":"repository: https://github.com/briansmith/untrusted license: ISC","title":"untrusted 0.7.1"},{"location":"policies/credits/#ureq-220","text":"repository: https://github.com/algesten/ureq license: Apache-2.0 OR MIT","title":"ureq 2.2.0"},{"location":"policies/credits/#url-222","text":"repository: https://github.com/servo/rust-url license: Apache-2.0 OR MIT","title":"url 2.2.2"},{"location":"policies/credits/#users-0110","text":"repository: https://github.com/ogham/rust-users license: MIT","title":"users 0.11.0"},{"location":"policies/credits/#utf8-width-015","text":"repository: https://github.com/magiclen/utf8-width license: MIT","title":"utf8-width 0.1.5"},{"location":"policies/credits/#utf8parse-020","text":"repository: https://github.com/jwilm/vte license: Apache-2.0 OR MIT","title":"utf8parse 0.2.0"},{"location":"policies/credits/#uuid-082","text":"repository: https://github.com/uuid-rs/uuid license: Apache-2.0 OR MIT","title":"uuid 0.8.2"},{"location":"policies/credits/#value-bag-100-alpha7","text":"repository: https://github.com/sval-rs/value-bag license: Apache-2.0 OR MIT","title":"value-bag 1.0.0-alpha.7"},{"location":"policies/credits/#vcpkg-0215","text":"repository: https://github.com/mcgoo/vcpkg-rs license: Apache-2.0 OR MIT","title":"vcpkg 0.2.15"},{"location":"policies/credits/#vec_map-082","text":"repository: https://github.com/contain-rs/vec-map license: Apache-2.0 OR MIT","title":"vec_map 0.8.2"},{"location":"policies/credits/#vergen-5116","text":"repository: https://github.com/rustyhorde/vergen license: Apache-2.0 OR MIT","title":"vergen 5.1.16"},{"location":"policies/credits/#version_check-093","text":"repository: https://github.com/SergioBenitez/version_check license: Apache-2.0 OR MIT","title":"version_check 0.9.3"},{"location":"policies/credits/#wait-timeout-020","text":"repository: https://github.com/alexcrichton/wait-timeout license: Apache-2.0 OR MIT","title":"wait-timeout 0.2.0"},{"location":"policies/credits/#waker-fn-110","text":"repository: https://github.com/stjepang/waker-fn license: Apache-2.0 OR MIT","title":"waker-fn 1.1.0"},{"location":"policies/credits/#walkdir-232","text":"repository: https://github.com/BurntSushi/walkdir license: MIT OR Unlicense","title":"walkdir 2.3.2"},{"location":"policies/credits/#want-030","text":"repository: https://github.com/seanmonstar/want license: MIT","title":"want 0.3.0"},{"location":"policies/credits/#wasi-090wasi-snapshot-preview1","text":"repository: https://github.com/bytecodealliance/wasi license: Apache-2.0 OR Apache-2.0 WITH LLVM-exception OR MIT","title":"wasi 0.9.0+wasi-snapshot-preview1"},{"location":"policies/credits/#wasi-0100wasi-snapshot-preview1","text":"repository: https://github.com/bytecodealliance/wasi license: Apache-2.0 OR Apache-2.0 WITH LLVM-exception OR MIT","title":"wasi 0.10.0+wasi-snapshot-preview1"},{"location":"policies/credits/#wasm-bindgen-0278","text":"repository: https://github.com/rustwasm/wasm-bindgen license: Apache-2.0 OR MIT","title":"wasm-bindgen 0.2.78"},{"location":"policies/credits/#wasm-bindgen-backend-0278","text":"repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/backend license: Apache-2.0 OR MIT","title":"wasm-bindgen-backend 0.2.78"},{"location":"policies/credits/#wasm-bindgen-futures-0428","text":"repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/futures license: Apache-2.0 OR MIT","title":"wasm-bindgen-futures 0.4.28"},{"location":"policies/credits/#wasm-bindgen-macro-0278","text":"repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/macro license: Apache-2.0 OR MIT","title":"wasm-bindgen-macro 0.2.78"},{"location":"policies/credits/#wasm-bindgen-macro-support-0278","text":"repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/macro-support license: Apache-2.0 OR MIT","title":"wasm-bindgen-macro-support 0.2.78"},{"location":"policies/credits/#wasm-bindgen-shared-0278","text":"repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/shared license: Apache-2.0 OR MIT","title":"wasm-bindgen-shared 0.2.78"},{"location":"policies/credits/#web-sys-0355","text":"repository: https://github.com/rustwasm/wasm-bindgen/tree/master/crates/web-sys license: Apache-2.0 OR MIT","title":"web-sys 0.3.55"},{"location":"policies/credits/#webbrowser-055","text":"repository: https://github.com/amodm/webbrowser-rs license: Apache-2.0 OR MIT","title":"webbrowser 0.5.5"},{"location":"policies/credits/#webpki-0214","text":"repository: https://github.com/briansmith/webpki license: None","title":"webpki 0.21.4"},{"location":"policies/credits/#webpki-roots-0211","text":"repository: https://github.com/ctz/webpki-roots license: MPL-2.0","title":"webpki-roots 0.21.1"},{"location":"policies/credits/#wepoll-ffi-012","text":"repository: https://github.com/aclysma/wepoll-ffi license: Apache-2.0 OR BSD-2-Clause OR MIT","title":"wepoll-ffi 0.1.2"},{"location":"policies/credits/#which-311","text":"repository: https://github.com/harryfei/which-rs.git license: MIT","title":"which 3.1.1"},{"location":"policies/credits/#which-422","text":"repository: https://github.com/harryfei/which-rs.git license: MIT","title":"which 4.2.2"},{"location":"policies/credits/#widestring-043","text":"repository: https://github.com/starkat99/widestring-rs.git license: Apache-2.0 OR MIT","title":"widestring 0.4.3"},{"location":"policies/credits/#winapi-039","text":"repository: https://github.com/retep998/winapi-rs license: Apache-2.0 OR MIT","title":"winapi 0.3.9"},{"location":"policies/credits/#winapi-i686-pc-windows-gnu-040","text":"repository: https://github.com/retep998/winapi-rs license: Apache-2.0 OR MIT","title":"winapi-i686-pc-windows-gnu 0.4.0"},{"location":"policies/credits/#winapi-util-015","text":"repository: https://github.com/BurntSushi/winapi-util license: MIT OR Unlicense","title":"winapi-util 0.1.5"},{"location":"policies/credits/#winapi-x86_64-pc-windows-gnu-040","text":"repository: https://github.com/retep998/winapi-rs license: Apache-2.0 OR MIT","title":"winapi-x86_64-pc-windows-gnu 0.4.0"},{"location":"policies/credits/#winreg-062","text":"repository: https://github.com/gentoo90/winreg-rs license: MIT","title":"winreg 0.6.2"},{"location":"policies/credits/#winreg-070","text":"repository: https://github.com/gentoo90/winreg-rs license: MIT","title":"winreg 0.7.0"},{"location":"policies/credits/#wyz-040","text":"repository: https://github.com/myrrlyn/wyz license: MIT","title":"wyz 0.4.0"},{"location":"policies/credits/#xattr-022","text":"repository: https://github.com/Stebalien/xattr license: Apache-2.0 OR MIT","title":"xattr 0.2.2"},{"location":"policies/credits/#xml-rs-084","text":"repository: https://github.com/netvl/xml-rs license: MIT","title":"xml-rs 0.8.4"},{"location":"policies/credits/#yaml-rust-045","text":"repository: https://github.com/chyh1990/yaml-rust license: Apache-2.0 OR MIT","title":"yaml-rust 0.4.5"},{"location":"policies/credits/#zeroize-142","text":"repository: https://github.com/iqlusioninc/crates/tree/main/zeroize license: Apache-2.0 OR MIT","title":"zeroize 1.4.2"},{"location":"policies/credits/#zeroize_derive-120","text":"repository: https://github.com/iqlusioninc/crates/tree/main/zeroize/derive license: Apache-2.0 OR MIT","title":"zeroize_derive 1.2.0"},{"location":"policies/license/","text":"License \u00b6 Databend is licensed under Apache 2.0 LICENSE. Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and \u00a9 You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2021 Datafuse Labs Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"policies/license/#license","text":"Databend is licensed under Apache 2.0 LICENSE. Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and \u00a9 You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2021 Datafuse Labs Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"policies/notice/","text":"Databend includes some code from \u00b6 arrow/datafusion pola-rs/polars We include the text of the original license below: Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Databend includes some code from"},{"location":"policies/notice/#databend-includes-some-code-from","text":"arrow/datafusion pola-rs/polars We include the text of the original license below: Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Databend includes some code from"},{"location":"rfcs/cli/0001-cli-design/","text":"Proposal: Databend CLI Design Doc \u00b6 Background \u00b6 bendctl is a command-line tool for creating, listing, logging, deleting databend running instances on local or on cloud. It also supports to port forward webUI, monitoring dashboard on local and run SQL query from command line Goals \u00b6 Centralized way to manage running databend cluster on local or on k8s(Cloud) (start, delete, update, log) Manage and install release Instances on local machine Show different dashboards on local (prometheus, jaeger, query web UI (like querybook or superset)) Support to run query or load data through command line TLS Authentication support: support client side authentication, and also support to configure mTLS for managed databend instances Non Goals for now \u00b6 More detailed managements like manage schema, table etc Query Task visualization (list and show all query tasks on current cluster) RBAC tenant management(add a subcommand tenant is helpful, and is compatible with this design) Installation \u00b6 Use single line install script to install bendctl on local machine curl -fsS https://raw.githubusercontent.com/datafuselabs/databend/main/scripts/installer/install.sh | bash SubCommands \u00b6 Cluster Create \u00b6 Create, Configure and switch to a databend cluster using the following command: bendctl cluster create --profile = <databend profile> Support three kinds of profile in alpha stage, local: local profile will run standalone databend cluster on local(one running databend-query instance and one running databend-dfs instance) demo: install a standalone databend instance on cloud(k8s or maybe fargate in later stage) cluster: install databend cluster on cloud( through databend operator ) Support to use flags or yaml or toml files for deployment configuration setup For example: Run databend instance on local and setup the api address, version, tls for it bendctl cluster create --profile = local --set local.mysql_port = 3307 --set local.http_address = 127 .0.0.1:7070 --set local.version = v0.4.88-nightly --set local.tls_key = <key file location> --set local.tls_cert = <cert file location --set local.ca_cert = <ca cert location> Create and configure databend cluster through toml file or yaml file bendctl cluster create -f cluster_configuration.toml Cluster List \u00b6 List all clusters managed by the command line (Name with * in the cluster used in current session) bendctl cluster list | NAME | PROFILE | CLUSTER | STATUS | ADDRESS | TLS | | default ( * ) | local | local | RUNNING | localhost:3307 | disabled | | demo | demo | minikube | RUNNING | 172 .0.0.11:3307 | disabled | | production | cluster | GKE | RUNNING | 192 .12.1.1:3307 | enabled | Cluster View \u00b6 View databend components in current cluster For example: In cluster profile: bendctl cluster view | NAME | CLUSTER | COMPONENT | STATUS | TLS | | query-1 | GKE | databend-query | running | enabled | | query-2 | GKE | databend-query | running | enabled | | query-3 | GKE | databend-query | pending | enabled | | dfs-1 | GKE | databend-dfs | running | enabled | | dfs-2 | GKE | databend-dfs | running | enabled | Check on disk utilization bendctl cluster df | NAME | COMPONENT | USED | ALWAYABLE | LOCATION | | local-disk-1 | Block | 10Gi | 90Gi | /mnt/databend-dfs | | s3-disk | Object | 100 Gi | 1000Gi | s3://bucket-1/mnt/databend-dfs | Cluster delete \u00b6 For local profile, pids in running instances shall be killed, and for cluster profile, computing pods would be deleted, can add some flags to delete disk resources as well( RBAC needed) bendctl cluster delete Cluster log \u00b6 Show logs in current running instance show all databend-query logs bendctl cluster log --component = query --all The command above would show all databend-dfs logs bendctl cluster log --component = dfs --all The command above would show databend operator logs bendctl cluster log --component = operator Cluster add \u00b6 Add component to current storage The following command add two query nodes, each need 2 cpu resource bendctl cluster add --component query --num 2 --cpu 2 --namespace = <operator namespace> Cluster use \u00b6 Switch to another cluster The Command will switch to another cluster run on GKE cloud bendctl cluster use --name cloud-instance-1 --cluster GKE --kubeconfig ~/.kube/config --kubecontext gke-cloud-1 Cluster Check \u00b6 Check whether current configuration can be deployed on given cluster It will check on port availability, and storage resource availability for deployment bendctl cluster check --profile = local It will check on cloud resources, whether compute nodes could be scheduled on given cloud platform, whether TLS configured etc bendctl cluster check -f deploy.yaml Cluster Analyze \u00b6 Analyze and troubleshooting on given configuration, difference between analyze and check is that analyze is troubleshooting on a running cluster, and check mainly used for pre-fight check bendctl cluster analyze --profile = local Cluster Update \u00b6 Update cluster to a newer version bendctl cluster update v0.5.1-nightly Query \u00b6 Run query using selected client bendctl query 'SELECT * FROM TABLE1' --client = mysql","title":"DatabendCLI Design"},{"location":"rfcs/cli/0001-cli-design/#proposal-databend-cli-design-doc","text":"","title":"Proposal: Databend CLI Design Doc"},{"location":"rfcs/cli/0001-cli-design/#background","text":"bendctl is a command-line tool for creating, listing, logging, deleting databend running instances on local or on cloud. It also supports to port forward webUI, monitoring dashboard on local and run SQL query from command line","title":"Background"},{"location":"rfcs/cli/0001-cli-design/#goals","text":"Centralized way to manage running databend cluster on local or on k8s(Cloud) (start, delete, update, log) Manage and install release Instances on local machine Show different dashboards on local (prometheus, jaeger, query web UI (like querybook or superset)) Support to run query or load data through command line TLS Authentication support: support client side authentication, and also support to configure mTLS for managed databend instances","title":"Goals"},{"location":"rfcs/cli/0001-cli-design/#non-goals-for-now","text":"More detailed managements like manage schema, table etc Query Task visualization (list and show all query tasks on current cluster) RBAC tenant management(add a subcommand tenant is helpful, and is compatible with this design)","title":"Non Goals for now"},{"location":"rfcs/cli/0001-cli-design/#installation","text":"Use single line install script to install bendctl on local machine curl -fsS https://raw.githubusercontent.com/datafuselabs/databend/main/scripts/installer/install.sh | bash","title":"Installation"},{"location":"rfcs/cli/0001-cli-design/#subcommands","text":"","title":"SubCommands"},{"location":"rfcs/cli/0001-cli-design/#cluster-create","text":"Create, Configure and switch to a databend cluster using the following command: bendctl cluster create --profile = <databend profile> Support three kinds of profile in alpha stage, local: local profile will run standalone databend cluster on local(one running databend-query instance and one running databend-dfs instance) demo: install a standalone databend instance on cloud(k8s or maybe fargate in later stage) cluster: install databend cluster on cloud( through databend operator ) Support to use flags or yaml or toml files for deployment configuration setup For example: Run databend instance on local and setup the api address, version, tls for it bendctl cluster create --profile = local --set local.mysql_port = 3307 --set local.http_address = 127 .0.0.1:7070 --set local.version = v0.4.88-nightly --set local.tls_key = <key file location> --set local.tls_cert = <cert file location --set local.ca_cert = <ca cert location> Create and configure databend cluster through toml file or yaml file bendctl cluster create -f cluster_configuration.toml","title":"Cluster Create"},{"location":"rfcs/cli/0001-cli-design/#cluster-list","text":"List all clusters managed by the command line (Name with * in the cluster used in current session) bendctl cluster list | NAME | PROFILE | CLUSTER | STATUS | ADDRESS | TLS | | default ( * ) | local | local | RUNNING | localhost:3307 | disabled | | demo | demo | minikube | RUNNING | 172 .0.0.11:3307 | disabled | | production | cluster | GKE | RUNNING | 192 .12.1.1:3307 | enabled |","title":"Cluster List"},{"location":"rfcs/cli/0001-cli-design/#cluster-view","text":"View databend components in current cluster For example: In cluster profile: bendctl cluster view | NAME | CLUSTER | COMPONENT | STATUS | TLS | | query-1 | GKE | databend-query | running | enabled | | query-2 | GKE | databend-query | running | enabled | | query-3 | GKE | databend-query | pending | enabled | | dfs-1 | GKE | databend-dfs | running | enabled | | dfs-2 | GKE | databend-dfs | running | enabled | Check on disk utilization bendctl cluster df | NAME | COMPONENT | USED | ALWAYABLE | LOCATION | | local-disk-1 | Block | 10Gi | 90Gi | /mnt/databend-dfs | | s3-disk | Object | 100 Gi | 1000Gi | s3://bucket-1/mnt/databend-dfs |","title":"Cluster View"},{"location":"rfcs/cli/0001-cli-design/#cluster-delete","text":"For local profile, pids in running instances shall be killed, and for cluster profile, computing pods would be deleted, can add some flags to delete disk resources as well( RBAC needed) bendctl cluster delete","title":"Cluster delete"},{"location":"rfcs/cli/0001-cli-design/#cluster-log","text":"Show logs in current running instance show all databend-query logs bendctl cluster log --component = query --all The command above would show all databend-dfs logs bendctl cluster log --component = dfs --all The command above would show databend operator logs bendctl cluster log --component = operator","title":"Cluster log"},{"location":"rfcs/cli/0001-cli-design/#cluster-add","text":"Add component to current storage The following command add two query nodes, each need 2 cpu resource bendctl cluster add --component query --num 2 --cpu 2 --namespace = <operator namespace>","title":"Cluster add"},{"location":"rfcs/cli/0001-cli-design/#cluster-use","text":"Switch to another cluster The Command will switch to another cluster run on GKE cloud bendctl cluster use --name cloud-instance-1 --cluster GKE --kubeconfig ~/.kube/config --kubecontext gke-cloud-1","title":"Cluster use"},{"location":"rfcs/cli/0001-cli-design/#cluster-check","text":"Check whether current configuration can be deployed on given cluster It will check on port availability, and storage resource availability for deployment bendctl cluster check --profile = local It will check on cloud resources, whether compute nodes could be scheduled on given cloud platform, whether TLS configured etc bendctl cluster check -f deploy.yaml","title":"Cluster Check"},{"location":"rfcs/cli/0001-cli-design/#cluster-analyze","text":"Analyze and troubleshooting on given configuration, difference between analyze and check is that analyze is troubleshooting on a running cluster, and check mainly used for pre-fight check bendctl cluster analyze --profile = local","title":"Cluster Analyze"},{"location":"rfcs/cli/0001-cli-design/#cluster-update","text":"Update cluster to a newer version bendctl cluster update v0.5.1-nightly","title":"Cluster Update"},{"location":"rfcs/cli/0001-cli-design/#query","text":"Run query using selected client bendctl query 'SELECT * FROM TABLE1' --client = mysql","title":"Query"},{"location":"rfcs/query/0001-join-framework-design/","text":"Proposal: Join framework \u00b6 Background \u00b6 Join is one of the major features in SQL. Meanwhile, it's the most complicated part either. Thus in this section, we will make a brief introduction to types of join semantics and join algorithms. Generally, join can be categorized as following types by semantic: INNER JOIN : return all tuples satisfy the join condition LEFT OUTER JOIN : return all tuples satisfy the join condition and the rows from left table for which no row from right table satisfies the join condition RIGHT OUTER JOIN : return all tuples satisfy the join condition and the rows from right table for which no row from left table satisfies the join condition FULL OUTER JOIN : return all tuples satisfy the join condition and the rows from a table for which no row from other table satisfies the join condition CROSS JOIN : cartesian product of joined tables Besides, IN , EXISTS , NOT IN , NOT EXISTS expressions can be implemented by semi-join and anti-join (known as subquery). There are three kinds of common join algorithms: Nested-loop join Hash join Sort-merge join Nested-loop join is the basic join algorithm, it can be described as following pseudo code: // R\u22c8S var innerTable = R var outerTable = S var result for s <- outerTable: for r <- innerTable: if condition(r, s) == true: insert(result, combine(r, s)) Before introducing hash join, we introduce the definition of equi join here. A equi join is join whose join condition is an equation(e.g. r.a == s.a ). For the joins whose join condition is not an equation, we call them non-equi join Hash join can only work with equi join. It can be described as two phase: build phase and probe phase . As inner table and outer table of nested-loop join, hash join will choose a table as build side and another table as probe side . The pseudo code of hash join: // R\u22c8S var build = R var probe = S var hashTable var result // Build phase for r <- build: var key = hash(r, condition) insert(hashTable, key, r) // Probe phase for s <- probe: var key = hash(s, condition) if exists(hashTable, key): var r = get(hashTable, key) insert(result, combine(r, s)) Sort-merge join will sort the joined tables if they are not sorted by join key, and then merge them like merge sort. Generally, a sort-merge join can only work with equi-join either, but it exists a band join optimization that can make sort-merge join work with some specific non-equi join. We won't talk about this here since it's a little bit out of scope. Join framework \u00b6 To implement join, we have several parts of work to be done: Support parse join statement into logical plan Support bind column reference for joined tables Support some basic heuristic optimization(e.g. outer join elimination, subquery elimination) and join reorder with choosing implementation Support some join algorithms(local execution for now but design for distributed execution) Parser & Planner \u00b6 According to ANSI-SQL specification, joins are defined in FROM clause. Besides, subquery in other clauses can be translated to join(correlated subquery will be translated to semi join or anti join) in some cases. After parsing SQL string into AST, we will build logical plan from AST with PlanParser . Following bnf definition is a simplified ANSI-SQL specification of FROM clause: < from clause > ::= FROM < table reference list > < table reference list > ::= < table reference > [ { < comma > < table reference > }... ] < table reference > ::= < table primary or joined table > < table primary or joined table > ::= < table primary > | < joined table > < table primary > ::= < table or query name > [ [ AS ] < correlation name > [ < left paren > < derived column list > < right paren > ] ] | < derived table > [ AS ] < correlation name > [ < left paren > < derived column list > < right paren > ] | < left paren > < joined table > < right paren > < joined table > ::= < cross join > | < qualified join > | < natural join > < cross join > ::= < table reference > CROSS JOIN < table primary > < qualified join > ::= < table reference > [ < join type > ] JOIN < table reference > < join specification > < natural join > ::= < table reference > NATURAL [ < join type > ] JOIN < table primary > < join specification > ::= < join condition > | < named columns join > < join condition > ::= ON < search condition > < named columns join > ::= USING < left paren > < join column list > < right paren > < join type > ::= INNER | < outer join type > [ OUTER ] < outer join type > ::= LEFT | RIGHT | FULL < join column list > ::= < column name list > <table reference> concated with <comma> are cross joined. And it's possible to find some conjunctions in WHERE clause as their join conditions, that is rewriting cross join into inner join. There are many queries organized in this way that doesn't explicitly specify join condition, for example TPCH query set. sqlparser library can parse a SQL string into AST. Joins are organized as a tree structure. There are following kinds of join trees: Left deep tree Right deep tree Bushy tree In left deep tree, every join node's right child is a table, for example: SELECT * FROM a , b , c , d ; /* join / \\ join d / \\ join c / \\ a b */ In right deep tree, every join node's left child is a table, for example: SELECT * FROM a , b , c , d ; /* join / \\ a join / \\ b join / \\ c d */ In bushy tree, all children of every join node can be either result of join or table, for example: SELECT * FROM a , b , c , d ; /* join / \\ join join / \\ / \\ a b c d */ Most of join s can be represented as left deep tree, which is easier to optimize. We can rewrite some joins to left deep tree during parsing phase. Here's an example of sqlparser AST, the comment part is simplified AST debug string: SELECT * FROM a , b NATURAL JOIN c , d ; /* Query { with: None, body: Select( Select { projection: [Wildcard], from: [ TableWithJoins { relation: Table { name: \"a\", }, joins: [] }, TableWithJoins { relation: Table { name: \"b\", }, joins: [ Join { relation: Table { name: \"c\", }, join_operator: Inner(Natural) } ] }, TableWithJoins { relation: Table { name: \"d\", }, joins: [] } ], } ), } */ The AST above can be directly represented as a bushy tree: join / \\ join d / \\ a join / \\ b c This bushy tree is equivalent to the following left deep tree so we can rewrite it in parsing phase: join / \\ join d / \\ join c / \\ a b After rewriting AST to left deep tree, we will bind the AST to concrete tables and columns with catalog. During binding, semantic checking is necessary(e.g. check whether column name is ambiguous). To implement semantic checking and simplify the binding process, we introduce Scope to represent context of each query block. It will record information about available columns in current context and which table they belong to. Columns from a parent Scope is visible to all of its children Scope . struct Scope { pub parent : Arc < Scope > , pub columns : Vec < ColumnRef > } Here's an example to explain how Scope works: CREATE TABLE t0 ( a INT ); CREATE TABLE t1 ( b INT ); CREATE TABLE t2 ( c INT ); SELECT * FROM t0 , ( SELECT b , c , c + 1 AS d FROM t1 , t2 ) t ; /* Scope root: [t0.a, t.b, t.c, t.d] | \\ | Scope t0: [a] | Scope t: [t1.b, t2.c, d] | \\ | Scope t1: [b] | Scope t2: [c] */ Since it may exist different column with same name after join, we should identify ColumnRef with a unique ColumnID . Meanwhile, correlation names are ensured to be unique, it's fine to identify them with name strings. struct ColumnRef { pub id : ColumnID , pub column_name : String , pub table_name : String } With unique ColumnID , we can check whether a query is ambiguous or not and keep their original name at the same time. For planner, we will add a variant Join for PlanNode to represent join operator: enum PlanNode { .. . Join ( JoinPlan ) } enum JoinType { Inner , LeftOuter , RightOuter , FullOuter , Cross } struct JoinPlan { pub join_type : JoinType , pub join_conditions : Vec < ExpressionPlan > , // Conjunctions of join condition pub left_child : Arc < PlanNode > , pub right_child : Arc < PlanNode > } Here's a problem that databend-query uses arrow::datatypes::Schema to represent data schema, while arrow::datatypes::Schema doesn't support identify columns with ColumnID natively. I suggest to introduce an internal DataSchema struct to represent data schema in databend-query, which can store more information and can be converted to arrow::datatypes::Schema naturally. struct DataSchema { pub columns : Vec < Arc < Column >> } struct Column { pub column_id : ColumnID , pub column_name : String , pub data_type : DataType , pub is_nullable : bool } Optimizer \u00b6 There are two kinds of optimization to be done: Heuristic optimization Cost-based optimization The heuristic optimization( RBO , aka rule-based optimization), is the optimization which can always reduce cost of a query. Since there are too many heuristic rules, we won't discuss this here. The cost-based optimization uses statistic information to calculate the cost of a query. With exploring framework(e.g. Volcano optimizer, Cascades optimizer), it can choose the best execution plan. Optimizer is the most complicated part in a SQL engine, we'd better only support limited heuristic optimization at the beginning. TODO: list common heuristic rules Execution \u00b6 As we discussed in section Background , join algorithms can be categorized into three kinds: Nested-loop join Hash join Sort-merge join Besides, there are two kinds of distributed join algorithms: Broadcast join Repartition join(aka shuffle join) We won't talk about detail of distributed join algorithms here, but we still need to consider about them. Different join algorithms have advantage on different scenarios. Nested-loop join is effective if the amount of data is relatively small. With vectorized execution model, it's natural to implement block nested-loop join, which is a refined nested-loop join algorithm. Another advantage of nested-loop join is it can work with non-equi join condition. Hash join is effective if one of the joined table is small and the other one is large. Since distributed join algorithm will always produce small tables(by partition), it fits hash join a lot. Meanwhile, vectorized hash join algorithm has been introduced by Marcin Zucowski (Co-founder of Snowflake, Phd of CWI). The disadvantage of hash join is that hash join will consume more memory than other join algorithms, and it only supports equi join. Sort-merge join is effective if inputs are sorted, while this is rarely happened. The comparison above is much biased, in fact it can hardly say that which algorithm is better. IMO, we can implement hash join and nested-loop join first since they are more common. Since we don't have infrastructure(planner, optimizer) for choosing join algorithm for now, I suggest to only implement block nested-loop join at present so we can build a complete prototype. We'are going to introduce a vectorized block nested-loop join algorithm. Pseudo code of naive nested-loop join has been introduced in Background section. As we know, nested-loop join will fetch only one row from outer table in each loop, which doen't have good locality. Block nested-loop join is a nested-loop join that will fetch a block of data in each loop. Here we introduce the naive block nested-loop join. // R\u22c8S var innerTable = R var outerTable = S var result for s <- outerTable.fetchBlock(): for r <- innerTable.fetchBlock(): buffer = conditionEvalBlock(s, r) for row <- buffer: insert(result, row) In vetorized execution, we can use a bit map to indicate whether a row should be return to result set or not. Then we can materialize the result later. For example, assume we have following SQL query: CREATE TABLE t ( a int , b int ); CREATE TABLE t1 ( b int , c int ); -- insert some rows SELECT a , b , c FROM t INNER JOIN t1 ON t . b = t1 . b ; The execution plan of this query should look like: Join (t.b = t1.b) -> TableScan t -> TableScan t1 If we use the vectorized block nested-loop join algorithm introduced above, the pseudo code should look like: var leftChild: BlockStream = scan(t) var rightChild: BlockStream = scan(t1) var condition: Expression = equal(column(t.b), column(t1.b)) var result for l <- leftChild: for r <- rightChild: buffer = mergeBlock(l, r) var bitMap: Array[boolean] = condition.eval(buffer) buffer.insertColumn(bitMap) result.insertBlock(buffer) materialize(result) In databend-query, we can add a NestedLoopJoinTransform to implement vectorized block nested-loop join.","title":"DatabendQuery Join"},{"location":"rfcs/query/0001-join-framework-design/#proposal-join-framework","text":"","title":"Proposal: Join framework"},{"location":"rfcs/query/0001-join-framework-design/#background","text":"Join is one of the major features in SQL. Meanwhile, it's the most complicated part either. Thus in this section, we will make a brief introduction to types of join semantics and join algorithms. Generally, join can be categorized as following types by semantic: INNER JOIN : return all tuples satisfy the join condition LEFT OUTER JOIN : return all tuples satisfy the join condition and the rows from left table for which no row from right table satisfies the join condition RIGHT OUTER JOIN : return all tuples satisfy the join condition and the rows from right table for which no row from left table satisfies the join condition FULL OUTER JOIN : return all tuples satisfy the join condition and the rows from a table for which no row from other table satisfies the join condition CROSS JOIN : cartesian product of joined tables Besides, IN , EXISTS , NOT IN , NOT EXISTS expressions can be implemented by semi-join and anti-join (known as subquery). There are three kinds of common join algorithms: Nested-loop join Hash join Sort-merge join Nested-loop join is the basic join algorithm, it can be described as following pseudo code: // R\u22c8S var innerTable = R var outerTable = S var result for s <- outerTable: for r <- innerTable: if condition(r, s) == true: insert(result, combine(r, s)) Before introducing hash join, we introduce the definition of equi join here. A equi join is join whose join condition is an equation(e.g. r.a == s.a ). For the joins whose join condition is not an equation, we call them non-equi join Hash join can only work with equi join. It can be described as two phase: build phase and probe phase . As inner table and outer table of nested-loop join, hash join will choose a table as build side and another table as probe side . The pseudo code of hash join: // R\u22c8S var build = R var probe = S var hashTable var result // Build phase for r <- build: var key = hash(r, condition) insert(hashTable, key, r) // Probe phase for s <- probe: var key = hash(s, condition) if exists(hashTable, key): var r = get(hashTable, key) insert(result, combine(r, s)) Sort-merge join will sort the joined tables if they are not sorted by join key, and then merge them like merge sort. Generally, a sort-merge join can only work with equi-join either, but it exists a band join optimization that can make sort-merge join work with some specific non-equi join. We won't talk about this here since it's a little bit out of scope.","title":"Background"},{"location":"rfcs/query/0001-join-framework-design/#join-framework","text":"To implement join, we have several parts of work to be done: Support parse join statement into logical plan Support bind column reference for joined tables Support some basic heuristic optimization(e.g. outer join elimination, subquery elimination) and join reorder with choosing implementation Support some join algorithms(local execution for now but design for distributed execution)","title":"Join framework"},{"location":"rfcs/query/0001-join-framework-design/#parser-planner","text":"According to ANSI-SQL specification, joins are defined in FROM clause. Besides, subquery in other clauses can be translated to join(correlated subquery will be translated to semi join or anti join) in some cases. After parsing SQL string into AST, we will build logical plan from AST with PlanParser . Following bnf definition is a simplified ANSI-SQL specification of FROM clause: < from clause > ::= FROM < table reference list > < table reference list > ::= < table reference > [ { < comma > < table reference > }... ] < table reference > ::= < table primary or joined table > < table primary or joined table > ::= < table primary > | < joined table > < table primary > ::= < table or query name > [ [ AS ] < correlation name > [ < left paren > < derived column list > < right paren > ] ] | < derived table > [ AS ] < correlation name > [ < left paren > < derived column list > < right paren > ] | < left paren > < joined table > < right paren > < joined table > ::= < cross join > | < qualified join > | < natural join > < cross join > ::= < table reference > CROSS JOIN < table primary > < qualified join > ::= < table reference > [ < join type > ] JOIN < table reference > < join specification > < natural join > ::= < table reference > NATURAL [ < join type > ] JOIN < table primary > < join specification > ::= < join condition > | < named columns join > < join condition > ::= ON < search condition > < named columns join > ::= USING < left paren > < join column list > < right paren > < join type > ::= INNER | < outer join type > [ OUTER ] < outer join type > ::= LEFT | RIGHT | FULL < join column list > ::= < column name list > <table reference> concated with <comma> are cross joined. And it's possible to find some conjunctions in WHERE clause as their join conditions, that is rewriting cross join into inner join. There are many queries organized in this way that doesn't explicitly specify join condition, for example TPCH query set. sqlparser library can parse a SQL string into AST. Joins are organized as a tree structure. There are following kinds of join trees: Left deep tree Right deep tree Bushy tree In left deep tree, every join node's right child is a table, for example: SELECT * FROM a , b , c , d ; /* join / \\ join d / \\ join c / \\ a b */ In right deep tree, every join node's left child is a table, for example: SELECT * FROM a , b , c , d ; /* join / \\ a join / \\ b join / \\ c d */ In bushy tree, all children of every join node can be either result of join or table, for example: SELECT * FROM a , b , c , d ; /* join / \\ join join / \\ / \\ a b c d */ Most of join s can be represented as left deep tree, which is easier to optimize. We can rewrite some joins to left deep tree during parsing phase. Here's an example of sqlparser AST, the comment part is simplified AST debug string: SELECT * FROM a , b NATURAL JOIN c , d ; /* Query { with: None, body: Select( Select { projection: [Wildcard], from: [ TableWithJoins { relation: Table { name: \"a\", }, joins: [] }, TableWithJoins { relation: Table { name: \"b\", }, joins: [ Join { relation: Table { name: \"c\", }, join_operator: Inner(Natural) } ] }, TableWithJoins { relation: Table { name: \"d\", }, joins: [] } ], } ), } */ The AST above can be directly represented as a bushy tree: join / \\ join d / \\ a join / \\ b c This bushy tree is equivalent to the following left deep tree so we can rewrite it in parsing phase: join / \\ join d / \\ join c / \\ a b After rewriting AST to left deep tree, we will bind the AST to concrete tables and columns with catalog. During binding, semantic checking is necessary(e.g. check whether column name is ambiguous). To implement semantic checking and simplify the binding process, we introduce Scope to represent context of each query block. It will record information about available columns in current context and which table they belong to. Columns from a parent Scope is visible to all of its children Scope . struct Scope { pub parent : Arc < Scope > , pub columns : Vec < ColumnRef > } Here's an example to explain how Scope works: CREATE TABLE t0 ( a INT ); CREATE TABLE t1 ( b INT ); CREATE TABLE t2 ( c INT ); SELECT * FROM t0 , ( SELECT b , c , c + 1 AS d FROM t1 , t2 ) t ; /* Scope root: [t0.a, t.b, t.c, t.d] | \\ | Scope t0: [a] | Scope t: [t1.b, t2.c, d] | \\ | Scope t1: [b] | Scope t2: [c] */ Since it may exist different column with same name after join, we should identify ColumnRef with a unique ColumnID . Meanwhile, correlation names are ensured to be unique, it's fine to identify them with name strings. struct ColumnRef { pub id : ColumnID , pub column_name : String , pub table_name : String } With unique ColumnID , we can check whether a query is ambiguous or not and keep their original name at the same time. For planner, we will add a variant Join for PlanNode to represent join operator: enum PlanNode { .. . Join ( JoinPlan ) } enum JoinType { Inner , LeftOuter , RightOuter , FullOuter , Cross } struct JoinPlan { pub join_type : JoinType , pub join_conditions : Vec < ExpressionPlan > , // Conjunctions of join condition pub left_child : Arc < PlanNode > , pub right_child : Arc < PlanNode > } Here's a problem that databend-query uses arrow::datatypes::Schema to represent data schema, while arrow::datatypes::Schema doesn't support identify columns with ColumnID natively. I suggest to introduce an internal DataSchema struct to represent data schema in databend-query, which can store more information and can be converted to arrow::datatypes::Schema naturally. struct DataSchema { pub columns : Vec < Arc < Column >> } struct Column { pub column_id : ColumnID , pub column_name : String , pub data_type : DataType , pub is_nullable : bool }","title":"Parser &amp; Planner"},{"location":"rfcs/query/0001-join-framework-design/#optimizer","text":"There are two kinds of optimization to be done: Heuristic optimization Cost-based optimization The heuristic optimization( RBO , aka rule-based optimization), is the optimization which can always reduce cost of a query. Since there are too many heuristic rules, we won't discuss this here. The cost-based optimization uses statistic information to calculate the cost of a query. With exploring framework(e.g. Volcano optimizer, Cascades optimizer), it can choose the best execution plan. Optimizer is the most complicated part in a SQL engine, we'd better only support limited heuristic optimization at the beginning. TODO: list common heuristic rules","title":"Optimizer"},{"location":"rfcs/query/0001-join-framework-design/#execution","text":"As we discussed in section Background , join algorithms can be categorized into three kinds: Nested-loop join Hash join Sort-merge join Besides, there are two kinds of distributed join algorithms: Broadcast join Repartition join(aka shuffle join) We won't talk about detail of distributed join algorithms here, but we still need to consider about them. Different join algorithms have advantage on different scenarios. Nested-loop join is effective if the amount of data is relatively small. With vectorized execution model, it's natural to implement block nested-loop join, which is a refined nested-loop join algorithm. Another advantage of nested-loop join is it can work with non-equi join condition. Hash join is effective if one of the joined table is small and the other one is large. Since distributed join algorithm will always produce small tables(by partition), it fits hash join a lot. Meanwhile, vectorized hash join algorithm has been introduced by Marcin Zucowski (Co-founder of Snowflake, Phd of CWI). The disadvantage of hash join is that hash join will consume more memory than other join algorithms, and it only supports equi join. Sort-merge join is effective if inputs are sorted, while this is rarely happened. The comparison above is much biased, in fact it can hardly say that which algorithm is better. IMO, we can implement hash join and nested-loop join first since they are more common. Since we don't have infrastructure(planner, optimizer) for choosing join algorithm for now, I suggest to only implement block nested-loop join at present so we can build a complete prototype. We'are going to introduce a vectorized block nested-loop join algorithm. Pseudo code of naive nested-loop join has been introduced in Background section. As we know, nested-loop join will fetch only one row from outer table in each loop, which doen't have good locality. Block nested-loop join is a nested-loop join that will fetch a block of data in each loop. Here we introduce the naive block nested-loop join. // R\u22c8S var innerTable = R var outerTable = S var result for s <- outerTable.fetchBlock(): for r <- innerTable.fetchBlock(): buffer = conditionEvalBlock(s, r) for row <- buffer: insert(result, row) In vetorized execution, we can use a bit map to indicate whether a row should be return to result set or not. Then we can materialize the result later. For example, assume we have following SQL query: CREATE TABLE t ( a int , b int ); CREATE TABLE t1 ( b int , c int ); -- insert some rows SELECT a , b , c FROM t INNER JOIN t1 ON t . b = t1 . b ; The execution plan of this query should look like: Join (t.b = t1.b) -> TableScan t -> TableScan t1 If we use the vectorized block nested-loop join algorithm introduced above, the pseudo code should look like: var leftChild: BlockStream = scan(t) var rightChild: BlockStream = scan(t1) var condition: Expression = equal(column(t.b), column(t1.b)) var result for l <- leftChild: for r <- rightChild: buffer = mergeBlock(l, r) var bitMap: Array[boolean] = condition.eval(buffer) buffer.insertColumn(bitMap) result.insertBlock(buffer) materialize(result) In databend-query, we can add a NestedLoopJoinTransform to implement vectorized block nested-loop join.","title":"Execution"},{"location":"rfcs/query/0002-plan-expression/","text":"Expression and plan builder \u00b6 Summary \u00b6 Logic plan and expression play a big role throughout the life cycle of SQL query. This doc is intended to explain the new design of expressions and plan builder. Expression \u00b6 Alias Expression \u00b6 Aliasing is useful in SQL, we can alias a complex expression as a short alias name. Such as: select a + 3 as b . In the standard SQL protocol, aliasing can work in: Group By, eg: select a + 3 as b, count(1) from table group by b Having, eg: select a + 3 as b, count(1) as c from table group by b having c > 0 Order By: eg: select a + 3 as b from table order by b Notes ClickHouse has extended the usage of expression alias, it can be work in: recursive alias expression: eg: select a + 1 as b, b + 1 as c filter: eg: select a + 1 as b, b + 1 as c from table where c > 0 Note Currently we do not support clickhouse style alias expression. It can be implemented later. For expression alias, we only handle it at last, in projection stage. But We have to replace the alias of the expression as early as possible to prevent ambiguity later. Eg: select number + 1 as c, sum(number) from numbers(10) group by c having c > 3 order by c limit 10 Firstly, we can scan all the alias expressions from projection ASTs. c ---> (number + 1) Then we replaced the alias into the corresponding expression in having , order by , group by clause. So the query will be: select number + 1 as c, sum(number) from numbers(10) group by (number + 1) having (number + 1) > 3 order by (number + 1) limit 10 At last, when the query is finished, we apply the projection to rename the column (number+1) to c Let's take a look at the explain result of this query: | Limit: 10 Projection: (number + 1) as c:UInt64, sum(number):UInt64 Sort: (number + 1):UInt64 Having: ((number + 1) > 3) AggregatorFinal: groupBy=[[(number + 1)]], aggr=[[sum(number)]] RedistributeStage[state: AggregatorMerge, id: 0] AggregatorPartial: groupBy=[[(number + 1)]], aggr=[[sum(number)]] Expression: (number + 1):UInt64, number:UInt64 (Before GroupBy) ReadDataSource: scan partitions: [4], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] We can see we do not need to care about aliasing until the projection, so it will be very convenient to apply other expressions. Materialized Expression \u00b6 Materialized expression processing is that we can rebase the expression as a ExpressionColumn if the same expression is already processed upstream. Eg: select number + 1 as c, sum(number) as d group by c having number + 1 > 3 order by d desc After aliases replacement, we will know that order by is sum(number) , but sum(number) is already processed during the aggregating stage, so we can rebase the order by expression SortExpression { ... } to Column(\"sum(number)\") , this could remove useless calculation of same expressions. So number + 1 in having can also apply to rebase the expression. Expression Functions \u00b6 There are many kinds of expression functions. ScalarFunctions, One-to-one calculation process, the result rows is same as the input rows. eg: select database() AggregateFunctions, Many-to-one calculation process, eg: select sum(number) BinaryFunctions, a special kind of \u00b7ScalarFunctions\u00b7 eg: select 1 + 2 ... For ScalarFunctions, we really don't care about the whole block, we just care about the columns involved by the arguments. sum(number) just care about the Column which named number . And the result is also a column, so we have the virtual method in IFunction is: fn eval ( & self , columns : & [ DataColumn ], _input_rows : usize ) -> Result < DataColumn > ; For AggregateFunctions, we should keep the state in the corresponding function instance to apply the two-level merge, we have the following virtual method in IAggregateFunction : fn accumulate ( & mut self , columns : & [ DataColumn ], _input_rows : usize ) -> Result < () > ; fn accumulate_result ( & self ) -> Result < Vec < DataValue >> ; fn merge ( & mut self , _states : & [ DataValue ]) -> Result < () > ; fn merge_result ( & self ) -> Result < DataValue > ; The process is accumulate (apply data to the function) \u2192 accumulate_result (to get the current state) \u2192 merge (merge current state from other state) ---> merge_result (to get the final result value) ps: We don't store the arguments types and arguments names in functions, we can store them later if we need. Column \u00b6 Block is the unit of data passed between streams for pipeline processing, while Column is the unit of data passed between expressions. So in the view of expression(functions, literal, ...), everything is Column , we have DataColumn to represent a column. #[derive(Clone, Debug)] pub enum DataColumn { // Array of values. Array ( DataArrayRef ), // A Single value. Constant ( DataValue , usize ) } DataColumn::Constant is like ConstantColumn in ClickHouse . Note: We don't have ScalarValue , because it can be known as Constant(DataValue, 1) , and there is DataValue struct. Expression chain and expression executor \u00b6 Currently, we can collect the inner expression from expressions to build ExpressionChain. This could be done by Depth-first-search visiting. ExpressionFunction: number + (number + 1) will be : [ ExpressionColumn(number), ExpressionColumn(number), ExpressionLiteral(1), ExpressionBinary('+', 'number', '1'), ExpressionBinary('+', 'number', '(number + 1)') ] . We have the ExpressionExecutor the execute the expression chain, during the execution, we don't need to care about the kind of the arguments. We just consider them as ColumnExpression from upstream, so we just fetch the column number and the column (number + 1) from the block. Plan Builder \u00b6 None aggregation query \u00b6 This is for queries without group by and aggregate functions . Eg: explain select number + 1 as b from numbers(10) where number + 1 > 3 order by number + 3 | explain | +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Projection: (number + 1) as b:UInt64 Sort: (number + 3):UInt64 Expression: (number + 1):UInt64, (number + 3):UInt64 (Before OrderBy) Filter: ((number + 1) > 3) ReadDataSource: scan partitions: [4], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] | +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.02 sec) The build process is SourcePlan : schema \u2192 [number] FilterPlan: filter expression is (number + 1) > 3 , the schema keeps the same, schema \u2192 [number] Expression: we will collect expressions from order by and having clauses to apply the expression, schema \u2192 [number, number + 1, number + 3] Sort: since we already have the number + 1 in the input plan, so the sorting will consider number + 1 as ColumnExpression , schema \u2192 [number, number + 1, number + 3] Projection: applying the aliases and projection the columns, schema \u2192 [b] Aggregation query \u00b6 To build Aggregation query, there will be more complex than the previous one. Eg: explain select number + 1 as b, sum(number + 2 ) + 4 as c from numbers(10) where number + 3 > 0 group by number + 1 having c > 3 and sum(number + 4) + 1 > 4 order by sum(number + 5) + 1; | Projection: (number + 1) as b:UInt64, (sum((number + 2)) + 4) as c:UInt64 Sort: sum((number + 5)):UInt64 Having: (((sum((number + 2)) + 4) > 3) AND (sum((number + 4)) > 0)) Expression: (number + 1):UInt64, (sum((number + 2)) + 4):UInt64, sum((number + 5)):UInt64 (Before OrderBy) AggregatorFinal: groupBy=[[(number + 1)]], aggr=[[sum((number + 2)), sum((number + 5)), sum((number + 4))]] RedistributeStage[state: AggregatorMerge, id: 0] AggregatorPartial: groupBy=[[(number + 1)]], aggr=[[sum((number + 2)), sum((number + 5)), sum((number + 4))]] Expression: (number + 1):UInt64, (number + 2):UInt64, (number + 5):UInt64, (number + 4):UInt64 (Before GroupBy) Filter: ((number + 3) > 0) ReadDataSource: scan partitions: [4], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] The build process is SourcePlan : schema \u2192 [number] FilterPlan: filter expression is (number + 3) > 0 , the schema keeps the same, schema \u2192 [number] Expression: Before group by (number + 1):UInt64, (number + 2):UInt64, (number + 5):UInt64, (number + 4):UInt64 (Before GroupBy) Before GroupBy, We must visit all the expression in projections , having , group by to collect the expressions and aggregate functions, schema \u2192 [number, number + 1, number + 2, number + 4, number + 5] AggregatorPartial: groupBy=[[(number + 1)]], aggr=[[sum((number + 2)), sum((number + 5)), sum((number + 4))]] , note that: the expressions are already materialized in upstream, so we just conside all the arguments as columns. AggregatorFinal, schema \u2192 [number + 1, sum((number + 2)), sum((number + 5)), sum((number + 4))] Expression: schema \u2192 [number + 1, sum((number + 2)), sum((number + 5)), sum((number + 4)), sum((number + 2)) + 4, sum((number + 5)) + 1] Sort: the schema keeps the same Projection: schema \u2192 b, c","title":"DatabendQuery Expression"},{"location":"rfcs/query/0002-plan-expression/#expression-and-plan-builder","text":"","title":"Expression and plan builder"},{"location":"rfcs/query/0002-plan-expression/#summary","text":"Logic plan and expression play a big role throughout the life cycle of SQL query. This doc is intended to explain the new design of expressions and plan builder.","title":"Summary"},{"location":"rfcs/query/0002-plan-expression/#expression","text":"","title":"Expression"},{"location":"rfcs/query/0002-plan-expression/#alias-expression","text":"Aliasing is useful in SQL, we can alias a complex expression as a short alias name. Such as: select a + 3 as b . In the standard SQL protocol, aliasing can work in: Group By, eg: select a + 3 as b, count(1) from table group by b Having, eg: select a + 3 as b, count(1) as c from table group by b having c > 0 Order By: eg: select a + 3 as b from table order by b Notes ClickHouse has extended the usage of expression alias, it can be work in: recursive alias expression: eg: select a + 1 as b, b + 1 as c filter: eg: select a + 1 as b, b + 1 as c from table where c > 0 Note Currently we do not support clickhouse style alias expression. It can be implemented later. For expression alias, we only handle it at last, in projection stage. But We have to replace the alias of the expression as early as possible to prevent ambiguity later. Eg: select number + 1 as c, sum(number) from numbers(10) group by c having c > 3 order by c limit 10 Firstly, we can scan all the alias expressions from projection ASTs. c ---> (number + 1) Then we replaced the alias into the corresponding expression in having , order by , group by clause. So the query will be: select number + 1 as c, sum(number) from numbers(10) group by (number + 1) having (number + 1) > 3 order by (number + 1) limit 10 At last, when the query is finished, we apply the projection to rename the column (number+1) to c Let's take a look at the explain result of this query: | Limit: 10 Projection: (number + 1) as c:UInt64, sum(number):UInt64 Sort: (number + 1):UInt64 Having: ((number + 1) > 3) AggregatorFinal: groupBy=[[(number + 1)]], aggr=[[sum(number)]] RedistributeStage[state: AggregatorMerge, id: 0] AggregatorPartial: groupBy=[[(number + 1)]], aggr=[[sum(number)]] Expression: (number + 1):UInt64, number:UInt64 (Before GroupBy) ReadDataSource: scan partitions: [4], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] We can see we do not need to care about aliasing until the projection, so it will be very convenient to apply other expressions.","title":"Alias Expression"},{"location":"rfcs/query/0002-plan-expression/#materialized-expression","text":"Materialized expression processing is that we can rebase the expression as a ExpressionColumn if the same expression is already processed upstream. Eg: select number + 1 as c, sum(number) as d group by c having number + 1 > 3 order by d desc After aliases replacement, we will know that order by is sum(number) , but sum(number) is already processed during the aggregating stage, so we can rebase the order by expression SortExpression { ... } to Column(\"sum(number)\") , this could remove useless calculation of same expressions. So number + 1 in having can also apply to rebase the expression.","title":"Materialized Expression"},{"location":"rfcs/query/0002-plan-expression/#expression-functions","text":"There are many kinds of expression functions. ScalarFunctions, One-to-one calculation process, the result rows is same as the input rows. eg: select database() AggregateFunctions, Many-to-one calculation process, eg: select sum(number) BinaryFunctions, a special kind of \u00b7ScalarFunctions\u00b7 eg: select 1 + 2 ... For ScalarFunctions, we really don't care about the whole block, we just care about the columns involved by the arguments. sum(number) just care about the Column which named number . And the result is also a column, so we have the virtual method in IFunction is: fn eval ( & self , columns : & [ DataColumn ], _input_rows : usize ) -> Result < DataColumn > ; For AggregateFunctions, we should keep the state in the corresponding function instance to apply the two-level merge, we have the following virtual method in IAggregateFunction : fn accumulate ( & mut self , columns : & [ DataColumn ], _input_rows : usize ) -> Result < () > ; fn accumulate_result ( & self ) -> Result < Vec < DataValue >> ; fn merge ( & mut self , _states : & [ DataValue ]) -> Result < () > ; fn merge_result ( & self ) -> Result < DataValue > ; The process is accumulate (apply data to the function) \u2192 accumulate_result (to get the current state) \u2192 merge (merge current state from other state) ---> merge_result (to get the final result value) ps: We don't store the arguments types and arguments names in functions, we can store them later if we need.","title":"Expression Functions"},{"location":"rfcs/query/0002-plan-expression/#column","text":"Block is the unit of data passed between streams for pipeline processing, while Column is the unit of data passed between expressions. So in the view of expression(functions, literal, ...), everything is Column , we have DataColumn to represent a column. #[derive(Clone, Debug)] pub enum DataColumn { // Array of values. Array ( DataArrayRef ), // A Single value. Constant ( DataValue , usize ) } DataColumn::Constant is like ConstantColumn in ClickHouse . Note: We don't have ScalarValue , because it can be known as Constant(DataValue, 1) , and there is DataValue struct.","title":"Column"},{"location":"rfcs/query/0002-plan-expression/#expression-chain-and-expression-executor","text":"Currently, we can collect the inner expression from expressions to build ExpressionChain. This could be done by Depth-first-search visiting. ExpressionFunction: number + (number + 1) will be : [ ExpressionColumn(number), ExpressionColumn(number), ExpressionLiteral(1), ExpressionBinary('+', 'number', '1'), ExpressionBinary('+', 'number', '(number + 1)') ] . We have the ExpressionExecutor the execute the expression chain, during the execution, we don't need to care about the kind of the arguments. We just consider them as ColumnExpression from upstream, so we just fetch the column number and the column (number + 1) from the block.","title":"Expression chain and expression executor"},{"location":"rfcs/query/0002-plan-expression/#plan-builder","text":"","title":"Plan Builder"},{"location":"rfcs/query/0002-plan-expression/#none-aggregation-query","text":"This is for queries without group by and aggregate functions . Eg: explain select number + 1 as b from numbers(10) where number + 1 > 3 order by number + 3 | explain | +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Projection: (number + 1) as b:UInt64 Sort: (number + 3):UInt64 Expression: (number + 1):UInt64, (number + 3):UInt64 (Before OrderBy) Filter: ((number + 1) > 3) ReadDataSource: scan partitions: [4], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] | +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.02 sec) The build process is SourcePlan : schema \u2192 [number] FilterPlan: filter expression is (number + 1) > 3 , the schema keeps the same, schema \u2192 [number] Expression: we will collect expressions from order by and having clauses to apply the expression, schema \u2192 [number, number + 1, number + 3] Sort: since we already have the number + 1 in the input plan, so the sorting will consider number + 1 as ColumnExpression , schema \u2192 [number, number + 1, number + 3] Projection: applying the aliases and projection the columns, schema \u2192 [b]","title":"None aggregation query"},{"location":"rfcs/query/0002-plan-expression/#aggregation-query","text":"To build Aggregation query, there will be more complex than the previous one. Eg: explain select number + 1 as b, sum(number + 2 ) + 4 as c from numbers(10) where number + 3 > 0 group by number + 1 having c > 3 and sum(number + 4) + 1 > 4 order by sum(number + 5) + 1; | Projection: (number + 1) as b:UInt64, (sum((number + 2)) + 4) as c:UInt64 Sort: sum((number + 5)):UInt64 Having: (((sum((number + 2)) + 4) > 3) AND (sum((number + 4)) > 0)) Expression: (number + 1):UInt64, (sum((number + 2)) + 4):UInt64, sum((number + 5)):UInt64 (Before OrderBy) AggregatorFinal: groupBy=[[(number + 1)]], aggr=[[sum((number + 2)), sum((number + 5)), sum((number + 4))]] RedistributeStage[state: AggregatorMerge, id: 0] AggregatorPartial: groupBy=[[(number + 1)]], aggr=[[sum((number + 2)), sum((number + 5)), sum((number + 4))]] Expression: (number + 1):UInt64, (number + 2):UInt64, (number + 5):UInt64, (number + 4):UInt64 (Before GroupBy) Filter: ((number + 3) > 0) ReadDataSource: scan partitions: [4], scan schema: [number:UInt64], statistics: [read_rows: 10, read_bytes: 80] The build process is SourcePlan : schema \u2192 [number] FilterPlan: filter expression is (number + 3) > 0 , the schema keeps the same, schema \u2192 [number] Expression: Before group by (number + 1):UInt64, (number + 2):UInt64, (number + 5):UInt64, (number + 4):UInt64 (Before GroupBy) Before GroupBy, We must visit all the expression in projections , having , group by to collect the expressions and aggregate functions, schema \u2192 [number, number + 1, number + 2, number + 4, number + 5] AggregatorPartial: groupBy=[[(number + 1)]], aggr=[[sum((number + 2)), sum((number + 5)), sum((number + 4))]] , note that: the expressions are already materialized in upstream, so we just conside all the arguments as columns. AggregatorFinal, schema \u2192 [number + 1, sum((number + 2)), sum((number + 5)), sum((number + 4))] Expression: schema \u2192 [number + 1, sum((number + 2)), sum((number + 5)), sum((number + 4)), sum((number + 2)) + 4, sum((number + 5)) + 1] Sort: the schema keeps the same Projection: schema \u2192 b, c","title":"Aggregation query"},{"location":"rfcs/query/0003-data-shuffle/","text":"Distributed query and data shuffle \u00b6 Summary \u00b6 Distributed query is distributed database necessary feature. This doc is intended to explain the distributed query and its data flow design. Local query \u00b6 Let's see how normal queries run on a single database node. ' +------+ +------------+ +---------+ ' | | AST | | Plan | | ' SQL--->|Parser+------>|Plan Builder+----->|Optimizer| ' | | | | | | ' +------+ +------------+ +---+-----+ ' | Plan ' v ' +----------+ +-----------+ ' | | Processor | | ' Data <------+DataStream|<-----------+Interpreter| ' | | | | ' +----------+ +-----------+ Parser and AST \u00b6 Databend uses the third-party SQL parser and its AST. For more information, see: https://github.com/ballista-compute/sqlparser-rs PlanBuilder and Plan \u00b6 A query plan (or query execution plan) is a sequence of steps used to access data in Databend. It is built by PlanBuilder from AST. We also use tree to describe it(similar to AST). But it has some differences with AST: Plan is serializable and deserializable. Plan is grammatically safe, we don't worry about it. Plan is used to describe the computation and data dependency, not related to syntax priority We can show it with EXPLAIN SELECT ... mysql> EXPLAIN SELECT number % 3 AS key, SUM(number) AS value FROM numbers(1000) WHERE number > 10 AND number < 990 GROUP BY key ORDER BY key ASC LIMIT 10; +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | explain | +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Limit: 10 Projection: (number % 3) as key:UInt8, SUM(number) as value:UInt64 Sort: (number % 3):UInt8, AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[SUM(number)]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[SUM(number)]] Expression: (number % 3):UInt8, number:UInt64 (Before GroupBy) Filter: ((number > 10) AND (number < 990)) ReadDataSource: scan partitions: [8], scan schema: [number:UInt64], statistics: [read_rows: 1000, read_bytes: 8000] | +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Optimizer and Plan \u00b6 For a query, especially a complex query, you can used different plan combinations, orders and structures to get the data . Each of the different ways will get different processing time. So we need to find a reasonable plan combination way in the shortest time, which is what the optimizer does. Interpreter and Processor \u00b6 The interpreter constructs the optimized plan into an executable data stream. We pull the result of SQL by pulling the data in the stream. The calculation logic of each operator in SQL corresponds to a processor, such as FilterPlan -> FilterProcessor, ProjectionPlan -> ProjectionProcessor Distributed query \u00b6 In the cluster mode, we may have to process with some problems different from the standalone mode. In distributed mode, the tables to be queried are always distributed in different nodes For some scenarios, distributed processing is always efficient, such as GROUP BY with keys, JOIN For some scenarios, we have no way of distributed processing, such as LIMIT, GROUP BY without keys In order to ensure fast calculation, we need to coordinate the location of calculation and data. Let's see how normal queries run on a database cluster. ' +------+ +------------+ +------------------+ ' | | AST | | Plan | Optimizer | ' SQL--->|Parser+------>|Plan Builder+----->| | ' | | | | | ScatterOptimizer | ' +------+ +------------+ +--------+---------+ ' | ' +--------------+ | ' | | | ' +--+ FlightStream | <------+ | Plan ' | | | | | ' | +--------------+ | | ' | | | ' | | | ' | | Flight RPC v ' +----------+ Processor | +--------------+ | +----------------+ ' | | RemoteProcessor | | | | do_action | Interpreter | ' Data<--+DataStream|<----------------+--+ FlightStream | <------+------------------+ | ' | | | | | | | PlanRescheduler| ' +----------+ | +--------------+ | +----------------+ ' | | ' | | ' | | ' | | ' | +--------------+ | ' | | | | ' +--+ FlightStream | <------+ ' | | ' +--------------+ ScatterOptimizer and StagePlan \u00b6 In Databend, we use ScatterOptimizer to decide the distributed computing of query. In other words, distributed query is an optimization of standalone query. In ScatterOptimizer, we traverse all the plans of the query and rewrite the plan of interest(rewrite as StagePlan { kind:StageKind, input:Self }), where input is the rewritten plan, and kind is an enumeration(Normal: data is shuffled again, Expansive: data spreads from one node to multiple nodes, Convergent: data aggregation from multiple nodes to one node) PlanScheduler and RemoteProcessor \u00b6 In cluster mode, we extract all the StagePlans in the plan optimized by ScatterOptimizer and send them to the corresponding nodes in the cluster according to the kind. For example: mysql> EXPLAIN SELECT argMin(user, salary) FROM (SELECT sum(number) AS salary, number%3 AS user FROM numbers_local(1000000000) GROUP BY user); +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | explain | +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Projection: argMin(user, salary):UInt64 <-- execute in local node AggregatorFinal: groupBy=[[]], aggr=[[argMin(user, salary)]] RedistributeStage[expr: 0] <-- execute in all nodes of the cluster AggregatorPartial: groupBy=[[]], aggr=[[argMin(user, salary)]] Projection: sum(number) as salary:UInt64, (number % 3) as user:UInt8 AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum(number)]] RedistributeStage[expr: sipHash(_group_by_key)] <-- execute in all nodes of the cluster AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum(number)]] Expression: (number % 3):UInt8, number:UInt64 (Before GroupBy) RedistributeStage[expr: blockNumber()] <-- execute in local node ReadDataSource: scan partitions: [8], scan schema: [number:UInt64], statistics: [read_rows: 1000000000, read_bytes: 8000000000] | +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ Flight API DataStream \u00b6 We need to fetch the results of the plans sent to other nodes for execution in some way. FuseData uses the third-party library arrow-flight. more information:[ https://github.com/apache/arrow-rs/tree/master/arrow-flight ]","title":"DatabendQuery Shuffle"},{"location":"rfcs/query/0003-data-shuffle/#distributed-query-and-data-shuffle","text":"","title":"Distributed query and data shuffle"},{"location":"rfcs/query/0003-data-shuffle/#summary","text":"Distributed query is distributed database necessary feature. This doc is intended to explain the distributed query and its data flow design.","title":"Summary"},{"location":"rfcs/query/0003-data-shuffle/#local-query","text":"Let's see how normal queries run on a single database node. ' +------+ +------------+ +---------+ ' | | AST | | Plan | | ' SQL--->|Parser+------>|Plan Builder+----->|Optimizer| ' | | | | | | ' +------+ +------------+ +---+-----+ ' | Plan ' v ' +----------+ +-----------+ ' | | Processor | | ' Data <------+DataStream|<-----------+Interpreter| ' | | | | ' +----------+ +-----------+","title":"Local query"},{"location":"rfcs/query/0003-data-shuffle/#parser-and-ast","text":"Databend uses the third-party SQL parser and its AST. For more information, see: https://github.com/ballista-compute/sqlparser-rs","title":"Parser and AST"},{"location":"rfcs/query/0003-data-shuffle/#planbuilder-and-plan","text":"A query plan (or query execution plan) is a sequence of steps used to access data in Databend. It is built by PlanBuilder from AST. We also use tree to describe it(similar to AST). But it has some differences with AST: Plan is serializable and deserializable. Plan is grammatically safe, we don't worry about it. Plan is used to describe the computation and data dependency, not related to syntax priority We can show it with EXPLAIN SELECT ... mysql> EXPLAIN SELECT number % 3 AS key, SUM(number) AS value FROM numbers(1000) WHERE number > 10 AND number < 990 GROUP BY key ORDER BY key ASC LIMIT 10; +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | explain | +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Limit: 10 Projection: (number % 3) as key:UInt8, SUM(number) as value:UInt64 Sort: (number % 3):UInt8, AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[SUM(number)]] AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[SUM(number)]] Expression: (number % 3):UInt8, number:UInt64 (Before GroupBy) Filter: ((number > 10) AND (number < 990)) ReadDataSource: scan partitions: [8], scan schema: [number:UInt64], statistics: [read_rows: 1000, read_bytes: 8000] | +----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+","title":"PlanBuilder and Plan"},{"location":"rfcs/query/0003-data-shuffle/#optimizer-and-plan","text":"For a query, especially a complex query, you can used different plan combinations, orders and structures to get the data . Each of the different ways will get different processing time. So we need to find a reasonable plan combination way in the shortest time, which is what the optimizer does.","title":"Optimizer and Plan"},{"location":"rfcs/query/0003-data-shuffle/#interpreter-and-processor","text":"The interpreter constructs the optimized plan into an executable data stream. We pull the result of SQL by pulling the data in the stream. The calculation logic of each operator in SQL corresponds to a processor, such as FilterPlan -> FilterProcessor, ProjectionPlan -> ProjectionProcessor","title":"Interpreter and Processor"},{"location":"rfcs/query/0003-data-shuffle/#distributed-query","text":"In the cluster mode, we may have to process with some problems different from the standalone mode. In distributed mode, the tables to be queried are always distributed in different nodes For some scenarios, distributed processing is always efficient, such as GROUP BY with keys, JOIN For some scenarios, we have no way of distributed processing, such as LIMIT, GROUP BY without keys In order to ensure fast calculation, we need to coordinate the location of calculation and data. Let's see how normal queries run on a database cluster. ' +------+ +------------+ +------------------+ ' | | AST | | Plan | Optimizer | ' SQL--->|Parser+------>|Plan Builder+----->| | ' | | | | | ScatterOptimizer | ' +------+ +------------+ +--------+---------+ ' | ' +--------------+ | ' | | | ' +--+ FlightStream | <------+ | Plan ' | | | | | ' | +--------------+ | | ' | | | ' | | | ' | | Flight RPC v ' +----------+ Processor | +--------------+ | +----------------+ ' | | RemoteProcessor | | | | do_action | Interpreter | ' Data<--+DataStream|<----------------+--+ FlightStream | <------+------------------+ | ' | | | | | | | PlanRescheduler| ' +----------+ | +--------------+ | +----------------+ ' | | ' | | ' | | ' | | ' | +--------------+ | ' | | | | ' +--+ FlightStream | <------+ ' | | ' +--------------+","title":"Distributed query"},{"location":"rfcs/query/0003-data-shuffle/#scatteroptimizer-and-stageplan","text":"In Databend, we use ScatterOptimizer to decide the distributed computing of query. In other words, distributed query is an optimization of standalone query. In ScatterOptimizer, we traverse all the plans of the query and rewrite the plan of interest(rewrite as StagePlan { kind:StageKind, input:Self }), where input is the rewritten plan, and kind is an enumeration(Normal: data is shuffled again, Expansive: data spreads from one node to multiple nodes, Convergent: data aggregation from multiple nodes to one node)","title":"ScatterOptimizer and StagePlan"},{"location":"rfcs/query/0003-data-shuffle/#planscheduler-and-remoteprocessor","text":"In cluster mode, we extract all the StagePlans in the plan optimized by ScatterOptimizer and send them to the corresponding nodes in the cluster according to the kind. For example: mysql> EXPLAIN SELECT argMin(user, salary) FROM (SELECT sum(number) AS salary, number%3 AS user FROM numbers_local(1000000000) GROUP BY user); +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | explain | +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Projection: argMin(user, salary):UInt64 <-- execute in local node AggregatorFinal: groupBy=[[]], aggr=[[argMin(user, salary)]] RedistributeStage[expr: 0] <-- execute in all nodes of the cluster AggregatorPartial: groupBy=[[]], aggr=[[argMin(user, salary)]] Projection: sum(number) as salary:UInt64, (number % 3) as user:UInt8 AggregatorFinal: groupBy=[[(number % 3)]], aggr=[[sum(number)]] RedistributeStage[expr: sipHash(_group_by_key)] <-- execute in all nodes of the cluster AggregatorPartial: groupBy=[[(number % 3)]], aggr=[[sum(number)]] Expression: (number % 3):UInt8, number:UInt64 (Before GroupBy) RedistributeStage[expr: blockNumber()] <-- execute in local node ReadDataSource: scan partitions: [8], scan schema: [number:UInt64], statistics: [read_rows: 1000000000, read_bytes: 8000000000] | +-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+","title":"PlanScheduler and RemoteProcessor"},{"location":"rfcs/query/0003-data-shuffle/#flight-api-datastream","text":"We need to fetch the results of the plans sent to other nodes for execution in some way. FuseData uses the third-party library arrow-flight. more information:[ https://github.com/apache/arrow-rs/tree/master/arrow-flight ]","title":"Flight API DataStream"},{"location":"rfcs/query/0004-performance-test/","text":"Design of test infra for performance test \u00b6 Currently, we have already supports to run performance tests locally in tests/perfs directory, and here we need to support performance testing in CI Decoupling compute and storage allow databend to integrate into kubernetes easily. With the support of kubernetes platform, databend benchmarking could achieve the following advantages: 1. Stable benchmarking results, with containerization and cgroup, easy testing instance could have idempotence computing resource 2. Elastic, can expand or shrink tests on demand and also supports to run test locally(minikube + DinD) or on the cloud 3. For following tests, we need to test on TPC benchmark and integrate databend-dfs storage layer to test infrastructure, thus far kubernetes can help instance scaling easily Goals \u00b6 Fast CI speed is desired, By design one performance testing should not exceed two hours(including docker build time and performance testing running time) Expandable: supports to deploy performance tests on scale, and also supports to deploy on a single machine for affordable CI Cloud Native environment supports: Should be able to deploy whole platform on different cloud providers like GKE, EKS High Availability: both webhook and runner should support to self-healing and do not have single point failure Observability: whole process should be observable, should collect logs for performance running instances and collect compare report results Non Goals \u00b6 Hybrid Cloud not supported for alpha version Networking optimization for github action part(typically CI fail is caused by networking problem Dashboard(Currently, prototype implemented, but priority here is low) Performance Test API \u00b6 Support three semantics /run-perf <branch-name> Compare performance difference between current pull requests\u2019 latest SHA build and given branch name Branch-name supports: 1. Main branch: main (some repo is main) 2. Release tag branch: i,e v1.1.1-nightly 3. Latest tag: fetch the latest tag in the github repo /rerun-perf <branch-name> Similar to run-perf part, the ONLY difference is that it would bypass docker build part and assume performance docker build images are ready for test Examples: /run-perf main It will compare performance between current PR\u2019s latest commit and main branch /run-perf v1.1.1-nightly It will compare performance between current PR\u2019s latest commit and release tag v1.1.1-nightly /run-perf latest It will compare performance between current PR\u2019s latest commit and the latest release tag /rerun-perf main Do the same thing as /run-perf main did, but will skip docker image building steps For more information please checkout test-infra","title":"Performance Test"},{"location":"rfcs/query/0004-performance-test/#design-of-test-infra-for-performance-test","text":"Currently, we have already supports to run performance tests locally in tests/perfs directory, and here we need to support performance testing in CI Decoupling compute and storage allow databend to integrate into kubernetes easily. With the support of kubernetes platform, databend benchmarking could achieve the following advantages: 1. Stable benchmarking results, with containerization and cgroup, easy testing instance could have idempotence computing resource 2. Elastic, can expand or shrink tests on demand and also supports to run test locally(minikube + DinD) or on the cloud 3. For following tests, we need to test on TPC benchmark and integrate databend-dfs storage layer to test infrastructure, thus far kubernetes can help instance scaling easily","title":"Design of test infra for performance test"},{"location":"rfcs/query/0004-performance-test/#goals","text":"Fast CI speed is desired, By design one performance testing should not exceed two hours(including docker build time and performance testing running time) Expandable: supports to deploy performance tests on scale, and also supports to deploy on a single machine for affordable CI Cloud Native environment supports: Should be able to deploy whole platform on different cloud providers like GKE, EKS High Availability: both webhook and runner should support to self-healing and do not have single point failure Observability: whole process should be observable, should collect logs for performance running instances and collect compare report results","title":"Goals"},{"location":"rfcs/query/0004-performance-test/#non-goals","text":"Hybrid Cloud not supported for alpha version Networking optimization for github action part(typically CI fail is caused by networking problem Dashboard(Currently, prototype implemented, but priority here is low)","title":"Non Goals"},{"location":"rfcs/query/0004-performance-test/#performance-test-api","text":"Support three semantics /run-perf <branch-name> Compare performance difference between current pull requests\u2019 latest SHA build and given branch name Branch-name supports: 1. Main branch: main (some repo is main) 2. Release tag branch: i,e v1.1.1-nightly 3. Latest tag: fetch the latest tag in the github repo /rerun-perf <branch-name> Similar to run-perf part, the ONLY difference is that it would bypass docker build part and assume performance docker build images are ready for test Examples: /run-perf main It will compare performance between current PR\u2019s latest commit and main branch /run-perf v1.1.1-nightly It will compare performance between current PR\u2019s latest commit and release tag v1.1.1-nightly /run-perf latest It will compare performance between current PR\u2019s latest commit and the latest release tag /rerun-perf main Do the same thing as /run-perf main did, but will skip docker image building steps For more information please checkout test-infra","title":"Performance Test API"},{"location":"rfcs/query/0005-new-sql-planner-framework/","text":"Start date: 2021/09/13 Tracking issues: https://github.com/datafuselabs/databend/issues/1217 Sumamry \u00b6 In order to support more complicated SQL queries, for example the queries contain JOIN and correlated subquery, we need to redesign the SQL planner component. The main problems of current implementation we are going to discussed in this RFC are as follows: Doesn't support JOIN and correlated subquery Doesn't have ability to do strict semantic checking, e.g. type check and name resolution, which brings unnecessary complexity of correctness ensurance during SQL optimization and execution Doesn't have a universal SQL optimization framework Let's start with a simple example. In SQL, it allows duplicated names of fields in a tuple. In PostgreSQL, a result set can contain different columns with same name: postgres=# create table t(a int); CREATE TABLE postgres=# insert into t values(1),(2); INSERT 0 2 postgres=# select * from t t1 cross join t t2; a | a ---+--- 1 | 1 1 | 2 2 | 1 2 | 2 (4 rows) We can see that there are two fields named with a , one of them comes from derived table t1 and the other one comes from derived table t2 . If you try to reference the column with duplicated name a , it will return an error: postgres=# select a from t t1, t t2; ERROR: column reference \"a\" is ambiguous LINE 1: select a from t t1, t t2; While you can reference the column with a canonical name like t.a since the table name is required to be unique in a query context. Currently, databend uses DataSchema to represent input and output relation schema, which can not provide enough information to handle the case shown above. In a DataSchema , each column is represented with DataField , which has following definition: pub struct DataField { name : String , data_type : DataType , nullable : bool , } Each DataField inside a DataSchema is identified with a unique name string. For now, the name just represent column name, thus it's difficult to implement JOIN with this abstraction. We will talk about the detailed solution of this in later sections. The second problem is about semantic check. Take type check as an example, each variable(e.g. column reference, constant value) inside an expression has it's own data type. And each scalar expresiion has requirement of data type for its arguments, for instance, a + expression requires its arguments to be numeric. To make sure that the query is valid and correct, we need to do type checking before executing the query. Since both optimizer and executor has requirement on type checking, it's better to resolve this with a single component, which can make it more maintainable. The last problem is about the query optimization framework. Many of modern optimizers are implemented in Volcano/Cascades style, which is a highly modular approach. A typical Cascades optimizer consists of independent modules: Transformation rules Implementation rules Exploration engine Cost model What's insteresting is that, the rule system(transformation and implementation) is decoupled with exploration engine and cost model, which means it's easy to build a heuristic optimizer without CBO(cost based optimization). And as soon as we're going to implement CBO, the rule system can be reused. Actually, this is the practical way. In some industrial Cascades implementation(e.g. SQL Server and CockroachDB), there is always a heuristic optimization phase, for example pre-exploration in SQL Server and normalization in CockroachDB, which generally shares a same rule system with exploration engine. In summary, this RFC will: Introduce a new framework to support planning JOIN and correlated subquery Introduce a rule system that allows developer to write transformation rules easily Design Details \u00b6 Architecture \u00b6 In current implementation, a SQL query will be processed as follows: PlanParser will parse the SQL text into AST(Abstrct Syntax Tree) PlanParser will also build a canonical plan tree represented with PlanNode from the AST After building plan tree, Optimizer will do some canonical optimization to the plan, and produce the final PlanNode Intepreter will take the PlanNode as input and interpret it as an executable Pipeline consists of Processor s Executor will execute the Pipeline with specific runtime In our new framework, PlanParser will be refactored into two components: Parser : parsing SQL text into uniform AST representation, which has been introduced in this PR Binder : bind variables appeared in the AST with objects(e.g. tables, columns, etc) in database and perform semantic check(name resolution, type checking). Will produce logical representation of plan tree Besides, a rule system will be introduced and replace current optimizer. Binder \u00b6 Since there maybe many syntactic contexts in a SQL query, we need a way to track the dependency relationship between them and the visibility of name s in different contexts. Here we propose the abstraction Metadata , which stores all the metadata we need for query optimization, including base tables from catalog, derived tables(subquery and join) and columns. Each table and column will be assigned with a unique identifier. pub struct Metadata { pub tables : Vec < TableEntry > , } pub struct TableEntry { pub index : IndexType , // Index of the table in `Metadata` pub columns : Vec < ColumnEntry > , // And metadata about the table, e.g. name, database name and etc. } pub struct ColumnEntry { pub index : ColumnIndex , // And metadata about the column, e.g. name, data type and etc. } pub type IndexType = usize ; pub struct ColumnIndex { pub table_index : IndexType , // Index of the table this column belongs to pub column_index : IndexType , // Index of the column inside its `TableEntry` } Therefore, after name resolution each variable will be bound with a unique ColumnIndex but not a string, so we don't need to worry about the issues like duplicated name. During the binding procedure, we need to track the state of binding. The state may contain the following information: Visible columns in current context, used when processing wildcard result set( SELECT * FROM t ) If a column in a context is group by key or not If a column is derived column(i.e. projection like a+1 AS a ) or not If a variable is from current subquery or not, to identify correlated column reference To maintain the state, we propose a data structure BindContext (this name is inspired by BinderContext from CMU Peloton, which is a very appropriate name in my mind). BindContext is a stack-like structure, each BindContext node in the stack records state of corresponding syntactic context. SQL binding is a bottom-up procedure, which means it will process AST recursively, add columns produced by data source(e.g. table scan, join, subquery) into Briefly, BindContext is a set of column references. To be clear, we will use diagram to explain hwo this mechanism works. Take this example: create table t ( a int ); select * from t -- table: context 1 [t.a] cross join t t1 -- table: context 2 [t1.a] -- join: context 3 [t.a, t1.a] where t . a = 1 According to semantic of SQL, we can describe the binding procedure as follows: Create an empty BindContext context 1 for table t , and fill it with columns from t Create an empty BindContext context 2 for table t , fill it with columns from t , and rename the table to t1 Create an empty BindContext context 3 for t cross join t1 , and fill it with columns from t and t1 Perform name resolution for predicate t.a = 1 Lookup context 3, and find the corresponding ColumnEntry for variable t.a Let's take a look at how BindContext handles correlated subquery. A correlated subquery indicates that the subquery depends on a column from outer context. There is a canonical Apply operator to execute correlated subquery, which will evaluate the subquery expression for each tuple(like a cross join). While most of the correlated subqueries can be decorrelated into join(e.g. semi-join, anti-semi-join and etc.). Take this query as example: create table t ( a int ); select * from t -- table: context 1 [t.a] where exists ( select * from t t1 -- table: context 2 with parent 1 [t1.a] where t1 . a = t . a -- t.a is a correlated column since it comes from t that appears in outer query ); Before binding the exists subquery, we will create a new BindContext for it, and pass the outer BindContext as its parent context. When we bind the correlated column reference t.a inside the subquery, we will first lookup current BindContext to see if it exists an appropriate column, if not, then we will keep trying to do the lookup in parent context until we find the corresponding column or we exhaust all the parents. If we find the column in parent context, then we can confirm that this subquery is a correlated subquery, and the column reference bound with parent context is the correlated column. The procedure can be summarized as follows: Create an empty BindContext context 1 for table t , and fill it with columns from t Create an empty BindContext context 2 for table t with context 1 as its parent cotext, fill it with columns from t , and rename the table to t1 Perform name resolution for predicate t1.a = t.a Lookup context 2, and find the corresponding ColumnEntry for variable t1.a , but can not find t.a . So we will keep going through step 5 Lookup parent of context 2(context 1), and find the corresponding ColumnEntry for variable t.a . Since the variable is found in outer context, it will be marked as correlated column reference, and the subquery will be marked as correlated Optimizer & Rule system \u00b6 SQL optimization is based on the equivalence of relational algebra. There are a bunch of different thereoms and lemmas can help us identify if two relational algebra trees are logically equivalent. In Cascades/Volcano style query optimizer, transformation rules are used to perform the algebra transformation on a plan tree. Each transformation rule has description about the relational operator it can be applied to, which we call it a rule pattern . The optimizer will provide a scheme to walk through the plan tree, check if any rule can be applied to the plan tree, and then apply transformation for the matched rules. The rule pattern is also a tree structure, which will look like: pub trait RulePattern { fn get_children_pattern ( & self ) -> Vec < Box < dyn RulePattern >> ; fn match ( & self , plan : & PlanNode ) -> bool ; } The transformation rule should implement the following trait: pub trait TransformationRule { fn get_rule_pattern ( & self ) -> & dyn RulePattern ; fn apply ( & self , plan : & PlanNode ) -> Result < PlanNode > ; } With these rule abstraction, we can write transformation rules easily. For example, we want to implement ConstantFolding transformation, the scheme can be described as: Find all operators with scalar expressions Fold the constant values found in scalar expressions Replace original operators with rewritten operators The pseudo code: pub struct ConstantFoldingPattern ; impl RulePattern for ConstantFoldingPattern { fn get_children_pattern ( & self ) -> Vec < Box < dyn RulePattern >> { vec! [] } fn match ( & self , plan : & PlanNode ) -> bool { ! plan . expr . empty () } } pub struct ConstantFoldingRule { pattern : ConstantFoldingPattern , } impl TransformationRule for ConstantFoldingRule { fn get_rule_pattern ( & self ) -> & dyn RulePattern { & self . pattern } fn apply ( & self , plan : & PlanNode ) -> Result < PlanNode > { let new_expr = plan . get_expr (). constant_folding () ? ; let mut new_plan = plan . clone (); new_plan . set_expr ( new_expr ); Ok ( new_plan ) } } pub struct Optimizer { rules : Vec < Box < dyn TransformationRule >> } impl ReplaceVisitor for Optimizer { fn visit ( & mut self , plan : & PlanNode ) -> Result < PlanNode > { let mut new_plan = plan . clone (); for rule in self . rules . iter () { if rule . get_rule_pattern (). match ( plan ) { new_plan = rule . apply ( & new_plan ) ? ; } } Ok ( new_plan ) } } pub fn optimize ( plan : & PlanNode ) -> Result < PlanNode > { let opt = Optimizer { rules : vec ! [ ConstantFoldingRule :: new ()], }; opt . visit ( plan ) } Milestone \u00b6 After this refactoring, we want: Provide naive implementation(hash join for equi-join and nested-loop join for cross join) for JOIN , including planning and execution Support running most of the queries from TPCH benchmark(contains different types of joins and correlated subquery) with databend Implement several simple optimization rules, e.g. outer join elimination, decorrelation, predicate pushdown and etc. Migrate to the new planner framework And at the same time, we won't: Take performance serious, related work should be done in next stage Implement cost based optimization, this work depends on design of statistics system","title":"SQL Planner Framework"},{"location":"rfcs/query/0005-new-sql-planner-framework/#sumamry","text":"In order to support more complicated SQL queries, for example the queries contain JOIN and correlated subquery, we need to redesign the SQL planner component. The main problems of current implementation we are going to discussed in this RFC are as follows: Doesn't support JOIN and correlated subquery Doesn't have ability to do strict semantic checking, e.g. type check and name resolution, which brings unnecessary complexity of correctness ensurance during SQL optimization and execution Doesn't have a universal SQL optimization framework Let's start with a simple example. In SQL, it allows duplicated names of fields in a tuple. In PostgreSQL, a result set can contain different columns with same name: postgres=# create table t(a int); CREATE TABLE postgres=# insert into t values(1),(2); INSERT 0 2 postgres=# select * from t t1 cross join t t2; a | a ---+--- 1 | 1 1 | 2 2 | 1 2 | 2 (4 rows) We can see that there are two fields named with a , one of them comes from derived table t1 and the other one comes from derived table t2 . If you try to reference the column with duplicated name a , it will return an error: postgres=# select a from t t1, t t2; ERROR: column reference \"a\" is ambiguous LINE 1: select a from t t1, t t2; While you can reference the column with a canonical name like t.a since the table name is required to be unique in a query context. Currently, databend uses DataSchema to represent input and output relation schema, which can not provide enough information to handle the case shown above. In a DataSchema , each column is represented with DataField , which has following definition: pub struct DataField { name : String , data_type : DataType , nullable : bool , } Each DataField inside a DataSchema is identified with a unique name string. For now, the name just represent column name, thus it's difficult to implement JOIN with this abstraction. We will talk about the detailed solution of this in later sections. The second problem is about semantic check. Take type check as an example, each variable(e.g. column reference, constant value) inside an expression has it's own data type. And each scalar expresiion has requirement of data type for its arguments, for instance, a + expression requires its arguments to be numeric. To make sure that the query is valid and correct, we need to do type checking before executing the query. Since both optimizer and executor has requirement on type checking, it's better to resolve this with a single component, which can make it more maintainable. The last problem is about the query optimization framework. Many of modern optimizers are implemented in Volcano/Cascades style, which is a highly modular approach. A typical Cascades optimizer consists of independent modules: Transformation rules Implementation rules Exploration engine Cost model What's insteresting is that, the rule system(transformation and implementation) is decoupled with exploration engine and cost model, which means it's easy to build a heuristic optimizer without CBO(cost based optimization). And as soon as we're going to implement CBO, the rule system can be reused. Actually, this is the practical way. In some industrial Cascades implementation(e.g. SQL Server and CockroachDB), there is always a heuristic optimization phase, for example pre-exploration in SQL Server and normalization in CockroachDB, which generally shares a same rule system with exploration engine. In summary, this RFC will: Introduce a new framework to support planning JOIN and correlated subquery Introduce a rule system that allows developer to write transformation rules easily","title":"Sumamry"},{"location":"rfcs/query/0005-new-sql-planner-framework/#design-details","text":"","title":"Design Details"},{"location":"rfcs/query/0005-new-sql-planner-framework/#architecture","text":"In current implementation, a SQL query will be processed as follows: PlanParser will parse the SQL text into AST(Abstrct Syntax Tree) PlanParser will also build a canonical plan tree represented with PlanNode from the AST After building plan tree, Optimizer will do some canonical optimization to the plan, and produce the final PlanNode Intepreter will take the PlanNode as input and interpret it as an executable Pipeline consists of Processor s Executor will execute the Pipeline with specific runtime In our new framework, PlanParser will be refactored into two components: Parser : parsing SQL text into uniform AST representation, which has been introduced in this PR Binder : bind variables appeared in the AST with objects(e.g. tables, columns, etc) in database and perform semantic check(name resolution, type checking). Will produce logical representation of plan tree Besides, a rule system will be introduced and replace current optimizer.","title":"Architecture"},{"location":"rfcs/query/0005-new-sql-planner-framework/#binder","text":"Since there maybe many syntactic contexts in a SQL query, we need a way to track the dependency relationship between them and the visibility of name s in different contexts. Here we propose the abstraction Metadata , which stores all the metadata we need for query optimization, including base tables from catalog, derived tables(subquery and join) and columns. Each table and column will be assigned with a unique identifier. pub struct Metadata { pub tables : Vec < TableEntry > , } pub struct TableEntry { pub index : IndexType , // Index of the table in `Metadata` pub columns : Vec < ColumnEntry > , // And metadata about the table, e.g. name, database name and etc. } pub struct ColumnEntry { pub index : ColumnIndex , // And metadata about the column, e.g. name, data type and etc. } pub type IndexType = usize ; pub struct ColumnIndex { pub table_index : IndexType , // Index of the table this column belongs to pub column_index : IndexType , // Index of the column inside its `TableEntry` } Therefore, after name resolution each variable will be bound with a unique ColumnIndex but not a string, so we don't need to worry about the issues like duplicated name. During the binding procedure, we need to track the state of binding. The state may contain the following information: Visible columns in current context, used when processing wildcard result set( SELECT * FROM t ) If a column in a context is group by key or not If a column is derived column(i.e. projection like a+1 AS a ) or not If a variable is from current subquery or not, to identify correlated column reference To maintain the state, we propose a data structure BindContext (this name is inspired by BinderContext from CMU Peloton, which is a very appropriate name in my mind). BindContext is a stack-like structure, each BindContext node in the stack records state of corresponding syntactic context. SQL binding is a bottom-up procedure, which means it will process AST recursively, add columns produced by data source(e.g. table scan, join, subquery) into Briefly, BindContext is a set of column references. To be clear, we will use diagram to explain hwo this mechanism works. Take this example: create table t ( a int ); select * from t -- table: context 1 [t.a] cross join t t1 -- table: context 2 [t1.a] -- join: context 3 [t.a, t1.a] where t . a = 1 According to semantic of SQL, we can describe the binding procedure as follows: Create an empty BindContext context 1 for table t , and fill it with columns from t Create an empty BindContext context 2 for table t , fill it with columns from t , and rename the table to t1 Create an empty BindContext context 3 for t cross join t1 , and fill it with columns from t and t1 Perform name resolution for predicate t.a = 1 Lookup context 3, and find the corresponding ColumnEntry for variable t.a Let's take a look at how BindContext handles correlated subquery. A correlated subquery indicates that the subquery depends on a column from outer context. There is a canonical Apply operator to execute correlated subquery, which will evaluate the subquery expression for each tuple(like a cross join). While most of the correlated subqueries can be decorrelated into join(e.g. semi-join, anti-semi-join and etc.). Take this query as example: create table t ( a int ); select * from t -- table: context 1 [t.a] where exists ( select * from t t1 -- table: context 2 with parent 1 [t1.a] where t1 . a = t . a -- t.a is a correlated column since it comes from t that appears in outer query ); Before binding the exists subquery, we will create a new BindContext for it, and pass the outer BindContext as its parent context. When we bind the correlated column reference t.a inside the subquery, we will first lookup current BindContext to see if it exists an appropriate column, if not, then we will keep trying to do the lookup in parent context until we find the corresponding column or we exhaust all the parents. If we find the column in parent context, then we can confirm that this subquery is a correlated subquery, and the column reference bound with parent context is the correlated column. The procedure can be summarized as follows: Create an empty BindContext context 1 for table t , and fill it with columns from t Create an empty BindContext context 2 for table t with context 1 as its parent cotext, fill it with columns from t , and rename the table to t1 Perform name resolution for predicate t1.a = t.a Lookup context 2, and find the corresponding ColumnEntry for variable t1.a , but can not find t.a . So we will keep going through step 5 Lookup parent of context 2(context 1), and find the corresponding ColumnEntry for variable t.a . Since the variable is found in outer context, it will be marked as correlated column reference, and the subquery will be marked as correlated","title":"Binder"},{"location":"rfcs/query/0005-new-sql-planner-framework/#optimizer-rule-system","text":"SQL optimization is based on the equivalence of relational algebra. There are a bunch of different thereoms and lemmas can help us identify if two relational algebra trees are logically equivalent. In Cascades/Volcano style query optimizer, transformation rules are used to perform the algebra transformation on a plan tree. Each transformation rule has description about the relational operator it can be applied to, which we call it a rule pattern . The optimizer will provide a scheme to walk through the plan tree, check if any rule can be applied to the plan tree, and then apply transformation for the matched rules. The rule pattern is also a tree structure, which will look like: pub trait RulePattern { fn get_children_pattern ( & self ) -> Vec < Box < dyn RulePattern >> ; fn match ( & self , plan : & PlanNode ) -> bool ; } The transformation rule should implement the following trait: pub trait TransformationRule { fn get_rule_pattern ( & self ) -> & dyn RulePattern ; fn apply ( & self , plan : & PlanNode ) -> Result < PlanNode > ; } With these rule abstraction, we can write transformation rules easily. For example, we want to implement ConstantFolding transformation, the scheme can be described as: Find all operators with scalar expressions Fold the constant values found in scalar expressions Replace original operators with rewritten operators The pseudo code: pub struct ConstantFoldingPattern ; impl RulePattern for ConstantFoldingPattern { fn get_children_pattern ( & self ) -> Vec < Box < dyn RulePattern >> { vec! [] } fn match ( & self , plan : & PlanNode ) -> bool { ! plan . expr . empty () } } pub struct ConstantFoldingRule { pattern : ConstantFoldingPattern , } impl TransformationRule for ConstantFoldingRule { fn get_rule_pattern ( & self ) -> & dyn RulePattern { & self . pattern } fn apply ( & self , plan : & PlanNode ) -> Result < PlanNode > { let new_expr = plan . get_expr (). constant_folding () ? ; let mut new_plan = plan . clone (); new_plan . set_expr ( new_expr ); Ok ( new_plan ) } } pub struct Optimizer { rules : Vec < Box < dyn TransformationRule >> } impl ReplaceVisitor for Optimizer { fn visit ( & mut self , plan : & PlanNode ) -> Result < PlanNode > { let mut new_plan = plan . clone (); for rule in self . rules . iter () { if rule . get_rule_pattern (). match ( plan ) { new_plan = rule . apply ( & new_plan ) ? ; } } Ok ( new_plan ) } } pub fn optimize ( plan : & PlanNode ) -> Result < PlanNode > { let opt = Optimizer { rules : vec ! [ ConstantFoldingRule :: new ()], }; opt . visit ( plan ) }","title":"Optimizer &amp; Rule system"},{"location":"rfcs/query/0005-new-sql-planner-framework/#milestone","text":"After this refactoring, we want: Provide naive implementation(hash join for equi-join and nested-loop join for cross join) for JOIN , including planning and execution Support running most of the queries from TPCH benchmark(contains different types of joins and correlated subquery) with databend Implement several simple optimization rules, e.g. outer join elimination, decorrelation, predicate pushdown and etc. Migrate to the new planner framework And at the same time, we won't: Take performance serious, related work should be done in next stage Implement cost based optimization, this work depends on design of statistics system","title":"Milestone"},{"location":"sqlstatement/aggregate-functions/aggregate-argmax/","text":"Calculates the arg value for a maximum val value. If there are several different values of arg for maximum values of val , returns the first of these values encountered. Syntax \u00b6 argMax(arg, val) Arguments \u00b6 Arguments Description arg Argument val Value Return Type \u00b6 arg value that corresponds to maximum val value. matches arg type. Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. Input table: SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user ORDER BY salary ASC; +----------+------+ | salary | user | +----------+------+ | 16661667 | 1 | | 16665000 | 2 | | 16668333 | 0 | +----------+------+ mysql> SELECT argMax(user, salary) FROM (SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user); +----------------------+ | argMax(user, salary) | +----------------------+ | 0 | +----------------------+","title":"argMax"},{"location":"sqlstatement/aggregate-functions/aggregate-argmax/#syntax","text":"argMax(arg, val)","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-argmax/#arguments","text":"Arguments Description arg Argument val Value","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-argmax/#return-type","text":"arg value that corresponds to maximum val value. matches arg type.","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-argmax/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. Input table: SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user ORDER BY salary ASC; +----------+------+ | salary | user | +----------+------+ | 16661667 | 1 | | 16665000 | 2 | | 16668333 | 0 | +----------+------+ mysql> SELECT argMax(user, salary) FROM (SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user); +----------------------+ | argMax(user, salary) | +----------------------+ | 0 | +----------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-argmin/","text":"Calculates the arg value for a minimum val value. If there are several different values of arg for minimum values of val , returns the first of these values encountered. Syntax \u00b6 argMin(arg, val) Arguments \u00b6 Arguments Description arg Argument val Value Return Type \u00b6 arg value that corresponds to minimum val value. matches arg type. Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. Input table: SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user ORDER BY salary ASC; +----------+------+ | salary | user | +----------+------+ | 16661667 | 1 | | 16665000 | 2 | | 16668333 | 0 | +----------+------+ mysql> SELECT argMin(user, salary) FROM (SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user); +----------------------+ | argMin(user, salary) | +----------------------+ | 1 | +----------------------+","title":"argMin"},{"location":"sqlstatement/aggregate-functions/aggregate-argmin/#syntax","text":"argMin(arg, val)","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-argmin/#arguments","text":"Arguments Description arg Argument val Value","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-argmin/#return-type","text":"arg value that corresponds to minimum val value. matches arg type.","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-argmin/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. Input table: SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user ORDER BY salary ASC; +----------+------+ | salary | user | +----------+------+ | 16661667 | 1 | | 16665000 | 2 | | 16668333 | 0 | +----------+------+ mysql> SELECT argMin(user, salary) FROM (SELECT sum(number) AS salary, number%3 AS user FROM numbers_mt(10000) GROUP BY user); +----------------------+ | argMin(user, salary) | +----------------------+ | 1 | +----------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-avg-if/","text":"avgIf \u00b6 The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. avgIf(column, cond) Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT avg(number) FROM numbers(10); +-------------+ | avg(number) | +-------------+ | 4.5 | +-------------+ mysql> SELECT avgIf(number, number > 7) FROM numbers(10); +-----------------------------+ | avgIf(number, (number > 7)) | +-----------------------------+ | 8.5 | +-----------------------------+","title":"avgIf"},{"location":"sqlstatement/aggregate-functions/aggregate-avg-if/#avgif","text":"The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. avgIf(column, cond)","title":"avgIf"},{"location":"sqlstatement/aggregate-functions/aggregate-avg-if/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT avg(number) FROM numbers(10); +-------------+ | avg(number) | +-------------+ | 4.5 | +-------------+ mysql> SELECT avgIf(number, number > 7) FROM numbers(10); +-----------------------------+ | avgIf(number, (number > 7)) | +-----------------------------+ | 8.5 | +-----------------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-avg/","text":"Aggregate function. The AVG() function returns the average value of an expression. Note: NULL values are not counted. Syntax \u00b6 AVG ( expression ) Arguments \u00b6 Arguments Description expression Any numerical expression Return Type \u00b6 double Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT AVG(*) FROM numbers(3); +--------+ | avg(*) | +--------+ | 1 | +--------+ mysql> SELECT AVG(number) FROM numbers(3); +-------------+ | avg(number) | +-------------+ | 1 | +-------------+ mysql> SELECT AVG(number+1) FROM numbers(3); +----------------------+ | avg(plus(number, 1)) | +----------------------+ | 2 | +----------------------+ mysql> SELECT AVG(number+1) AS a FROM numbers(3); +------+ | a | +------+ | 2 | +------+","title":"AVG"},{"location":"sqlstatement/aggregate-functions/aggregate-avg/#syntax","text":"AVG ( expression )","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-avg/#arguments","text":"Arguments Description expression Any numerical expression","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-avg/#return-type","text":"double","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-avg/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT AVG(*) FROM numbers(3); +--------+ | avg(*) | +--------+ | 1 | +--------+ mysql> SELECT AVG(number) FROM numbers(3); +-------------+ | avg(number) | +-------------+ | 1 | +-------------+ mysql> SELECT AVG(number+1) FROM numbers(3); +----------------------+ | avg(plus(number, 1)) | +----------------------+ | 2 | +----------------------+ mysql> SELECT AVG(number+1) AS a FROM numbers(3); +------+ | a | +------+ | 2 | +------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-combinator/","text":"Aggregate Function Combinators \u00b6 The name of an aggregate function can have a suffix appended to it. This changes the way the aggregate function works. Distinct \u00b6 Every unique combination of arguments will be aggregated only once. Repeating values are ignored. count(distinct(expression)) sum(distinct(expression)) min(distinct(expression)) max(distinct(expression)) Examples \u00b6 mysql> SELECT sum(distinct(number%3)) FROM numbers_mt(10); +----------------------------+ | sum(distinct (number % 3)) | +----------------------------+ | 3 | +----------------------------+","title":"DISTINCT"},{"location":"sqlstatement/aggregate-functions/aggregate-combinator/#aggregate-function-combinators","text":"The name of an aggregate function can have a suffix appended to it. This changes the way the aggregate function works.","title":"Aggregate Function Combinators"},{"location":"sqlstatement/aggregate-functions/aggregate-combinator/#distinct","text":"Every unique combination of arguments will be aggregated only once. Repeating values are ignored. count(distinct(expression)) sum(distinct(expression)) min(distinct(expression)) max(distinct(expression))","title":"Distinct"},{"location":"sqlstatement/aggregate-functions/aggregate-combinator/#examples","text":"mysql> SELECT sum(distinct(number%3)) FROM numbers_mt(10); +----------------------------+ | sum(distinct (number % 3)) | +----------------------------+ | 3 | +----------------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-count-distinct/","text":"Aggregate function. The count(distinct ...) function calculates the uniq value of a set of values. Note: NULL values are not counted. Syntax \u00b6 COUNT(distinct arguments ...) UNIQ(arguments) Arguments \u00b6 Arguments Description expression Any expression, size of the arguments is [1, 32] Return Type \u00b6 UInt64 Examples \u00b6 mysql> SELECT count(distinct number % 3) FROM numbers(1000); +------------------------------+ | count(distinct (number % 3)) | +------------------------------+ | 3 | +------------------------------+ mysql> SELECT uniq(number % 3, number) FROM numbers(1000); +----------------------------+ | uniq((number % 3), number) | +----------------------------+ | 1000 | +----------------------------+ 1 row in set (0.02 sec) mysql> SELECT uniq(number % 3, number) = count(distinct number %3, number) FROM numbers(1000); +---------------------------------------------------------------------+ | (uniq((number % 3), number) = count(distinct (number % 3), number)) | +---------------------------------------------------------------------+ | true | +---------------------------------------------------------------------+ 1 row in set (0.03 sec","title":"countDistinct"},{"location":"sqlstatement/aggregate-functions/aggregate-count-distinct/#syntax","text":"COUNT(distinct arguments ...) UNIQ(arguments)","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-count-distinct/#arguments","text":"Arguments Description expression Any expression, size of the arguments is [1, 32]","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-count-distinct/#return-type","text":"UInt64","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-count-distinct/#examples","text":"mysql> SELECT count(distinct number % 3) FROM numbers(1000); +------------------------------+ | count(distinct (number % 3)) | +------------------------------+ | 3 | +------------------------------+ mysql> SELECT uniq(number % 3, number) FROM numbers(1000); +----------------------------+ | uniq((number % 3), number) | +----------------------------+ | 1000 | +----------------------------+ 1 row in set (0.02 sec) mysql> SELECT uniq(number % 3, number) = count(distinct number %3, number) FROM numbers(1000); +---------------------------------------------------------------------+ | (uniq((number % 3), number) = count(distinct (number % 3), number)) | +---------------------------------------------------------------------+ | true | +---------------------------------------------------------------------+ 1 row in set (0.03 sec","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-count-if/","text":"countIf \u00b6 The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. countIf(column, cond) Examples \u00b6 Note numbers_mt(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT count(number) FROM numbers(10); +---------------+ | count(number) | +---------------+ | 10 | +---------------+ mysql> SELECT countIf(number, number > 7) FROM numbers(10); +-------------------------------+ | countIf(number, (number > 7)) | +-------------------------------+ | 2 | +-------------------------------+","title":"countIf"},{"location":"sqlstatement/aggregate-functions/aggregate-count-if/#countif","text":"The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. countIf(column, cond)","title":"countIf"},{"location":"sqlstatement/aggregate-functions/aggregate-count-if/#examples","text":"Note numbers_mt(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT count(number) FROM numbers(10); +---------------+ | count(number) | +---------------+ | 10 | +---------------+ mysql> SELECT countIf(number, number > 7) FROM numbers(10); +-------------------------------+ | countIf(number, (number > 7)) | +-------------------------------+ | 2 | +-------------------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-count/","text":"Aggregate function. The COUNT() function returns the number of records returned by a select query. Note: NULL values are not counted. Syntax \u00b6 COUNT(expression) Arguments \u00b6 Arguments Description expression Any expression. This may be a column name, the result of another function, or a math operation. * is also allowed, to indicate pure row counting. Return Type \u00b6 An integer. Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT count(*) FROM numbers(3); +----------+ | count(*) | +----------+ | 3 | +----------+ mysql> SELECT count(number) FROM numbers(3); +---------------+ | count(number) | +---------------+ | 3 | +---------------+ mysql> SELECT count(number) AS c FROM numbers(3); +------+ | c | +------+ | 3 | +------+","title":"COUNT"},{"location":"sqlstatement/aggregate-functions/aggregate-count/#syntax","text":"COUNT(expression)","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-count/#arguments","text":"Arguments Description expression Any expression. This may be a column name, the result of another function, or a math operation. * is also allowed, to indicate pure row counting.","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-count/#return-type","text":"An integer.","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-count/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT count(*) FROM numbers(3); +----------+ | count(*) | +----------+ | 3 | +----------+ mysql> SELECT count(number) FROM numbers(3); +---------------+ | count(number) | +---------------+ | 3 | +---------------+ mysql> SELECT count(number) AS c FROM numbers(3); +------+ | c | +------+ | 3 | +------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-max-if/","text":"maxIf \u00b6 The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. maxIf(column, cond) Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT max(number) FROM numbers(10); +-------------+ | max(number) | +-------------+ | 9 | +-------------+ mysql> SELECT maxIf(number, number < 7) FROM numbers(10); +-----------------------------+ | maxIf(number, (number < 7)) | +-----------------------------+ | 6 | +-----------------------------+","title":"maxIf"},{"location":"sqlstatement/aggregate-functions/aggregate-max-if/#maxif","text":"The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. maxIf(column, cond)","title":"maxIf"},{"location":"sqlstatement/aggregate-functions/aggregate-max-if/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT max(number) FROM numbers(10); +-------------+ | max(number) | +-------------+ | 9 | +-------------+ mysql> SELECT maxIf(number, number < 7) FROM numbers(10); +-----------------------------+ | maxIf(number, (number < 7)) | +-----------------------------+ | 6 | +-----------------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-max/","text":"Aggregate function. The MAX() function returns the maximum value in a set of values. Syntax \u00b6 MAX(expression) Arguments \u00b6 Arguments Description expression Any expression Return Type \u00b6 The maximum value, in the type of the value. Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT MAX(*) FROM numbers(3); +--------+ | max(*) | +--------+ | 2 | +--------+ mysql> SELECT MAX(number) FROM numbers(3); +-------------+ | max(number) | +-------------+ | 2 | +-------------+ mysql> SELECT MAX(number) AS max FROM numbers(3); +------+ | max | +------+ | 2 | +------+","title":"MAX"},{"location":"sqlstatement/aggregate-functions/aggregate-max/#syntax","text":"MAX(expression)","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-max/#arguments","text":"Arguments Description expression Any expression","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-max/#return-type","text":"The maximum value, in the type of the value.","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-max/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT MAX(*) FROM numbers(3); +--------+ | max(*) | +--------+ | 2 | +--------+ mysql> SELECT MAX(number) FROM numbers(3); +-------------+ | max(number) | +-------------+ | 2 | +-------------+ mysql> SELECT MAX(number) AS max FROM numbers(3); +------+ | max | +------+ | 2 | +------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-min-if/","text":"minIf \u00b6 The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. minIf(column, cond) Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT min(number) FROM numbers(10); +-------------+ | min(number) | +-------------+ | 0 | +-------------+ mysql> SELECT minIf(number, number > 7) FROM numbers(10); +-----------------------------+ | minIf(number, (number > 7)) | +-----------------------------+ | 8 | +-----------------------------+","title":"minIf"},{"location":"sqlstatement/aggregate-functions/aggregate-min-if/#minif","text":"The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. minIf(column, cond)","title":"minIf"},{"location":"sqlstatement/aggregate-functions/aggregate-min-if/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT min(number) FROM numbers(10); +-------------+ | min(number) | +-------------+ | 0 | +-------------+ mysql> SELECT minIf(number, number > 7) FROM numbers(10); +-----------------------------+ | minIf(number, (number > 7)) | +-----------------------------+ | 8 | +-----------------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-min/","text":"Aggregate function. The MIN() function returns the minimum value in a set of values. Syntax \u00b6 MIN(expression) Arguments \u00b6 Arguments Description expression Any expression Return Type \u00b6 The minimum value, in the type of the value. Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT MIN(*) FROM numbers(3); +--------+ | min(*) | +--------+ | 0 | +--------+ mysql> SELECT MIN(number) FROM numbers(3); +-------------+ | min(number) | +-------------+ | 0 | +-------------+ mysql> SELECT MIN(number) AS min FROM numbers(3); +------+ | min | +------+ | 0 | +------+","title":"MIN"},{"location":"sqlstatement/aggregate-functions/aggregate-min/#syntax","text":"MIN(expression)","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-min/#arguments","text":"Arguments Description expression Any expression","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-min/#return-type","text":"The minimum value, in the type of the value.","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-min/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT MIN(*) FROM numbers(3); +--------+ | min(*) | +--------+ | 0 | +--------+ mysql> SELECT MIN(number) FROM numbers(3); +-------------+ | min(number) | +-------------+ | 0 | +-------------+ mysql> SELECT MIN(number) AS min FROM numbers(3); +------+ | min | +------+ | 0 | +------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-stddev-pop/","text":"Aggregate function. The STDDEV_POP() function returns the population standard deviation(the square root of VAR_POP()) of an expression. Note STD() or STDDEV() can also be used, which are equivalent but not standard SQL. Warning NULL values are not counted. Syntax \u00b6 STDDEV_POP ( expression ) STDDEV ( expression ) STD ( expression ) Arguments \u00b6 Arguments Description expression Any numerical expression Return Type \u00b6 double Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT STDDEV_POP(number) FROM numbers(10000); +--------------------+ | STDDEV_POP(number) | +--------------------+ | 2886.751331514372 | +--------------------+ mysql> SELECT STDDEV(number) FROM numbers(1000); +--------------------+ | STDDEV(number) | +--------------------+ | 288.67499025720946 | +--------------------+ mysql> SELECT STD(number) FROM numbers(100); +-------------------+ | STD(number) | +-------------------+ | 28.86607004772212 | +-------------------+","title":"STDDEV_POP"},{"location":"sqlstatement/aggregate-functions/aggregate-stddev-pop/#syntax","text":"STDDEV_POP ( expression ) STDDEV ( expression ) STD ( expression )","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-stddev-pop/#arguments","text":"Arguments Description expression Any numerical expression","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-stddev-pop/#return-type","text":"double","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-stddev-pop/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT STDDEV_POP(number) FROM numbers(10000); +--------------------+ | STDDEV_POP(number) | +--------------------+ | 2886.751331514372 | +--------------------+ mysql> SELECT STDDEV(number) FROM numbers(1000); +--------------------+ | STDDEV(number) | +--------------------+ | 288.67499025720946 | +--------------------+ mysql> SELECT STD(number) FROM numbers(100); +-------------------+ | STD(number) | +-------------------+ | 28.86607004772212 | +-------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-sum-if/","text":"sumIf \u00b6 The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. sumIf(column, cond) Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT sum(number) FROM numbers(10); +-------------+ | sum(number) | +-------------+ | 45 | +-------------+ mysql> SELECT sumIf(number, number > 7) FROM numbers(10); +-----------------------------+ | sumIf(number, (number > 7)) | +-----------------------------+ | 17 | +-----------------------------+","title":"sumIf"},{"location":"sqlstatement/aggregate-functions/aggregate-sum-if/#sumif","text":"The suffix -If can be appended to the name of any aggregate function. In this case, the aggregate function accepts an extra argument \u2013 a condition. sumIf(column, cond)","title":"sumIf"},{"location":"sqlstatement/aggregate-functions/aggregate-sum-if/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT sum(number) FROM numbers(10); +-------------+ | sum(number) | +-------------+ | 45 | +-------------+ mysql> SELECT sumIf(number, number > 7) FROM numbers(10); +-----------------------------+ | sumIf(number, (number > 7)) | +-----------------------------+ | 17 | +-----------------------------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-sum/","text":"Aggregate function. The SUM() function calculates the sum of a set of values. Note: NULL values are not counted. Syntax \u00b6 SUM(expression) Arguments \u00b6 Arguments Description expression Any expression Return Type \u00b6 A double if the input type is double, otherwise integer. Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT SUM(*) FROM numbers(3); +--------+ | sum(*) | +--------+ | 3 | +--------+ mysql> SELECT SUM(number) FROM numbers(3); +-------------+ | sum(number) | +-------------+ | 3 | +-------------+ mysql> SELECT SUM(number) AS sum FROM numbers(3); +------+ | sum | +------+ | 3 | +------+ mysql> SELECT SUM(number+2) AS sum FROM numbers(3); +------+ | sum | +------+ | 9 | +------+","title":"SUM"},{"location":"sqlstatement/aggregate-functions/aggregate-sum/#syntax","text":"SUM(expression)","title":"Syntax"},{"location":"sqlstatement/aggregate-functions/aggregate-sum/#arguments","text":"Arguments Description expression Any expression","title":"Arguments"},{"location":"sqlstatement/aggregate-functions/aggregate-sum/#return-type","text":"A double if the input type is double, otherwise integer.","title":"Return Type"},{"location":"sqlstatement/aggregate-functions/aggregate-sum/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SELECT SUM(*) FROM numbers(3); +--------+ | sum(*) | +--------+ | 3 | +--------+ mysql> SELECT SUM(number) FROM numbers(3); +-------------+ | sum(number) | +-------------+ | 3 | +-------------+ mysql> SELECT SUM(number) AS sum FROM numbers(3); +------+ | sum | +------+ | 3 | +------+ mysql> SELECT SUM(number+2) AS sum FROM numbers(3); +------+ | sum | +------+ | 9 | +------+","title":"Examples"},{"location":"sqlstatement/aggregate-functions/aggregate-windowfunnel/","text":"windowFunnel \u00b6 Similar to windowFunnel in ClickHouse (they were created by the same author), it searches for event chains in a sliding time window and calculates the maximum number of events that occurred from the chain. The function works according to the algorithm: The function searches for data that triggers the first condition in the chain and sets the event counter to 1. This is the moment when the sliding window starts. If events from the chain occur sequentially within the window, the counter is incremented. If the sequence of events is disrupted, the counter isn\u2019t incremented. If the data has multiple event chains at varying points of completion, the function will only output the size of the longest chain. windowFunnel ( window )( timestamp , cond1 , cond2 , ..., condN ) Arguments timestamp \u2014 Name of the column containing the timestamp. Data types supported: unsigned integer types. cond \u2014 Conditions or data describing the chain of events. Must be Boolean datatype. Parameters window \u2014 Length of the sliding window, it is the time interval between the first and the last condition. The unit of window depends on the timestamp itself and varies. Determined using the expression timestamp of cond1 <= timestamp of cond2 <= ... <= timestamp of condN <= timestamp of cond1 + window . Returned value The maximum number of consecutive triggered conditions from the chain within the sliding time window. All the chains in the selection are analyzed. Type: UInt8 . Example Determine if a set period of time is enough for the user to select a phone and purchase it twice in the online store. Set the following chain of events: The user logged in to their account on the store ( eventID = 1003 ). The user searches for a phone ( eventID = 1007, product = 'phone' ). The user placed an order ( eventID = 1009 ). The user made the order again ( eventID = 1010 ). Input table: \u250c\u2500user_id\u2500\u252c\u2500timestamp\u2500\u252c\u2500eventID\u2500\u252c\u2500product\u2500\u2510 \u2502 1 \u2502 20 \u2502 1003 \u2502 phone \u2502 \u2502 1 \u2502 200 \u2502 1007 \u2502 phone \u2502 \u2502 1 \u2502 50 \u2502 1009 \u2502 phone \u2502 \u2502 1 \u2502 400 \u2502 1010 \u2502 phone \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find out how far the user user_id could get through the chain. Query: SELECT level , count () AS c FROM ( SELECT user_id , windowFunnel ( 500 )( timestamp , eventID = 1003 , eventID = 1009 , eventID = 1007 , eventID = 1010 ) AS level FROM test GROUP BY user_id ) GROUP BY level ORDER BY level ASC ; Result: \u250c\u2500level\u2500\u252c\u2500c\u2500\u2510 \u2502 4 \u2502 1 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518","title":"windowFunnel"},{"location":"sqlstatement/aggregate-functions/aggregate-windowfunnel/#windowfunnel","text":"Similar to windowFunnel in ClickHouse (they were created by the same author), it searches for event chains in a sliding time window and calculates the maximum number of events that occurred from the chain. The function works according to the algorithm: The function searches for data that triggers the first condition in the chain and sets the event counter to 1. This is the moment when the sliding window starts. If events from the chain occur sequentially within the window, the counter is incremented. If the sequence of events is disrupted, the counter isn\u2019t incremented. If the data has multiple event chains at varying points of completion, the function will only output the size of the longest chain. windowFunnel ( window )( timestamp , cond1 , cond2 , ..., condN ) Arguments timestamp \u2014 Name of the column containing the timestamp. Data types supported: unsigned integer types. cond \u2014 Conditions or data describing the chain of events. Must be Boolean datatype. Parameters window \u2014 Length of the sliding window, it is the time interval between the first and the last condition. The unit of window depends on the timestamp itself and varies. Determined using the expression timestamp of cond1 <= timestamp of cond2 <= ... <= timestamp of condN <= timestamp of cond1 + window . Returned value The maximum number of consecutive triggered conditions from the chain within the sliding time window. All the chains in the selection are analyzed. Type: UInt8 . Example Determine if a set period of time is enough for the user to select a phone and purchase it twice in the online store. Set the following chain of events: The user logged in to their account on the store ( eventID = 1003 ). The user searches for a phone ( eventID = 1007, product = 'phone' ). The user placed an order ( eventID = 1009 ). The user made the order again ( eventID = 1010 ). Input table: \u250c\u2500user_id\u2500\u252c\u2500timestamp\u2500\u252c\u2500eventID\u2500\u252c\u2500product\u2500\u2510 \u2502 1 \u2502 20 \u2502 1003 \u2502 phone \u2502 \u2502 1 \u2502 200 \u2502 1007 \u2502 phone \u2502 \u2502 1 \u2502 50 \u2502 1009 \u2502 phone \u2502 \u2502 1 \u2502 400 \u2502 1010 \u2502 phone \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Find out how far the user user_id could get through the chain. Query: SELECT level , count () AS c FROM ( SELECT user_id , windowFunnel ( 500 )( timestamp , eventID = 1003 , eventID = 1009 , eventID = 1007 , eventID = 1010 ) AS level FROM test GROUP BY user_id ) GROUP BY level ORDER BY level ASC ; Result: \u250c\u2500level\u2500\u252c\u2500c\u2500\u2510 \u2502 4 \u2502 1 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2518","title":"windowFunnel"},{"location":"sqlstatement/conditional-functions/if/","text":"If expr1 is TRUE, IF() returns expr2. Otherwise, it returns expr3. Syntax \u00b6 IF ( expr1 , expr2 , expr3 ) Arguments \u00b6 Arguments Description expr1 The condition for evaluation that can be true or false. expr2 The expression to return if condition is met. expr3 The expression to return if condition is not met. Return Type \u00b6 The return type is determined by expr2 and expr3, they must have the lowest common type. Examples \u00b6 mysql> select if(number=0, true, false) from numbers(1); +-------------------------------+ | if((number = 0), true, false) | +-------------------------------+ | 1 | +-------------------------------+ 1 row in set (0.01 sec) mysql> SELECT if(number > 5, number*5, number+5 ) FROM numbers(10); +----------------------------------------------+ | if((number > 5), (number * 5), (number + 5)) | +----------------------------------------------+ | 5 | | 6 | | 7 | | 8 | | 9 | | 10 | | 30 | | 35 | | 40 | | 45 | +----------------------------------------------+","title":"IF"},{"location":"sqlstatement/conditional-functions/if/#syntax","text":"IF ( expr1 , expr2 , expr3 )","title":"Syntax"},{"location":"sqlstatement/conditional-functions/if/#arguments","text":"Arguments Description expr1 The condition for evaluation that can be true or false. expr2 The expression to return if condition is met. expr3 The expression to return if condition is not met.","title":"Arguments"},{"location":"sqlstatement/conditional-functions/if/#return-type","text":"The return type is determined by expr2 and expr3, they must have the lowest common type.","title":"Return Type"},{"location":"sqlstatement/conditional-functions/if/#examples","text":"mysql> select if(number=0, true, false) from numbers(1); +-------------------------------+ | if((number = 0), true, false) | +-------------------------------+ | 1 | +-------------------------------+ 1 row in set (0.01 sec) mysql> SELECT if(number > 5, number*5, number+5 ) FROM numbers(10); +----------------------------------------------+ | if((number > 5), (number * 5), (number + 5)) | +----------------------------------------------+ | 5 | | 6 | | 7 | | 8 | | 9 | | 10 | | 30 | | 35 | | 40 | | 45 | +----------------------------------------------+","title":"Examples"},{"location":"sqlstatement/conversion-functions/cast/","text":"Convert a value from one data type to another data type. Syntax \u00b6 CAST ( x AS t ) Arguments \u00b6 Arguments Description x A value to convert. t The target data type. Return Type \u00b6 Converted value. Examples \u00b6 mysql> SELECT CAST(1 AS VARCHAR); +-------------------+ | cast(1 as String) | +-------------------+ | 1 | +-------------------+ mysql> SELECT CAST(1 AS UInt64); +-------------------+ | cast(1 as UInt64) | +-------------------+ | 1 | +-------------------+ mysql> SELECT toTypeName(CAST(1 AS UInt64)); +-------------------------------+ | toTypeName(cast(1 as UInt64)) | +-------------------------------+ | UInt64 | +-------------------------------+","title":"CAST"},{"location":"sqlstatement/conversion-functions/cast/#syntax","text":"CAST ( x AS t )","title":"Syntax"},{"location":"sqlstatement/conversion-functions/cast/#arguments","text":"Arguments Description x A value to convert. t The target data type.","title":"Arguments"},{"location":"sqlstatement/conversion-functions/cast/#return-type","text":"Converted value.","title":"Return Type"},{"location":"sqlstatement/conversion-functions/cast/#examples","text":"mysql> SELECT CAST(1 AS VARCHAR); +-------------------+ | cast(1 as String) | +-------------------+ | 1 | +-------------------+ mysql> SELECT CAST(1 AS UInt64); +-------------------+ | cast(1 as UInt64) | +-------------------+ | 1 | +-------------------+ mysql> SELECT toTypeName(CAST(1 AS UInt64)); +-------------------------------+ | toTypeName(cast(1 as UInt64)) | +-------------------------------+ | UInt64 | +-------------------------------+","title":"Examples"},{"location":"sqlstatement/conversion-functions/type-conversion/","text":"toInt(8|16|32|64) Syntax \u00b6 toInt8 ( expr ) \u2014 Results in the Int8 data type . toInt16 ( expr ) \u2014 Results in the Int16 data type . toInt32 ( expr ) \u2014 Results in the Int32 data type . toInt64 ( expr ) \u2014 Results in the Int64 data type . Examples \u00b6 mysql> SELECT toInt8(1); +-----------+ | toInt8(1) | +-----------+ | 1 | +-----------+ mysql> SELECT toTypeName(toInt8(1)); +-----------------------+ | toTypeName(toInt8(1)) | +-----------------------+ | Int8 | +-----------------------+","title":"Type Conversion"},{"location":"sqlstatement/conversion-functions/type-conversion/#syntax","text":"toInt8 ( expr ) \u2014 Results in the Int8 data type . toInt16 ( expr ) \u2014 Results in the Int16 data type . toInt32 ( expr ) \u2014 Results in the Int32 data type . toInt64 ( expr ) \u2014 Results in the Int64 data type .","title":"Syntax"},{"location":"sqlstatement/conversion-functions/type-conversion/#examples","text":"mysql> SELECT toInt8(1); +-----------+ | toInt8(1) | +-----------+ | 1 | +-----------+ mysql> SELECT toTypeName(toInt8(1)); +-----------------------+ | toTypeName(toInt8(1)) | +-----------------------+ | Int8 | +-----------------------+","title":"Examples"},{"location":"sqlstatement/data-definition-language-ddl/ddl-create-database/","text":"Create a database. Syntax \u00b6 CREATE DATABASE < database_name > Examples \u00b6 mysql > CREATE DATABASE test ;","title":"CREATE DATABASE"},{"location":"sqlstatement/data-definition-language-ddl/ddl-create-database/#syntax","text":"CREATE DATABASE < database_name >","title":"Syntax"},{"location":"sqlstatement/data-definition-language-ddl/ddl-create-database/#examples","text":"mysql > CREATE DATABASE test ;","title":"Examples"},{"location":"sqlstatement/data-definition-language-ddl/ddl-create-table/","text":"Create a new table. Syntax \u00b6 CREATE TABLE [ IF NOT EXISTS ] [ db .] table_name ( name1 type1 , name2 type2 , ... ) ENGINE = engine Note Local engine is one of Memory , Parquet , JSONEachRow , Null or CSV , data will be stored in the DatabendQuery memory/disk locally. Remote engine is remote , will be stored in the remote DatabendStore cluster. Examples \u00b6 Memory engine \u00b6 mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > INSERT INTO test ( a , b ) values ( 888 , 'stars' ); mysql > SELECT * FROM test ; + ------+---------+ | a | b | + ------+---------+ | 888 | stars | + ------+---------+","title":"CREATE TABLE"},{"location":"sqlstatement/data-definition-language-ddl/ddl-create-table/#syntax","text":"CREATE TABLE [ IF NOT EXISTS ] [ db .] table_name ( name1 type1 , name2 type2 , ... ) ENGINE = engine Note Local engine is one of Memory , Parquet , JSONEachRow , Null or CSV , data will be stored in the DatabendQuery memory/disk locally. Remote engine is remote , will be stored in the remote DatabendStore cluster.","title":"Syntax"},{"location":"sqlstatement/data-definition-language-ddl/ddl-create-table/#examples","text":"","title":"Examples"},{"location":"sqlstatement/data-definition-language-ddl/ddl-create-table/#memory-engine","text":"mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > INSERT INTO test ( a , b ) values ( 888 , 'stars' ); mysql > SELECT * FROM test ; + ------+---------+ | a | b | + ------+---------+ | 888 | stars | + ------+---------+","title":"Memory engine"},{"location":"sqlstatement/data-definition-language-ddl/ddl-drop-database/","text":"Drop a database. Syntax \u00b6 DROP DATABASE [ IF EXISTS ] < database_name > Examples \u00b6 mysql > DROP DATABASE test ;","title":"DROP DATABASE"},{"location":"sqlstatement/data-definition-language-ddl/ddl-drop-database/#syntax","text":"DROP DATABASE [ IF EXISTS ] < database_name >","title":"Syntax"},{"location":"sqlstatement/data-definition-language-ddl/ddl-drop-database/#examples","text":"mysql > DROP DATABASE test ;","title":"Examples"},{"location":"sqlstatement/data-definition-language-ddl/ddl-drop-table/","text":"Deletes the table. Syntax \u00b6 DROP TABLE [ IF EXISTS ] [ db .] name Examples \u00b6 mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > DROP TABLE test ;","title":"DROP TABLE"},{"location":"sqlstatement/data-definition-language-ddl/ddl-drop-table/#syntax","text":"DROP TABLE [ IF EXISTS ] [ db .] name","title":"Syntax"},{"location":"sqlstatement/data-definition-language-ddl/ddl-drop-table/#examples","text":"mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > DROP TABLE test ;","title":"Examples"},{"location":"sqlstatement/data-definition-language-ddl/ddl-truncate-table/","text":"Empties the table completely. Syntax \u00b6 TRUNCATE TABLE [ db .] name Examples \u00b6 mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > INSERT INTO test ( a , b ) values ( 888 , 'stars' ); mysql > SELECT * FROM test ; + ------+---------+ | a | b | + ------+---------+ | 888 | stars | + ------+---------+ mysql > TRUNCATE TABLE test ; mysql > SELECT * FROM test ;","title":"TRUNCATE TABLE"},{"location":"sqlstatement/data-definition-language-ddl/ddl-truncate-table/#syntax","text":"TRUNCATE TABLE [ db .] name","title":"Syntax"},{"location":"sqlstatement/data-definition-language-ddl/ddl-truncate-table/#examples","text":"mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > INSERT INTO test ( a , b ) values ( 888 , 'stars' ); mysql > SELECT * FROM test ; + ------+---------+ | a | b | + ------+---------+ | 888 | stars | + ------+---------+ mysql > TRUNCATE TABLE test ; mysql > SELECT * FROM test ;","title":"Examples"},{"location":"sqlstatement/data-manipulation-language-dml/dml-insert/","text":"Writing data. Syntax \u00b6 INSERT INTO [db.]table [(c1, c2, c3)] VALUES (v11, v12, v13), (v21, v22, v23), ... Note Local engine is one of Memory , Parquet , JSONEachRow , Null or CSV , data will be stored in the DatabendQuery memory/disk locally. Remote engine is remote , will be stored in the remote DatabendStore cluster. Examples \u00b6 Memory engine \u00b6 mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > INSERT INTO test ( a , b ) values ( 888 , 'stars' ); mysql > INSERT INTO test values ( 1024 , 'stars' ); mysql > SELECT * FROM test ; + ------+-------+ | a | b | + ------+-------+ | 888 | stars | | 1024 | stars | + ------+-------+","title":"INSERT"},{"location":"sqlstatement/data-manipulation-language-dml/dml-insert/#syntax","text":"INSERT INTO [db.]table [(c1, c2, c3)] VALUES (v11, v12, v13), (v21, v22, v23), ... Note Local engine is one of Memory , Parquet , JSONEachRow , Null or CSV , data will be stored in the DatabendQuery memory/disk locally. Remote engine is remote , will be stored in the remote DatabendStore cluster.","title":"Syntax"},{"location":"sqlstatement/data-manipulation-language-dml/dml-insert/#examples","text":"","title":"Examples"},{"location":"sqlstatement/data-manipulation-language-dml/dml-insert/#memory-engine","text":"mysql > CREATE TABLE test ( a UInt64 , b Varchar ) Engine = Memory ; mysql > INSERT INTO test ( a , b ) values ( 888 , 'stars' ); mysql > INSERT INTO test values ( 1024 , 'stars' ); mysql > SELECT * FROM test ; + ------+-------+ | a | b | + ------+-------+ | 888 | stars | | 1024 | stars | + ------+-------+","title":"Memory engine"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/","text":"Retrieves data from a table. Syntax \u00b6 SELECT [ALL | DISTINCT] select_expr [[AS] alias], ... [INTO variable [, ...]] [ FROM table_references [WHERE expr] [GROUP BY {{col_name | expr | position}, ... | extended_grouping_expr}] [HAVING expr] [ORDER BY {col_name | expr} [ASC | DESC], ...] [LIMIT row_count] ] Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. SELECT clause \u00b6 mysql> SELECT number FROM numbers(3); +--------+ | number | +--------+ | 0 | | 1 | | 2 | +--------+ FROM clause \u00b6 mysql> SELECT number FROM numbers(3) AS a; +--------+ | number | +--------+ | 0 | | 1 | | 2 | +--------+ WHERE clause \u00b6 mysql> SELECT number FROM numbers(3) WHERE number > 1; +--------+ | number | +--------+ | 2 | +--------+ 1 row in set (0.00 sec) GROUP BY clause \u00b6 mysql> SELECT number%2 as c1, number%3 as c2, MAX(number) FROM numbers(10000) GROUP BY c1, c2; +------+------+-------------+ | c1 | c2 | MAX(number) | +------+------+-------------+ | 1 | 2 | 9995 | | 1 | 1 | 9997 | | 0 | 2 | 9998 | | 0 | 1 | 9994 | | 0 | 0 | 9996 | | 1 | 0 | 9999 | +------+------+-------------+ 6 rows in set (0.00 sec) HAVING clause \u00b6 mysql> SELECT number%2 as c1, number%3 as c2, MAX(number) as max FROM numbers(10000) GROUP BY c1, c2 HAVING max>9996; +------+------+------+ | c1 | c2 | max | +------+------+------+ | 1 | 0 | 9999 | | 1 | 1 | 9997 | | 0 | 2 | 9998 | +------+------+------+ 3 rows in set (0.00 sec) ORDER By clause \u00b6 mysql> SELECT number FROM numbers(5) ORDER BY number ASC; +--------+ | number | +--------+ | 0 | | 1 | | 2 | | 3 | | 4 | +--------+ 5 rows in set (0.00 sec) mysql> SELECT number FROM numbers(5) ORDER BY number DESC; +--------+ | number | +--------+ | 4 | | 3 | | 2 | | 1 | | 0 | +--------+ 5 rows in set (0.00 sec) mysql> SELECT number%2 AS c1, number%3 AS c2 FROM numbers(5) ORDER BY c1 ASC, c2 DESC; +------+------+ | c1 | c2 | +------+------+ | 0 | 2 | | 0 | 1 | | 0 | 0 | | 1 | 1 | | 1 | 0 | +------+------+ 5 rows in set (0.00 sec) LIMIT clause \u00b6 mysql> SELECT number FROM numbers(1000000000) LIMIT 1; +--------+ | number | +--------+ | 0 | +--------+ 1 row in set (0.00 sec) Nested Sub-Selects \u00b6 SELECT statements can be nested in queries. SELECT ... [SELECT ...[SELECT [...]]] mysql> SELECT MIN(number) FROM (SELECT number%3 AS number FROM numbers(10)) GROUP BY number%2; +-------------+ | min(number) | +-------------+ | 1 | | 0 | +-------------+","title":"SELECT"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#syntax","text":"SELECT [ALL | DISTINCT] select_expr [[AS] alias], ... [INTO variable [, ...]] [ FROM table_references [WHERE expr] [GROUP BY {{col_name | expr | position}, ... | extended_grouping_expr}] [HAVING expr] [ORDER BY {col_name | expr} [ASC | DESC], ...] [LIMIT row_count] ] Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1.","title":"Syntax"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#select-clause","text":"mysql> SELECT number FROM numbers(3); +--------+ | number | +--------+ | 0 | | 1 | | 2 | +--------+","title":"SELECT clause"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#from-clause","text":"mysql> SELECT number FROM numbers(3) AS a; +--------+ | number | +--------+ | 0 | | 1 | | 2 | +--------+","title":"FROM clause"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#where-clause","text":"mysql> SELECT number FROM numbers(3) WHERE number > 1; +--------+ | number | +--------+ | 2 | +--------+ 1 row in set (0.00 sec)","title":"WHERE clause"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#group-by-clause","text":"mysql> SELECT number%2 as c1, number%3 as c2, MAX(number) FROM numbers(10000) GROUP BY c1, c2; +------+------+-------------+ | c1 | c2 | MAX(number) | +------+------+-------------+ | 1 | 2 | 9995 | | 1 | 1 | 9997 | | 0 | 2 | 9998 | | 0 | 1 | 9994 | | 0 | 0 | 9996 | | 1 | 0 | 9999 | +------+------+-------------+ 6 rows in set (0.00 sec)","title":"GROUP BY clause"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#having-clause","text":"mysql> SELECT number%2 as c1, number%3 as c2, MAX(number) as max FROM numbers(10000) GROUP BY c1, c2 HAVING max>9996; +------+------+------+ | c1 | c2 | max | +------+------+------+ | 1 | 0 | 9999 | | 1 | 1 | 9997 | | 0 | 2 | 9998 | +------+------+------+ 3 rows in set (0.00 sec)","title":"HAVING clause"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#order-by-clause","text":"mysql> SELECT number FROM numbers(5) ORDER BY number ASC; +--------+ | number | +--------+ | 0 | | 1 | | 2 | | 3 | | 4 | +--------+ 5 rows in set (0.00 sec) mysql> SELECT number FROM numbers(5) ORDER BY number DESC; +--------+ | number | +--------+ | 4 | | 3 | | 2 | | 1 | | 0 | +--------+ 5 rows in set (0.00 sec) mysql> SELECT number%2 AS c1, number%3 AS c2 FROM numbers(5) ORDER BY c1 ASC, c2 DESC; +------+------+ | c1 | c2 | +------+------+ | 0 | 2 | | 0 | 1 | | 0 | 0 | | 1 | 1 | | 1 | 0 | +------+------+ 5 rows in set (0.00 sec)","title":"ORDER By clause"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#limit-clause","text":"mysql> SELECT number FROM numbers(1000000000) LIMIT 1; +--------+ | number | +--------+ | 0 | +--------+ 1 row in set (0.00 sec)","title":"LIMIT clause"},{"location":"sqlstatement/data-manipulation-language-dml/dml-select/#nested-sub-selects","text":"SELECT statements can be nested in queries. SELECT ... [SELECT ...[SELECT [...]]] mysql> SELECT MIN(number) FROM (SELECT number%3 AS number FROM numbers(10)) GROUP BY number%2; +-------------+ | min(number) | +-------------+ | 1 | | 0 | +-------------+","title":"Nested Sub-Selects"},{"location":"sqlstatement/data-types/data-type-integer-number/","text":"Data Type Size Min Value Max Value Int8 1 byte -128 127 Int16 2 byte -32768 32767 Int32 4 byte -2147483648 2147483647 Int64 8 byte -9223372036854775808 9223372036854775807 UInt8 1 byte 0 255 UInt16 2 byte 0 65535 UInt32 4 byte 0 4294967295 UInt64 8 byte 0 18446744073709551615","title":"Integer Numbers"},{"location":"sqlstatement/data-types/data-type-real-number/","text":"Data Type Size Precision Syntax Float32 4 byte 23 bits FLOAT Float64 8 byte 53 bits DOUBLE","title":"Real Numbers"},{"location":"sqlstatement/data-types/data-type-string-types/","text":"Strings of an arbitrary length. \u00b6 Data Type Syntax String Varchar","title":"String Types"},{"location":"sqlstatement/data-types/data-type-string-types/#strings-of-an-arbitrary-length","text":"Data Type Syntax String Varchar","title":"Strings of an arbitrary length."},{"location":"sqlstatement/data-types/data-type-time-date-types/","text":"Data Type Size Resolution Min Value Max Value Precision Date 2 byte day 1000-01-01 9999-12-31 YYYY-MM-DD Date32 4 byte day 1000-01-01 9999-12-31 YYYY-MM-DD DateTime/DateTime32 4 byte second 1970-01-01 00:00:00 2105-12-31 23:59:59 YYYY-MM-DD hh:mm:ss DateTime/DateTime32 4 byte second 1970-01-01 00:00:00 2105-12-31 23:59:59 YYYY-MM-DD hh:mm:ss For example: CREATE TABLE dt ( d Date, t DateTime, event_id UInt8 ) ENGINE = Memory; INSERT INTO dt VALUES ('2021-09-09', '2021-09-09 01:01:01', 1); mysql> select * from dt; +------------+---------------------+----------+ | d | t | event_id | +------------+---------------------+----------+ | 2021-09-09 | 2021-09-09 01:01:01 | 1 | +------------+---------------------+----------+","title":"Time and Date"},{"location":"sqlstatement/datetime-functions/addinterval/","text":"Add time interval to a date or datetime, return the result of date or datetime type. Syntax \u00b6 addYears ( exp0 , expr1 ) addMonths ( exp0 , expr1 ) addDays ( exp0 , expr1 ) addHours ( exp0 , expr1 ) addMinutes ( exp0 , expr1 ) addSeconds ( exp0 , expr1 ) Return Type \u00b6 Date16, Date32 or DateTime32, depends on the input. Examples \u00b6 mysql> select toDate(18875), addYears(toDate(18875), 2); +---------------+-----------------------------+ | toDate(18875) | addYears(toDate(18875), 10) | +---------------+-----------------------------+ | 2021-09-05 | 2023-09-05 | +---------------+-----------------------------+ mysql> select toDate(18875), addMonths(toDate(18875), 2); +---------------+-----------------------------+ | toDate(18875) | addMonths(toDate(18875), 2) | +---------------+-----------------------------+ | 2021-09-05 | 2021-11-05 | +---------------+-----------------------------+ mysql> select toDate(18875), addDays(toDate(18875), 2); +---------------+---------------------------+ | toDate(18875) | addDays(toDate(18875), 2) | +---------------+---------------------------+ | 2021-09-05 | 2021-09-07 | +---------------+---------------------------+ mysql> select toDateTime(1630833797), addHours(toDateTime(1630833797), 2); +------------------------+-------------------------------------+ | toDateTime(1630833797) | addHours(toDateTime(1630833797), 2) | +------------------------+-------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 11:23:17 | +------------------------+-------------------------------------+ mysql> select toDateTime(1630833797), addMinutes(toDateTime(1630833797), 2); +------------------------+---------------------------------------+ | toDateTime(1630833797) | addMinutes(toDateTime(1630833797), 2) | +------------------------+---------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:25:17 | +------------------------+---------------------------------------+ mysql> select toDateTime(1630833797), addSeconds(toDateTime(1630833797), 2); +------------------------+---------------------------------------+ | toDateTime(1630833797) | addSeconds(toDateTime(1630833797), 2) | +------------------------+---------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:23:19 | +------------------------+---------------------------------------+","title":"addYEARS/MONTHS/DAYS/HOURS/MINUTES/SECONDS"},{"location":"sqlstatement/datetime-functions/addinterval/#syntax","text":"addYears ( exp0 , expr1 ) addMonths ( exp0 , expr1 ) addDays ( exp0 , expr1 ) addHours ( exp0 , expr1 ) addMinutes ( exp0 , expr1 ) addSeconds ( exp0 , expr1 )","title":"Syntax"},{"location":"sqlstatement/datetime-functions/addinterval/#return-type","text":"Date16, Date32 or DateTime32, depends on the input.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/addinterval/#examples","text":"mysql> select toDate(18875), addYears(toDate(18875), 2); +---------------+-----------------------------+ | toDate(18875) | addYears(toDate(18875), 10) | +---------------+-----------------------------+ | 2021-09-05 | 2023-09-05 | +---------------+-----------------------------+ mysql> select toDate(18875), addMonths(toDate(18875), 2); +---------------+-----------------------------+ | toDate(18875) | addMonths(toDate(18875), 2) | +---------------+-----------------------------+ | 2021-09-05 | 2021-11-05 | +---------------+-----------------------------+ mysql> select toDate(18875), addDays(toDate(18875), 2); +---------------+---------------------------+ | toDate(18875) | addDays(toDate(18875), 2) | +---------------+---------------------------+ | 2021-09-05 | 2021-09-07 | +---------------+---------------------------+ mysql> select toDateTime(1630833797), addHours(toDateTime(1630833797), 2); +------------------------+-------------------------------------+ | toDateTime(1630833797) | addHours(toDateTime(1630833797), 2) | +------------------------+-------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 11:23:17 | +------------------------+-------------------------------------+ mysql> select toDateTime(1630833797), addMinutes(toDateTime(1630833797), 2); +------------------------+---------------------------------------+ | toDateTime(1630833797) | addMinutes(toDateTime(1630833797), 2) | +------------------------+---------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:25:17 | +------------------------+---------------------------------------+ mysql> select toDateTime(1630833797), addSeconds(toDateTime(1630833797), 2); +------------------------+---------------------------------------+ | toDateTime(1630833797) | addSeconds(toDateTime(1630833797), 2) | +------------------------+---------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:23:19 | +------------------------+---------------------------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/now/","text":"Returns the current date and time. Syntax \u00b6 NOW () Return Type \u00b6 Datetime object, returns date and time in \u201cYYYY-MM-DD HH:MM:DD\u201d format. Examples \u00b6 mysql> select NOW(); +---------------------+ | NOW() | +---------------------+ | 2021-09-03 01:26:07 | +---------------------+","title":"NOW"},{"location":"sqlstatement/datetime-functions/now/#syntax","text":"NOW ()","title":"Syntax"},{"location":"sqlstatement/datetime-functions/now/#return-type","text":"Datetime object, returns date and time in \u201cYYYY-MM-DD HH:MM:DD\u201d format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/now/#examples","text":"mysql> select NOW(); +---------------------+ | NOW() | +---------------------+ | 2021-09-03 01:26:07 | +---------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/subtractinterval/","text":"Subtract time interval from a date or datetime, return the result of date or datetime type. Syntax \u00b6 subtractYears ( exp0 , expr1 ) subtractMonths ( exp0 , expr1 ) subtractDays ( exp0 , expr1 ) subtractHours ( exp0 , expr1 ) subtractMinutes ( exp0 , expr1 ) subtractSeconds ( exp0 , expr1 ) Return Type \u00b6 Date16, Date32 or DateTime32, depends on the input. Examples \u00b6 mysql> select toDate(18875), subtractYears(toDate(18875), 2); +---------------+---------------------------------+ | toDate(18875) | subtractYears(toDate(18875), 2) | +---------------+---------------------------------+ | 2021-09-05 | 2019-09-05 | +---------------+---------------------------------+ mysql> select toDate(18875), subtractMonths(toDate(18875), 2); +---------------+----------------------------------+ | toDate(18875) | subtractMonths(toDate(18875), 2) | +---------------+----------------------------------+ | 2021-09-05 | 2021-07-05 | +---------------+----------------------------------+ mysql> select toDate(18875), subtractDays(toDate(18875), 2); +---------------+--------------------------------+ | toDate(18875) | subtractDays(toDate(18875), 2) | +---------------+--------------------------------+ | 2021-09-05 | 2021-09-03 | +---------------+--------------------------------+ mysql> select toDateTime(1630833797), subtractHours(toDateTime(1630833797), 2); +------------------------+------------------------------------------+ | toDateTime(1630833797) | subtractHours(toDateTime(1630833797), 2) | +------------------------+------------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 07:23:17 | +------------------------+------------------------------------------+ mysql> select toDateTime(1630833797), subtractMinutes(toDateTime(1630833797), 2); +------------------------+--------------------------------------------+ | toDateTime(1630833797) | subtractMinutes(toDateTime(1630833797), 2) | +------------------------+--------------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:21:17 | +------------------------+--------------------------------------------+ mysql> select toDateTime(1630833797), subtractSeconds(toDateTime(1630833797), 2); +------------------------+--------------------------------------------+ | toDateTime(1630833797) | subtractSeconds(toDateTime(1630833797), 2) | +------------------------+--------------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:23:15 | +------------------------+--------------------------------------------+","title":"subtractYEARS/MONTHS/DAYS/HOURS/MINUTES/SECONDS"},{"location":"sqlstatement/datetime-functions/subtractinterval/#syntax","text":"subtractYears ( exp0 , expr1 ) subtractMonths ( exp0 , expr1 ) subtractDays ( exp0 , expr1 ) subtractHours ( exp0 , expr1 ) subtractMinutes ( exp0 , expr1 ) subtractSeconds ( exp0 , expr1 )","title":"Syntax"},{"location":"sqlstatement/datetime-functions/subtractinterval/#return-type","text":"Date16, Date32 or DateTime32, depends on the input.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/subtractinterval/#examples","text":"mysql> select toDate(18875), subtractYears(toDate(18875), 2); +---------------+---------------------------------+ | toDate(18875) | subtractYears(toDate(18875), 2) | +---------------+---------------------------------+ | 2021-09-05 | 2019-09-05 | +---------------+---------------------------------+ mysql> select toDate(18875), subtractMonths(toDate(18875), 2); +---------------+----------------------------------+ | toDate(18875) | subtractMonths(toDate(18875), 2) | +---------------+----------------------------------+ | 2021-09-05 | 2021-07-05 | +---------------+----------------------------------+ mysql> select toDate(18875), subtractDays(toDate(18875), 2); +---------------+--------------------------------+ | toDate(18875) | subtractDays(toDate(18875), 2) | +---------------+--------------------------------+ | 2021-09-05 | 2021-09-03 | +---------------+--------------------------------+ mysql> select toDateTime(1630833797), subtractHours(toDateTime(1630833797), 2); +------------------------+------------------------------------------+ | toDateTime(1630833797) | subtractHours(toDateTime(1630833797), 2) | +------------------------+------------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 07:23:17 | +------------------------+------------------------------------------+ mysql> select toDateTime(1630833797), subtractMinutes(toDateTime(1630833797), 2); +------------------------+--------------------------------------------+ | toDateTime(1630833797) | subtractMinutes(toDateTime(1630833797), 2) | +------------------------+--------------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:21:17 | +------------------------+--------------------------------------------+ mysql> select toDateTime(1630833797), subtractSeconds(toDateTime(1630833797), 2); +------------------------+--------------------------------------------+ | toDateTime(1630833797) | subtractSeconds(toDateTime(1630833797), 2) | +------------------------+--------------------------------------------+ | 2021-09-05 09:23:17 | 2021-09-05 09:23:15 | +------------------------+--------------------------------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/today/","text":"Returns current date. Syntax \u00b6 TODAY () Return Type \u00b6 Datetime object, returns date in \u201cYYYY-MM-DD\u201d format. Examples \u00b6 mysql> select TODAY(); +------------+ | TODAY() | +------------+ | 2021-09-03 | +------------+","title":"TODAY"},{"location":"sqlstatement/datetime-functions/today/#syntax","text":"TODAY ()","title":"Syntax"},{"location":"sqlstatement/datetime-functions/today/#return-type","text":"Datetime object, returns date in \u201cYYYY-MM-DD\u201d format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/today/#examples","text":"mysql> select TODAY(); +------------+ | TODAY() | +------------+ | 2021-09-03 | +------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/tomorrow/","text":"Returns tomorrow date, same as today() + 1 . Syntax \u00b6 YESTERDAY () Return Type \u00b6 Datetime object, returns date in \u201cYYYY-MM-DD\u201d format. Examples \u00b6 mysql> select TOMORROW(); +------------+ | TOMORROW() | +------------+ | 2021-09-04 | +------------+ mysql> select TODAY()+1; +---------------+ | (TODAY() + 1) | +---------------+ | 2021-09-04 | +---------------+","title":"TOMORROW"},{"location":"sqlstatement/datetime-functions/tomorrow/#syntax","text":"YESTERDAY ()","title":"Syntax"},{"location":"sqlstatement/datetime-functions/tomorrow/#return-type","text":"Datetime object, returns date in \u201cYYYY-MM-DD\u201d format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/tomorrow/#examples","text":"mysql> select TOMORROW(); +------------+ | TOMORROW() | +------------+ | 2021-09-04 | +------------+ mysql> select TODAY()+1; +---------------+ | (TODAY() + 1) | +---------------+ | 2021-09-04 | +---------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/tostartofisoyear/","text":"Returns the first day of the ISO year for a date or a date with time. Syntax \u00b6 toStartOfISOYear ( expr ) Return Type \u00b6 Datetime object, returns date in \u201cYYYY-MM-DD\u201d format. Examples \u00b6 mysql> select toStartOfISOYear(toDate(18869)); +---------------------------------+ | toStartOfISOYear(toDate(18869)) | +---------------------------------+ | 2021-01-04 | +---------------------------------+ mysql> select toStartOfISOYear(toDateTime(1630812366)); +------------------------------------------+ | toStartOfISOYear(toDateTime(1630812366)) | +------------------------------------------+ | 2021-01-04 | +------------------------------------------+","title":"toStartOfISOYear"},{"location":"sqlstatement/datetime-functions/tostartofisoyear/#syntax","text":"toStartOfISOYear ( expr )","title":"Syntax"},{"location":"sqlstatement/datetime-functions/tostartofisoyear/#return-type","text":"Datetime object, returns date in \u201cYYYY-MM-DD\u201d format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/tostartofisoyear/#examples","text":"mysql> select toStartOfISOYear(toDate(18869)); +---------------------------------+ | toStartOfISOYear(toDate(18869)) | +---------------------------------+ | 2021-01-04 | +---------------------------------+ mysql> select toStartOfISOYear(toDateTime(1630812366)); +------------------------------------------+ | toStartOfISOYear(toDateTime(1630812366)) | +------------------------------------------+ | 2021-01-04 | +------------------------------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/tostartofyear/","text":"Returns the first day of the year for a date or a date with time. Syntax \u00b6 toStartOfYear ( expr ) Return Type \u00b6 Datetime object, returns date in \u201cYYYY-MM-DD\u201d format. Examples \u00b6 select toStartOfYear(toDate(18869)); +------------------------------+ | toStartOfYear(toDate(18869)) | +------------------------------+ | 2021-01-01 | +------------------------------+ mysql> select toStartOfYear(toDateTime(1630812366)); +---------------------------------------+ | toStartOfYear(toDateTime(1630812366)) | +---------------------------------------+ | 2021-01-01 | +---------------------------------------+","title":"toStartOfYear"},{"location":"sqlstatement/datetime-functions/tostartofyear/#syntax","text":"toStartOfYear ( expr )","title":"Syntax"},{"location":"sqlstatement/datetime-functions/tostartofyear/#return-type","text":"Datetime object, returns date in \u201cYYYY-MM-DD\u201d format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/tostartofyear/#examples","text":"select toStartOfYear(toDate(18869)); +------------------------------+ | toStartOfYear(toDate(18869)) | +------------------------------+ | 2021-01-01 | +------------------------------+ mysql> select toStartOfYear(toDateTime(1630812366)); +---------------------------------------+ | toStartOfYear(toDateTime(1630812366)) | +---------------------------------------+ | 2021-01-01 | +---------------------------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/toyyyymm/","text":"Converts a date or date with time to a UInt32 number containing the year and month number. Syntax \u00b6 toYYYYMM ( expr ) Return Type \u00b6 UInt32, returns in YYYYMM format. Examples \u00b6 mysql> select toDate(18875); +---------------+ | toDate(18875) | +---------------+ | 2021-09-05 | +---------------+ mysql> select toYYYYMM(toDate(18875)); +-------------------------+ | toYYYYMM(toDate(18875)) | +-------------------------+ | 202109 | +-------------------------+ mysql> select toTypeName(toYYYYMM(toDate(18875))); +-------------------------------------+ | toTypeName(toYYYYMM(toDate(18875))) | +-------------------------------------+ | UInt32 | +-------------------------------------+","title":"toYYYYMM"},{"location":"sqlstatement/datetime-functions/toyyyymm/#syntax","text":"toYYYYMM ( expr )","title":"Syntax"},{"location":"sqlstatement/datetime-functions/toyyyymm/#return-type","text":"UInt32, returns in YYYYMM format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/toyyyymm/#examples","text":"mysql> select toDate(18875); +---------------+ | toDate(18875) | +---------------+ | 2021-09-05 | +---------------+ mysql> select toYYYYMM(toDate(18875)); +-------------------------+ | toYYYYMM(toDate(18875)) | +-------------------------+ | 202109 | +-------------------------+ mysql> select toTypeName(toYYYYMM(toDate(18875))); +-------------------------------------+ | toTypeName(toYYYYMM(toDate(18875))) | +-------------------------------------+ | UInt32 | +-------------------------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/toyyyymmdd/","text":"Converts a date or date with time to a UInt32 number containing the year and month number (YYYY * 10000 + MM * 100 + DD). Syntax \u00b6 toYYYYMMDD ( expr ) Return Type \u00b6 UInt32, returns in YYYYMMDD format. Examples \u00b6 mysql> select toDate(18875); +---------------+ | toDate(18875) | +---------------+ | 2021-09-05 | +---------------+ mysql> select toYYYYMMDD(toDate(18875)); +---------------------------+ | toYYYYMMDD(toDate(18875)) | +---------------------------+ | 20210905 | +---------------------------+ mysql> select toTypeName(toYYYYMMDD(toDate(18875))); +---------------------------------------+ | toTypeName(toYYYYMMDD(toDate(18875))) | +---------------------------------------+ | UInt32 | +---------------------------------------+ mysql> select toDateTime(1630833797); +------------------------+ | toDateTime(1630833797) | +------------------------+ | 2021-09-05 09:23:17 | +------------------------+ mysql> select toYYYYMMDD(toDateTime(1630833797)); +------------------------------------+ | toYYYYMMDD(toDateTime(1630833797)) | +------------------------------------+ | 20210905 | +------------------------------------+ mysql> select toTypeName(toYYYYMMDD(toDateTime(1630833797))); +------------------------------------------------+ | toTypeName(toYYYYMMDD(toDateTime(1630833797))) | +------------------------------------------------+ | UInt32 | +------------------------------------------------+","title":"toYYYYMMDD"},{"location":"sqlstatement/datetime-functions/toyyyymmdd/#syntax","text":"toYYYYMMDD ( expr )","title":"Syntax"},{"location":"sqlstatement/datetime-functions/toyyyymmdd/#return-type","text":"UInt32, returns in YYYYMMDD format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/toyyyymmdd/#examples","text":"mysql> select toDate(18875); +---------------+ | toDate(18875) | +---------------+ | 2021-09-05 | +---------------+ mysql> select toYYYYMMDD(toDate(18875)); +---------------------------+ | toYYYYMMDD(toDate(18875)) | +---------------------------+ | 20210905 | +---------------------------+ mysql> select toTypeName(toYYYYMMDD(toDate(18875))); +---------------------------------------+ | toTypeName(toYYYYMMDD(toDate(18875))) | +---------------------------------------+ | UInt32 | +---------------------------------------+ mysql> select toDateTime(1630833797); +------------------------+ | toDateTime(1630833797) | +------------------------+ | 2021-09-05 09:23:17 | +------------------------+ mysql> select toYYYYMMDD(toDateTime(1630833797)); +------------------------------------+ | toYYYYMMDD(toDateTime(1630833797)) | +------------------------------------+ | 20210905 | +------------------------------------+ mysql> select toTypeName(toYYYYMMDD(toDateTime(1630833797))); +------------------------------------------------+ | toTypeName(toYYYYMMDD(toDateTime(1630833797))) | +------------------------------------------------+ | UInt32 | +------------------------------------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/toyyyymmddhhmmss/","text":"Converts a date or date with time to a UInt64 number containing the year and month number (YYYY * 10000000000 + MM * 100000000 + DD * 1000000 + hh * 10000 + mm * 100 + ss). Syntax \u00b6 toYYYYMMDDhhmmss ( expr ) Return Type \u00b6 UInt64, returns in YYYYMMDDhhmmss format. Examples \u00b6 mysql> select toDate(18875); +---------------+ | toDate(18875) | +---------------+ | 2021-09-05 | +---------------+ mysql> select toYYYYMMDDhhmmss(toDate(18875)); +---------------------------------+ | toYYYYMMDDhhmmss(toDate(18875)) | +---------------------------------+ | 20210905000000 | +---------------------------------+ mysql> select toTypeName(toYYYYMMDDhhmmss(toDate(18875))); +---------------------------------------------+ | toTypeName(toYYYYMMDDhhmmss(toDate(18875))) | +---------------------------------------------+ | UInt64 | +---------------------------------------------+ mysql> select toDateTime(1630833797); +------------------------+ | toDateTime(1630833797) | +------------------------+ | 2021-09-05 09:23:17 | +------------------------+ mysql> select toYYYYMMDDhhmmss(toDateTime(1630833797)); +------------------------------------------+ | toYYYYMMDDhhmmss(toDateTime(1630833797)) | +------------------------------------------+ | 20210905092317 | +------------------------------------------+ mysql> select toTypeName(toYYYYMMDDhhmmss(toDateTime(1630833797))); +------------------------------------------------------+ | toTypeName(toYYYYMMDDhhmmss(toDateTime(1630833797))) | +------------------------------------------------------+ | UInt64 | +------------------------------------------------------+","title":"toYYYYMMDDhhmmss"},{"location":"sqlstatement/datetime-functions/toyyyymmddhhmmss/#syntax","text":"toYYYYMMDDhhmmss ( expr )","title":"Syntax"},{"location":"sqlstatement/datetime-functions/toyyyymmddhhmmss/#return-type","text":"UInt64, returns in YYYYMMDDhhmmss format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/toyyyymmddhhmmss/#examples","text":"mysql> select toDate(18875); +---------------+ | toDate(18875) | +---------------+ | 2021-09-05 | +---------------+ mysql> select toYYYYMMDDhhmmss(toDate(18875)); +---------------------------------+ | toYYYYMMDDhhmmss(toDate(18875)) | +---------------------------------+ | 20210905000000 | +---------------------------------+ mysql> select toTypeName(toYYYYMMDDhhmmss(toDate(18875))); +---------------------------------------------+ | toTypeName(toYYYYMMDDhhmmss(toDate(18875))) | +---------------------------------------------+ | UInt64 | +---------------------------------------------+ mysql> select toDateTime(1630833797); +------------------------+ | toDateTime(1630833797) | +------------------------+ | 2021-09-05 09:23:17 | +------------------------+ mysql> select toYYYYMMDDhhmmss(toDateTime(1630833797)); +------------------------------------------+ | toYYYYMMDDhhmmss(toDateTime(1630833797)) | +------------------------------------------+ | 20210905092317 | +------------------------------------------+ mysql> select toTypeName(toYYYYMMDDhhmmss(toDateTime(1630833797))); +------------------------------------------------------+ | toTypeName(toYYYYMMDDhhmmss(toDateTime(1630833797))) | +------------------------------------------------------+ | UInt64 | +------------------------------------------------------+","title":"Examples"},{"location":"sqlstatement/datetime-functions/yesterday/","text":"Returns yesterday date, same as today() - 1 . Syntax \u00b6 YESTERDAY () Return Type \u00b6 Datetime object, returns date in \u201cYYYY-MM-DD\u201d format. Examples \u00b6 mysql> select YESTERDAY(); +-------------+ | YESTERDAY() | +-------------+ | 2021-09-02 | +-------------+ mysql> select TODAY()-1; +---------------+ | (TODAY() - 1) | +---------------+ | 2021-09-02 | +---------------+","title":"YESTERDAY"},{"location":"sqlstatement/datetime-functions/yesterday/#syntax","text":"YESTERDAY ()","title":"Syntax"},{"location":"sqlstatement/datetime-functions/yesterday/#return-type","text":"Datetime object, returns date in \u201cYYYY-MM-DD\u201d format.","title":"Return Type"},{"location":"sqlstatement/datetime-functions/yesterday/#examples","text":"mysql> select YESTERDAY(); +-------------+ | YESTERDAY() | +-------------+ | 2021-09-02 | +-------------+ mysql> select TODAY()-1; +---------------+ | (TODAY() - 1) | +---------------+ | 2021-09-02 | +---------------+","title":"Examples"},{"location":"sqlstatement/describe-commands/describe-table/","text":"Displays information about the columns in a given table. Syntax \u00b6 DESC|DESCRIBE [database.]table_name Examples \u00b6 mysql> describe system.numbers; +--------+--------+------+ | Field | Type | Null | +--------+--------+------+ | number | UInt64 | NO | +--------+--------+------+ 1 row in set (0.01 sec)","title":"DESCRIBE TABLE"},{"location":"sqlstatement/describe-commands/describe-table/#syntax","text":"DESC|DESCRIBE [database.]table_name","title":"Syntax"},{"location":"sqlstatement/describe-commands/describe-table/#examples","text":"mysql> describe system.numbers; +--------+--------+------+ | Field | Type | Null | +--------+--------+------+ | number | UInt64 | NO | +--------+--------+------+ 1 row in set (0.01 sec)","title":"Examples"},{"location":"sqlstatement/hash-functions/siphash/","text":"Produces a 64-bit SipHash hash value. Syntax \u00b6 siphash ( expression ) siphash64 ( expression ) Arguments \u00b6 Arguments Description expression Any expression. This may be a column name, the result of another function, or a math operation. Return Type \u00b6 A UInt64 data type hash value. Examples \u00b6 mysql> SELECT SIPHASH('1234567890'); +---------------------+ | SIPHASH(1234567890) | +---------------------+ | 9027491583908826579 | +---------------------+ mysql> SELECT SIPHASH(1); +---------------------+ | SIPHASH(1) | +---------------------+ | 2206609067086327257 | +---------------------+ mysql> SELECT SIPHASH(1.2); +---------------------+ | SIPHASH(1.2) | +---------------------+ | 2854037594257667269 | +---------------------+ mysql> SELECT SIPHASH(number) FROM numbers(2); +----------------------+ | siphash(number) | +----------------------+ | 13646096770106105413 | | 2206609067086327257 | +----------------------+","title":"SIPHASH"},{"location":"sqlstatement/hash-functions/siphash/#syntax","text":"siphash ( expression ) siphash64 ( expression )","title":"Syntax"},{"location":"sqlstatement/hash-functions/siphash/#arguments","text":"Arguments Description expression Any expression. This may be a column name, the result of another function, or a math operation.","title":"Arguments"},{"location":"sqlstatement/hash-functions/siphash/#return-type","text":"A UInt64 data type hash value.","title":"Return Type"},{"location":"sqlstatement/hash-functions/siphash/#examples","text":"mysql> SELECT SIPHASH('1234567890'); +---------------------+ | SIPHASH(1234567890) | +---------------------+ | 9027491583908826579 | +---------------------+ mysql> SELECT SIPHASH(1); +---------------------+ | SIPHASH(1) | +---------------------+ | 2206609067086327257 | +---------------------+ mysql> SELECT SIPHASH(1.2); +---------------------+ | SIPHASH(1.2) | +---------------------+ | 2854037594257667269 | +---------------------+ mysql> SELECT SIPHASH(number) FROM numbers(2); +----------------------+ | siphash(number) | +----------------------+ | 13646096770106105413 | | 2206609067086327257 | +----------------------+","title":"Examples"},{"location":"sqlstatement/information-functions/database/","text":"Returns the name of the currently selected database. If no database is selected, then this function returns default . Syntax \u00b6 SELECT DATABASE() Examples \u00b6 mysql> SELECT DATABASE(); +------------+ | DATABASE() | +------------+ | default | +------------+","title":"DATABASE"},{"location":"sqlstatement/information-functions/database/#syntax","text":"SELECT DATABASE()","title":"Syntax"},{"location":"sqlstatement/information-functions/database/#examples","text":"mysql> SELECT DATABASE(); +------------+ | DATABASE() | +------------+ | default | +------------+","title":"Examples"},{"location":"sqlstatement/information-functions/version/","text":"Return the current version information of DatabendQuery. Syntax \u00b6 SELECT VERSION() Examples \u00b6 mysql> SELECT VERSION(); +----------------------------------------------------------------------------------------+ | version() | +----------------------------------------------------------------------------------------+ | DatabendQuery v-0.1.0-0f9ec31-simd(1.56.0-nightly-2021-08-10T15:25:36.875868571+00:00) | +----------------------------------------------------------------------------------------+","title":"VERSION"},{"location":"sqlstatement/information-functions/version/#syntax","text":"SELECT VERSION()","title":"Syntax"},{"location":"sqlstatement/information-functions/version/#examples","text":"mysql> SELECT VERSION(); +----------------------------------------------------------------------------------------+ | version() | +----------------------------------------------------------------------------------------+ | DatabendQuery v-0.1.0-0f9ec31-simd(1.56.0-nightly-2021-08-10T15:25:36.875868571+00:00) | +----------------------------------------------------------------------------------------+","title":"Examples"},{"location":"sqlstatement/kill-commands/kill-query/","text":"Attempts to forcibly terminate the currently running queries. Syntax \u00b6 KILL QUERY|CONNECTION <query_id> Examples \u00b6 mysql> show processlist; +--------------------------------------+-------+-----------------+-------+----------+--------------------------------------------------------------------------------------+ | id | type | host | state | database | extra_info | +--------------------------------------+-------+-----------------+-------+----------+--------------------------------------------------------------------------------------+ | c95bd106-e897-407e-8e86-96e47e3d3717 | MySQL | 127.0.0.1:44606 | Query | default | show processlist | | 0ad851b2-6cde-488d-b965-e016de6a9fd5 | MySQL | 127.0.0.1:44644 | Query | default | select sum(number) from numbers_mt(10000000000) group by number%3, number%4,number%5 | +--------------------------------------+-------+-----------------+-------+----------+--------------------------------------------------------------------------------------+ 2 rows in set (0.01 sec) Read 2 rows, 380 B in 0.003 sec., 631.97 rows/sec., 120.07 KB/sec. mysql> kill query '0ad851b2-6cde-488d-b965-e016de6a9fd5'; Query OK, 0 rows affected (0.01 sec) Read 0 rows, 0 B in 0.000 sec., 0 rows/sec., 0 B/sec.","title":"KILL QUERY"},{"location":"sqlstatement/kill-commands/kill-query/#syntax","text":"KILL QUERY|CONNECTION <query_id>","title":"Syntax"},{"location":"sqlstatement/kill-commands/kill-query/#examples","text":"mysql> show processlist; +--------------------------------------+-------+-----------------+-------+----------+--------------------------------------------------------------------------------------+ | id | type | host | state | database | extra_info | +--------------------------------------+-------+-----------------+-------+----------+--------------------------------------------------------------------------------------+ | c95bd106-e897-407e-8e86-96e47e3d3717 | MySQL | 127.0.0.1:44606 | Query | default | show processlist | | 0ad851b2-6cde-488d-b965-e016de6a9fd5 | MySQL | 127.0.0.1:44644 | Query | default | select sum(number) from numbers_mt(10000000000) group by number%3, number%4,number%5 | +--------------------------------------+-------+-----------------+-------+----------+--------------------------------------------------------------------------------------+ 2 rows in set (0.01 sec) Read 2 rows, 380 B in 0.003 sec., 631.97 rows/sec., 120.07 KB/sec. mysql> kill query '0ad851b2-6cde-488d-b965-e016de6a9fd5'; Query OK, 0 rows affected (0.01 sec) Read 0 rows, 0 B in 0.000 sec., 0 rows/sec., 0 B/sec.","title":"Examples"},{"location":"sqlstatement/nullable-functions/isnotnull/","text":"Checks whether a value is not NULL. Syntax \u00b6 isNotNull ( x ) Arguments \u00b6 Arguments Description x A value with non-compound data type. Return Type \u00b6 If x is not NULL, isNotNull() returns 1, otherwise it returns 0. Examples \u00b6 mysql> CREATE TABLE nullable_test (a UInt32, b UInt32) engine=Memory; Query OK, 0 rows affected (3.19 sec) mysql> INSERT INTO nullable_test VALUES(1, Null), (Null, 2), (3, 3); Query OK, 0 rows affected (0.02 sec) mysql> SELECT a FROM nullable_test WHERE isNotNull(a); +------+ | a | +------+ | 1 | | 3 | +------+ 2 rows in set (0.01 sec)","title":"isNotNull"},{"location":"sqlstatement/nullable-functions/isnotnull/#syntax","text":"isNotNull ( x )","title":"Syntax"},{"location":"sqlstatement/nullable-functions/isnotnull/#arguments","text":"Arguments Description x A value with non-compound data type.","title":"Arguments"},{"location":"sqlstatement/nullable-functions/isnotnull/#return-type","text":"If x is not NULL, isNotNull() returns 1, otherwise it returns 0.","title":"Return Type"},{"location":"sqlstatement/nullable-functions/isnotnull/#examples","text":"mysql> CREATE TABLE nullable_test (a UInt32, b UInt32) engine=Memory; Query OK, 0 rows affected (3.19 sec) mysql> INSERT INTO nullable_test VALUES(1, Null), (Null, 2), (3, 3); Query OK, 0 rows affected (0.02 sec) mysql> SELECT a FROM nullable_test WHERE isNotNull(a); +------+ | a | +------+ | 1 | | 3 | +------+ 2 rows in set (0.01 sec)","title":"Examples"},{"location":"sqlstatement/nullable-functions/isnull/","text":"Checks whether a value is NULL. Syntax \u00b6 isNull ( x ) Arguments \u00b6 Arguments Description x A value with non-compound data type. Return Type \u00b6 If x is NULL, ISNULL() returns 1, otherwise it returns 0. Examples \u00b6 mysql> CREATE TABLE nullable_test (a UInt32, b UInt32) engine=Memory; Query OK, 0 rows affected (3.19 sec) mysql> INSERT INTO nullable_test VALUES(1, Null), (Null, 2), (3, 3); Query OK, 0 rows affected (0.02 sec) mysql> SELECT a FROM nullable_test WHERE isNull(b); +------+ | a | +------+ | 1 | +------+ 1 row in set (0.17 sec)","title":"isNull"},{"location":"sqlstatement/nullable-functions/isnull/#syntax","text":"isNull ( x )","title":"Syntax"},{"location":"sqlstatement/nullable-functions/isnull/#arguments","text":"Arguments Description x A value with non-compound data type.","title":"Arguments"},{"location":"sqlstatement/nullable-functions/isnull/#return-type","text":"If x is NULL, ISNULL() returns 1, otherwise it returns 0.","title":"Return Type"},{"location":"sqlstatement/nullable-functions/isnull/#examples","text":"mysql> CREATE TABLE nullable_test (a UInt32, b UInt32) engine=Memory; Query OK, 0 rows affected (3.19 sec) mysql> INSERT INTO nullable_test VALUES(1, Null), (Null, 2), (3, 3); Query OK, 0 rows affected (0.02 sec) mysql> SELECT a FROM nullable_test WHERE isNull(b); +------+ | a | +------+ | 1 | +------+ 1 row in set (0.17 sec)","title":"Examples"},{"location":"sqlstatement/other-functions/running-difference/","text":"Calculates the difference between successive row values \u200b\u200bin the data block. Returns 0 for the first row and the difference from the previous row for each subsequent row. Syntax \u00b6 runningDifference ( expression ) Arguments \u00b6 Arguments Description expression Any expression which generates numberic result, including integer numbers, real numbers, date and datetime. Return Type \u00b6 Numberic Type Examples \u00b6 databend :) DESC runing_difference_test; \u250c\u2500Field\u2500\u252c\u2500Type\u2500\u2500\u252c\u2500Null\u2500\u2510 \u2502 a \u2502 UInt8 \u2502 NO \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518 databend :) SELECT * FROM runing_difference_test; \u250c\u2500\u2500a\u2500\u2510 \u2502 1 \u2502 \u2502 3 \u2502 \u2502 5 \u2502 \u2502 10 \u2502 \u2514\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500a\u2500\u2510 \u2502 15 \u2502 \u2502 20 \u2502 \u2514\u2500\u2500\u2500\u2500\u2518 databend :) SELECT runningDifference(a) FROM runing_difference_test; \u250c\u2500runningDifference(a)\u2500\u2510 \u2502 0 \u2502 \u2502 2 \u2502 \u2502 2 \u2502 \u2502 5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500runningDifference(a)\u2500\u2510 \u2502 0 \u2502 \u2502 5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"runningDifference"},{"location":"sqlstatement/other-functions/running-difference/#syntax","text":"runningDifference ( expression )","title":"Syntax"},{"location":"sqlstatement/other-functions/running-difference/#arguments","text":"Arguments Description expression Any expression which generates numberic result, including integer numbers, real numbers, date and datetime.","title":"Arguments"},{"location":"sqlstatement/other-functions/running-difference/#return-type","text":"Numberic Type","title":"Return Type"},{"location":"sqlstatement/other-functions/running-difference/#examples","text":"databend :) DESC runing_difference_test; \u250c\u2500Field\u2500\u252c\u2500Type\u2500\u2500\u252c\u2500Null\u2500\u2510 \u2502 a \u2502 UInt8 \u2502 NO \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518 databend :) SELECT * FROM runing_difference_test; \u250c\u2500\u2500a\u2500\u2510 \u2502 1 \u2502 \u2502 3 \u2502 \u2502 5 \u2502 \u2502 10 \u2502 \u2514\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500a\u2500\u2510 \u2502 15 \u2502 \u2502 20 \u2502 \u2514\u2500\u2500\u2500\u2500\u2518 databend :) SELECT runningDifference(a) FROM runing_difference_test; \u250c\u2500runningDifference(a)\u2500\u2510 \u2502 0 \u2502 \u2502 2 \u2502 \u2502 2 \u2502 \u2502 5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500runningDifference(a)\u2500\u2510 \u2502 0 \u2502 \u2502 5 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Examples"},{"location":"sqlstatement/other-functions/totypename/","text":"ToTypeName function is used to return the name of a data type. Syntax \u00b6 ToTypeName ( expression ) Arguments \u00b6 Arguments Description expression Any expression. This may be a column name, the result of another function, or a math operation. Return Type \u00b6 String Examples \u00b6 mysql> SELECT ToTypeName(number) FROM numbers(2); +--------------------+ | ToTypeName(number) | +--------------------+ | UInt64 | | UInt64 | +--------------------+ mysql> SELECT ToTypeName(sum(number)) FROM numbers(2); +-------------------------+ | ToTypeName(sum(number)) | +-------------------------+ | UInt64 | +-------------------------+","title":"ToTypeName"},{"location":"sqlstatement/other-functions/totypename/#syntax","text":"ToTypeName ( expression )","title":"Syntax"},{"location":"sqlstatement/other-functions/totypename/#arguments","text":"Arguments Description expression Any expression. This may be a column name, the result of another function, or a math operation.","title":"Arguments"},{"location":"sqlstatement/other-functions/totypename/#return-type","text":"String","title":"Return Type"},{"location":"sqlstatement/other-functions/totypename/#examples","text":"mysql> SELECT ToTypeName(number) FROM numbers(2); +--------------------+ | ToTypeName(number) | +--------------------+ | UInt64 | | UInt64 | +--------------------+ mysql> SELECT ToTypeName(sum(number)) FROM numbers(2); +-------------------------+ | ToTypeName(sum(number)) | +-------------------------+ | UInt64 | +-------------------------+","title":"Examples"},{"location":"sqlstatement/show-commands/show-create-table/","text":"Shows the CREATE TABLE statement that creates the named table. Syntax \u00b6 SHOW CREATE TABLE [database.]table_name Examples \u00b6 Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SHOW CREATE TABLE system.numbers; +---------+--------------------------------------------------------------------+ | Table | Create Table | +---------+--------------------------------------------------------------------+ | numbers | CREATE TABLE `numbers` ( `number` UInt64, ) ENGINE=SystemNumbers | +---------+--------------------------------------------------------------------+","title":"SHOW CREATE TABLE"},{"location":"sqlstatement/show-commands/show-create-table/#syntax","text":"SHOW CREATE TABLE [database.]table_name","title":"Syntax"},{"location":"sqlstatement/show-commands/show-create-table/#examples","text":"Note numbers(N) \u2013 A table for test with the single number column (UInt64) that contains integers from 0 to N-1. mysql> SHOW CREATE TABLE system.numbers; +---------+--------------------------------------------------------------------+ | Table | Create Table | +---------+--------------------------------------------------------------------+ | numbers | CREATE TABLE `numbers` ( `number` UInt64, ) ENGINE=SystemNumbers | +---------+--------------------------------------------------------------------+","title":"Examples"},{"location":"sqlstatement/show-commands/show-databases/","text":"Shows the list of databases that exist on the instance. Syntax \u00b6 SHOW DATABASES [LIKE expr | WHERE expr] Examples \u00b6 mysql> SHOW DATABASES; +----------+ | Database | +----------+ | default | | for_test | | local | | ss | | ss1 | | ss2 | | ss3 | | system | | test | +----------+ 9 rows in set (0.00 sec) Showing the databases with database \"ss\" : mysql> SHOW DATABASES WHERE Database = 'ss'; +----------+ | Database | +----------+ | ss | +----------+ 1 row in set (0.01 sec) Showing the databases begin with \"ss\" : mysql> SHOW DATABASES Like 'ss%'; +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec) Showing the databases begin with \"ss\" with where: mysql> SHOW DATABASES WHERE Database Like 'ss%'; +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec) Showing the databases like substring expr: mysql> SHOW DATABASES Like SUBSTRING('ss%' FROM 1 FOR 3); +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec) Showing the databases like substring expr with where: mysql> SHOW DATABASES WHERE Database Like SUBSTRING('ss%' FROM 1 FOR 3); +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec)","title":"SHOW DATABASES"},{"location":"sqlstatement/show-commands/show-databases/#syntax","text":"SHOW DATABASES [LIKE expr | WHERE expr]","title":"Syntax"},{"location":"sqlstatement/show-commands/show-databases/#examples","text":"mysql> SHOW DATABASES; +----------+ | Database | +----------+ | default | | for_test | | local | | ss | | ss1 | | ss2 | | ss3 | | system | | test | +----------+ 9 rows in set (0.00 sec) Showing the databases with database \"ss\" : mysql> SHOW DATABASES WHERE Database = 'ss'; +----------+ | Database | +----------+ | ss | +----------+ 1 row in set (0.01 sec) Showing the databases begin with \"ss\" : mysql> SHOW DATABASES Like 'ss%'; +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec) Showing the databases begin with \"ss\" with where: mysql> SHOW DATABASES WHERE Database Like 'ss%'; +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec) Showing the databases like substring expr: mysql> SHOW DATABASES Like SUBSTRING('ss%' FROM 1 FOR 3); +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec) Showing the databases like substring expr with where: mysql> SHOW DATABASES WHERE Database Like SUBSTRING('ss%' FROM 1 FOR 3); +----------+ | Database | +----------+ | ss | | ss1 | | ss2 | | ss3 | +----------+ 4 rows in set (0.01 sec)","title":"Examples"},{"location":"sqlstatement/show-commands/show-metrics/","text":"Shows the list of system metrics. Syntax \u00b6 SHOW METRICS Examples \u00b6 mysql> SHOW METRICS; +-----------------------------------+---------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | metric | kind | labels | value | +-----------------------------------+---------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | session_connect_numbers | counter | {} | 1.0 | | optimizer_optimize_usedtime_sum | untyped | {} | 0.000438079 | | optimizer_optimize_usedtime_count | untyped | {} | 1.0 | | parser_parse_usedtime_sum | untyped | {} | 0.000254307 | | parser_parse_usedtime_count | untyped | {} | 2.0 | | optimizer_optimize_usedtime | summary | {} | [{\"quantile\":0.0,\"count\":0.000438079},{\"quantile\":0.5,\"count\":0.000438079},{\"quantile\":0.9,\"count\":0.000438079},{\"quantile\":0.95,\"count\":0.000438079},{\"quantile\":0.99,\"count\":0.000438079},{\"quantile\":0.999,\"count\":0.000438079},{\"quantile\":1.0,\"count\":0.000438079}] | | parser_parse_usedtime | summary | {} | [{\"quantile\":0.0,\"count\":0.000107972},{\"quantile\":0.5,\"count\":0.000107972},{\"quantile\":0.9,\"count\":0.000107972},{\"quantile\":0.95,\"count\":0.000107972},{\"quantile\":0.99,\"count\":0.000107972},{\"quantile\":0.999,\"count\":0.000107972},{\"quantile\":1.0,\"count\":0.000107972}] | +-----------------------------------+---------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 7 rows in set (0.01 sec) Read 7 rows, 1.06 KB in 0.004 sec., 1.83 thousand rows/sec., 278.48 KB/sec.","title":"SHOW METRICS"},{"location":"sqlstatement/show-commands/show-metrics/#syntax","text":"SHOW METRICS","title":"Syntax"},{"location":"sqlstatement/show-commands/show-metrics/#examples","text":"mysql> SHOW METRICS; +-----------------------------------+---------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | metric | kind | labels | value | +-----------------------------------+---------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | session_connect_numbers | counter | {} | 1.0 | | optimizer_optimize_usedtime_sum | untyped | {} | 0.000438079 | | optimizer_optimize_usedtime_count | untyped | {} | 1.0 | | parser_parse_usedtime_sum | untyped | {} | 0.000254307 | | parser_parse_usedtime_count | untyped | {} | 2.0 | | optimizer_optimize_usedtime | summary | {} | [{\"quantile\":0.0,\"count\":0.000438079},{\"quantile\":0.5,\"count\":0.000438079},{\"quantile\":0.9,\"count\":0.000438079},{\"quantile\":0.95,\"count\":0.000438079},{\"quantile\":0.99,\"count\":0.000438079},{\"quantile\":0.999,\"count\":0.000438079},{\"quantile\":1.0,\"count\":0.000438079}] | | parser_parse_usedtime | summary | {} | [{\"quantile\":0.0,\"count\":0.000107972},{\"quantile\":0.5,\"count\":0.000107972},{\"quantile\":0.9,\"count\":0.000107972},{\"quantile\":0.95,\"count\":0.000107972},{\"quantile\":0.99,\"count\":0.000107972},{\"quantile\":0.999,\"count\":0.000107972},{\"quantile\":1.0,\"count\":0.000107972}] | +-----------------------------------+---------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ 7 rows in set (0.01 sec) Read 7 rows, 1.06 KB in 0.004 sec., 1.83 thousand rows/sec., 278.48 KB/sec.","title":"Examples"},{"location":"sqlstatement/show-commands/show-processlist/","text":"The Databend process list indicates the operations currently being performed by the set of threads executing within the server. The SHOW PROCESSLIST statement is one source of process information. Syntax \u00b6 SHOW PROCESSLIST Examples \u00b6 mysql> SHOW PROCESSLIST; +--------------------------------------+-----------------+-------+----------+------------------+ | id | host | state | database | extra_info | +--------------------------------------+-----------------+-------+----------+------------------+ | 1e6e5ed4-5441-43da-9ed6-eb6ba9baeb64 | 127.0.0.1:60080 | Query | default | show processlist | | 3d283add-4f60-416d-b9ca-662120614093 | 127.0.0.1:57018 | Query | default | NULL | +--------------------------------------+-----------------+-------+----------+------------------+","title":"SHOW PROCESSLIST"},{"location":"sqlstatement/show-commands/show-processlist/#syntax","text":"SHOW PROCESSLIST","title":"Syntax"},{"location":"sqlstatement/show-commands/show-processlist/#examples","text":"mysql> SHOW PROCESSLIST; +--------------------------------------+-----------------+-------+----------+------------------+ | id | host | state | database | extra_info | +--------------------------------------+-----------------+-------+----------+------------------+ | 1e6e5ed4-5441-43da-9ed6-eb6ba9baeb64 | 127.0.0.1:60080 | Query | default | show processlist | | 3d283add-4f60-416d-b9ca-662120614093 | 127.0.0.1:57018 | Query | default | NULL | +--------------------------------------+-----------------+-------+----------+------------------+","title":"Examples"},{"location":"sqlstatement/show-commands/show-settings/","text":"Shows the databend's SETTINGS. You can change it by set command, like set max_threads = 1 . Syntax \u00b6 SHOW SETTINGS Examples \u00b6 mysql> SHOW SETTINGS; +-----------------------+-----------+ | name | value | +-----------------------+-----------+ | min_distributed_bytes | 524288000 | | flight_client_timeout | 60 | | max_threads | 16 | | max_block_size | 10000 | | min_distributed_rows | 100000000 | +-----------------------+-----------+","title":"SHOW SETTINGS"},{"location":"sqlstatement/show-commands/show-settings/#syntax","text":"SHOW SETTINGS","title":"Syntax"},{"location":"sqlstatement/show-commands/show-settings/#examples","text":"mysql> SHOW SETTINGS; +-----------------------+-----------+ | name | value | +-----------------------+-----------+ | min_distributed_bytes | 524288000 | | flight_client_timeout | 60 | | max_threads | 16 | | max_block_size | 10000 | | min_distributed_rows | 100000000 | +-----------------------+-----------+","title":"Examples"},{"location":"sqlstatement/show-commands/show-tables/","text":"Shows the list of tables in the currently selected database. Syntax \u00b6 SHOW TABLES [LIKE 'pattern' | WHERE expr | FROM 'pattern' | IN 'pattern'] Examples \u00b6 mysql> SHOW TABLES; +---------------+ | name | +---------------+ | clusters | | contributors | | databases | | functions | | numbers | | numbers_local | | numbers_mt | | one | | processes | | settings | | tables | | tracing | +---------------+ Showing the tables with table name \"numbers_local\" : mysql> SHOW TABLES LIKE 'numbers%'; +---------------+ | name | +---------------+ | numbers_local | +---------------+ Showing the tables begin with \"numbers\" : mysql> SHOW TABLES LIKE 'numbers%'; +---------------+ | name | +---------------+ | numbers | | numbers_local | | numbers_mt | +---------------+ Showing the tables begin with \"numbers\" with WHERE : mysql> SHOW TABLES WHERE name LIKE 'numbers%'; +---------------+ | name | +---------------+ | numbers | | numbers_local | | numbers_mt | +---------------+ Showing the tables are inside \"ss\" : mysql> SHOW TABLES FROM 'ss'; +---------------+ | name | +---------------+ | numbers | | numbers_local | | numbers_mt | +---------------+","title":"SHOW TABLES"},{"location":"sqlstatement/show-commands/show-tables/#syntax","text":"SHOW TABLES [LIKE 'pattern' | WHERE expr | FROM 'pattern' | IN 'pattern']","title":"Syntax"},{"location":"sqlstatement/show-commands/show-tables/#examples","text":"mysql> SHOW TABLES; +---------------+ | name | +---------------+ | clusters | | contributors | | databases | | functions | | numbers | | numbers_local | | numbers_mt | | one | | processes | | settings | | tables | | tracing | +---------------+ Showing the tables with table name \"numbers_local\" : mysql> SHOW TABLES LIKE 'numbers%'; +---------------+ | name | +---------------+ | numbers_local | +---------------+ Showing the tables begin with \"numbers\" : mysql> SHOW TABLES LIKE 'numbers%'; +---------------+ | name | +---------------+ | numbers | | numbers_local | | numbers_mt | +---------------+ Showing the tables begin with \"numbers\" with WHERE : mysql> SHOW TABLES WHERE name LIKE 'numbers%'; +---------------+ | name | +---------------+ | numbers | | numbers_local | | numbers_mt | +---------------+ Showing the tables are inside \"ss\" : mysql> SHOW TABLES FROM 'ss'; +---------------+ | name | +---------------+ | numbers | | numbers_local | | numbers_mt | +---------------+","title":"Examples"},{"location":"sqlstatement/string-functions/substring/","text":"SUBSTRING function is used to extract a string containing a specific number of characters from a particular position of a given string. Syntax \u00b6 SUBSTRING ( expression [ FROM position_expr ] [ FOR length_expr ]) or SUBSTRING ( expression , position_expr , [ length_expr ]) Arguments \u00b6 Arguments Description expression The main string from where the character to be extracted position_expr The one-indexed position expression to start at. If negative, counts from the end length_expr The number expression of characters to extract Return Type \u00b6 String Note In SUBSTRING, the starting index point of a string is 1 (not 0). In the following example, the starting index 3 represents the third character in the string, because the index starts from 1. mysql> SELECT SUBSTRING('1234567890' FROM 3 FOR 3); +---------------------------+ | SUBSTRING(1234567890,3,3) | +---------------------------+ | 345 | +---------------------------+ Examples \u00b6 mysql> SELECT SUBSTRING('1234567890' FROM 3 FOR 3); +---------------------------+ | SUBSTRING(1234567890,3,3) | +---------------------------+ | 345 | +---------------------------+ mysql> SELECT SUBSTRING('1234567890', 3, 3); +-------------------------------+ | substring('1234567890', 3, 3) | +-------------------------------+ | 345 | +-------------------------------+ mysql> SELECT SUBSTRING('1234567890' FROM 3); +------------------------------+ | SUBSTRING(1234567890,3,NULL) | +------------------------------+ | 34567890 | +------------------------------+ 1 row in set (0.01 sec) mysql> SELECT SUBSTRING('1234567890', 3); +----------------------------+ | substring('1234567890', 3) | +----------------------------+ | 34567890 | +----------------------------+ mysql> SELECT SUBSTRING('1234567890' FOR 3); +---------------------------+ | SUBSTRING(1234567890,1,3) | +---------------------------+ | 123 | +---------------------------+ 1 row in set (0.01 sec) mysql> SELECT SUBSTRING('1234567890',1, 3); +-------------------------------+ | substring('1234567890', 1, 3) | +-------------------------------+ | 123 | +-------------------------------+","title":"SUBSTRING"},{"location":"sqlstatement/string-functions/substring/#syntax","text":"SUBSTRING ( expression [ FROM position_expr ] [ FOR length_expr ]) or SUBSTRING ( expression , position_expr , [ length_expr ])","title":"Syntax"},{"location":"sqlstatement/string-functions/substring/#arguments","text":"Arguments Description expression The main string from where the character to be extracted position_expr The one-indexed position expression to start at. If negative, counts from the end length_expr The number expression of characters to extract","title":"Arguments"},{"location":"sqlstatement/string-functions/substring/#return-type","text":"String Note In SUBSTRING, the starting index point of a string is 1 (not 0). In the following example, the starting index 3 represents the third character in the string, because the index starts from 1. mysql> SELECT SUBSTRING('1234567890' FROM 3 FOR 3); +---------------------------+ | SUBSTRING(1234567890,3,3) | +---------------------------+ | 345 | +---------------------------+","title":"Return Type"},{"location":"sqlstatement/string-functions/substring/#examples","text":"mysql> SELECT SUBSTRING('1234567890' FROM 3 FOR 3); +---------------------------+ | SUBSTRING(1234567890,3,3) | +---------------------------+ | 345 | +---------------------------+ mysql> SELECT SUBSTRING('1234567890', 3, 3); +-------------------------------+ | substring('1234567890', 3, 3) | +-------------------------------+ | 345 | +-------------------------------+ mysql> SELECT SUBSTRING('1234567890' FROM 3); +------------------------------+ | SUBSTRING(1234567890,3,NULL) | +------------------------------+ | 34567890 | +------------------------------+ 1 row in set (0.01 sec) mysql> SELECT SUBSTRING('1234567890', 3); +----------------------------+ | substring('1234567890', 3) | +----------------------------+ | 34567890 | +----------------------------+ mysql> SELECT SUBSTRING('1234567890' FOR 3); +---------------------------+ | SUBSTRING(1234567890,1,3) | +---------------------------+ | 123 | +---------------------------+ 1 row in set (0.01 sec) mysql> SELECT SUBSTRING('1234567890',1, 3); +-------------------------------+ | substring('1234567890', 1, 3) | +-------------------------------+ | 123 | +-------------------------------+","title":"Examples"},{"location":"sqlstatement/test-functions/crashme/","text":"CRASHME function makes a crash,. Warning Only used for testing where panic is required. This function is very useful for distributed query stability testing, we can trigger panic by hand. Currently CRASHME function there is no permission restrictions. Syntax \u00b6 crashme ( expression ) Arguments \u00b6 Arguments Description expression Any expression, like sleep(1) Return Type \u00b6 Null Examples \u00b6 mysql> SELECT * FROM (SELECT crashme(sleep(1)));; ERROR 2013 (HY000) at line 2: Lost connection to MySQL server during query","title":"CRASHME"},{"location":"sqlstatement/test-functions/crashme/#syntax","text":"crashme ( expression )","title":"Syntax"},{"location":"sqlstatement/test-functions/crashme/#arguments","text":"Arguments Description expression Any expression, like sleep(1)","title":"Arguments"},{"location":"sqlstatement/test-functions/crashme/#return-type","text":"Null","title":"Return Type"},{"location":"sqlstatement/test-functions/crashme/#examples","text":"mysql> SELECT * FROM (SELECT crashme(sleep(1)));; ERROR 2013 (HY000) at line 2: Lost connection to MySQL server during query","title":"Examples"},{"location":"sqlstatement/test-functions/sleep/","text":"Sleeps seconds seconds on each data block. Warning Only used for testing where sleep is required. Syntax \u00b6 sleep ( seconds ) Arguments \u00b6 Arguments Description seconds Must be a constant column of any nonnegative number or float.\uff5c Return Type \u00b6 UInt8 Examples \u00b6 mysql> SELECT sleep(2); +----------+ | sleep(2) | +----------+ | 0 | +----------+ 1 row in set (2.01 sec) mysql> SELECT sleep(2.7); +------------+ | sleep(2.7) | +------------+ | 0 | +------------+ 1 row in set (2.71 sec)","title":"SLEEP"},{"location":"sqlstatement/test-functions/sleep/#syntax","text":"sleep ( seconds )","title":"Syntax"},{"location":"sqlstatement/test-functions/sleep/#arguments","text":"Arguments Description seconds Must be a constant column of any nonnegative number or float.\uff5c","title":"Arguments"},{"location":"sqlstatement/test-functions/sleep/#return-type","text":"UInt8","title":"Return Type"},{"location":"sqlstatement/test-functions/sleep/#examples","text":"mysql> SELECT sleep(2); +----------+ | sleep(2) | +----------+ | 0 | +----------+ 1 row in set (2.01 sec) mysql> SELECT sleep(2.7); +------------+ | sleep(2.7) | +------------+ | 0 | +------------+ 1 row in set (2.71 sec)","title":"Examples"},{"location":"system/system-tables/","text":"Most system tables store their data in RAM. A DatabendQuery server creates such system tables at the start. system.numbers \u00b6 This table contains a single UInt64 column named number that contains almost all the natural numbers starting from zero. You can use this table for tests, or if you need to do a brute force search. Reads from this table are parallelized too. Used for tests. mysql> SELECT avg(number) FROM numbers(100000000); +-------------+ | avg(number) | +-------------+ | 49999999.5 | +-------------+ 1 row in set (0.04 sec) system.numbers_mt \u00b6 The same as system.numbers system.settings \u00b6 Contains information about session settings for current user. mysql> SELECT * FROM system.settings; +----------------+---------+---------------------------------------------------------------------------------------------------+ | name | value | description | +----------------+---------+---------------------------------------------------------------------------------------------------+ | max_block_size | 10000 | Maximum block size for reading | | max_threads | 8 | The maximum number of threads to execute the request. By default, it is determined automatically. | | default_db | default | The default database for current session | +----------------+---------+---------------------------------------------------------------------------------------------------+ 3 rows in set (0.00 sec) system.functions \u00b6 Contains information about normal and aggregate functions. mysql> SELECT * FROM system.functions limit 10; +----------+--------------+ | name | is_aggregate | +----------+--------------+ | + | false | | plus | false | | - | false | | minus | false | | * | false | | multiply | false | | / | false | | divide | false | | % | false | | modulo | false | +----------+--------------+ 10 rows in set (0.01 sec) system.contributors \u00b6 Contains information about contributors. mysql> SELECT * FROM system.contributors LIMIT 20; +-------------------------+ | name | +-------------------------+ | artorias1024 | | BohuTANG | | dependabot[bot] | | dependabot-preview[bot] | | drdr xp | | Eason | | hulunbier | | jyizheng | | leiysky | | smallfish | | sundy-li | | sundyli | | taiyang-li | | TLightSky | | Winter Zhang | | wubx | | yizheng | | Yizheng Jiao | | zhang2014 | | zhihanz | +-------------------------+ 20 rows in set (0.00 sec) system.credits \u00b6 Contains information about credits. mysql> SELECT * FROM system.credits LIMIT 20; +-------------------+---------+---------------------------+ | name | version | license | +-------------------+---------+---------------------------+ | addr2line | 0.16.0 | Apache-2.0 OR MIT | | adler | 1.0.2 | 0BSD OR Apache-2.0 OR MIT | | ahash | 0.6.3 | Apache-2.0 OR MIT | | ahash | 0.7.4 | Apache-2.0 OR MIT | | aho-corasick | 0.7.18 | MIT OR Unlicense | | ansi_term | 0.9.0 | MIT | | ansi_term | 0.11.0 | MIT | | ansi_term | 0.12.1 | MIT | | anyhow | 1.0.43 | Apache-2.0 OR MIT | | arbitrary | 1.0.1 | Apache-2.0 OR MIT | | arrayvec | 0.4.12 | Apache-2.0 OR MIT | | arrayvec | 0.5.2 | Apache-2.0 OR MIT | | arrow-flight | 0.1.0 | Apache-2.0 | | arrow2 | 0.4.0 | Apache-2.0 | | assert_cmd | 2.0.1 | Apache-2.0 OR MIT | | async-compat | 0.2.1 | Apache-2.0 OR MIT | | async-raft | 0.6.1 | Apache-2.0 OR MIT | | async-stream | 0.3.2 | MIT | | async-stream-impl | 0.3.2 | MIT | | async-trait | 0.1.51 | Apache-2.0 OR MIT | +-------------------+---------+---------------------------+ 20 rows in set (1.33 sec)","title":"System Tables"},{"location":"system/system-tables/#systemnumbers","text":"This table contains a single UInt64 column named number that contains almost all the natural numbers starting from zero. You can use this table for tests, or if you need to do a brute force search. Reads from this table are parallelized too. Used for tests. mysql> SELECT avg(number) FROM numbers(100000000); +-------------+ | avg(number) | +-------------+ | 49999999.5 | +-------------+ 1 row in set (0.04 sec)","title":"system.numbers"},{"location":"system/system-tables/#systemnumbers_mt","text":"The same as system.numbers","title":"system.numbers_mt"},{"location":"system/system-tables/#systemsettings","text":"Contains information about session settings for current user. mysql> SELECT * FROM system.settings; +----------------+---------+---------------------------------------------------------------------------------------------------+ | name | value | description | +----------------+---------+---------------------------------------------------------------------------------------------------+ | max_block_size | 10000 | Maximum block size for reading | | max_threads | 8 | The maximum number of threads to execute the request. By default, it is determined automatically. | | default_db | default | The default database for current session | +----------------+---------+---------------------------------------------------------------------------------------------------+ 3 rows in set (0.00 sec)","title":"system.settings"},{"location":"system/system-tables/#systemfunctions","text":"Contains information about normal and aggregate functions. mysql> SELECT * FROM system.functions limit 10; +----------+--------------+ | name | is_aggregate | +----------+--------------+ | + | false | | plus | false | | - | false | | minus | false | | * | false | | multiply | false | | / | false | | divide | false | | % | false | | modulo | false | +----------+--------------+ 10 rows in set (0.01 sec)","title":"system.functions"},{"location":"system/system-tables/#systemcontributors","text":"Contains information about contributors. mysql> SELECT * FROM system.contributors LIMIT 20; +-------------------------+ | name | +-------------------------+ | artorias1024 | | BohuTANG | | dependabot[bot] | | dependabot-preview[bot] | | drdr xp | | Eason | | hulunbier | | jyizheng | | leiysky | | smallfish | | sundy-li | | sundyli | | taiyang-li | | TLightSky | | Winter Zhang | | wubx | | yizheng | | Yizheng Jiao | | zhang2014 | | zhihanz | +-------------------------+ 20 rows in set (0.00 sec)","title":"system.contributors"},{"location":"system/system-tables/#systemcredits","text":"Contains information about credits. mysql> SELECT * FROM system.credits LIMIT 20; +-------------------+---------+---------------------------+ | name | version | license | +-------------------+---------+---------------------------+ | addr2line | 0.16.0 | Apache-2.0 OR MIT | | adler | 1.0.2 | 0BSD OR Apache-2.0 OR MIT | | ahash | 0.6.3 | Apache-2.0 OR MIT | | ahash | 0.7.4 | Apache-2.0 OR MIT | | aho-corasick | 0.7.18 | MIT OR Unlicense | | ansi_term | 0.9.0 | MIT | | ansi_term | 0.11.0 | MIT | | ansi_term | 0.12.1 | MIT | | anyhow | 1.0.43 | Apache-2.0 OR MIT | | arbitrary | 1.0.1 | Apache-2.0 OR MIT | | arrayvec | 0.4.12 | Apache-2.0 OR MIT | | arrayvec | 0.5.2 | Apache-2.0 OR MIT | | arrow-flight | 0.1.0 | Apache-2.0 | | arrow2 | 0.4.0 | Apache-2.0 | | assert_cmd | 2.0.1 | Apache-2.0 OR MIT | | async-compat | 0.2.1 | Apache-2.0 OR MIT | | async-raft | 0.6.1 | Apache-2.0 OR MIT | | async-stream | 0.3.2 | MIT | | async-stream-impl | 0.3.2 | MIT | | async-trait | 0.1.51 | Apache-2.0 OR MIT | +-------------------+---------+---------------------------+ 20 rows in set (1.33 sec)","title":"system.credits"}]}